Gmail	jiamu zhou <zhoujm99@gmail.com>
cs daily Subj-class mailing 200021 26
send mail ONLY to cs <no-reply@arxiv.org>	2024年1月19日 17:51
回复：cs@arxiv.org
收件人：cs daily title/abstract distribution <rabble@arxiv.org>
------------------------------------------------------------------------------
------------------------------------------------------------------------------
Send any comments regarding submissions directly to submitter.
------------------------------------------------------------------------------
Archives at http://arxiv.org/
To unsubscribe, e-mail To: cs@arXiv.org, Subject: cancel
------------------------------------------------------------------------------
 Submissions to:
Artificial Intelligence
Computation and Language
Machine Learning
 received from  Wed 17 Jan 24 19:00:00 GMT  to  Thu 18 Jan 24 19:00:00 GMT
------------------------------------------------------------------------------
------------------------------------------------------------------------------
\\
arXiv:2401.09444
Date: Wed, 20 Dec 2023 16:11:10 GMT   (1871kb,D)

Title: Online Handbook of Argumentation for AI: Volume 4
Authors: Lars Bengel, Lydia Bl\"umel, Elfia Bezou-Vrakatseli, Federico
  Castagna, Giulia D'Agostino, Isabelle Kuhlmann, Jack Mumford, Daphne
  Odekerken, Fabrizio Russo, Stefan Sarkadi, Madeleine Waller, Andreas Xydis
Categories: cs.AI
\\
  This volume contains revised versions of the papers selected for the fourth
volume of the Online Handbook of Argumentation for AI (OHAAI). Previously,
formal theories of argument and argument interaction have been proposed and
studied, and this has led to the more recent study of computational models of
argument. Argumentation, as a field within artificial intelligence (AI), is
highly relevant for researchers interested in symbolic representations of
knowledge and defeasible reasoning. The purpose of this handbook is to provide
an open access and curated anthology for the argumentation research community.
OHAAI is designed to serve as a research hub to keep track of the latest and
upcoming PhD-driven research on the theory and application of argumentation in
all areas related to AI.
\\ ( https://arxiv.org/abs/2401.09444 ,  1871kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09448
Date: Fri, 22 Dec 2023 05:21:37 GMT   (12466kb,D)

Title: Tumbug: A pictorial, universal knowledge representation method
Authors: Mark A. Atkins
Categories: cs.AI
Comments: 346 pages, 334 figures
\\
  Since the key to artificial general intelligence (AGI) is commonly believed
to be commonsense reasoning (CSR) or, roughly equivalently, discovery of a
knowledge representation method (KRM) that is particularly suitable for CSR,
the author developed a custom KRM for CSR. This novel KRM called Tumbug was
designed to be pictorial in nature because there exists increasing evidence
that the human brain uses some pictorial type of KRM, and no well-known prior
research in AGI has researched this KRM possibility. Tumbug is somewhat similar
to Roger Schank's Conceptual Dependency (CD) theory, but Tumbug is pictorial
and uses about 30 components based on fundamental concepts from the sciences
and human life, in contrast to CD theory, which is textual and uses about 17
components (= 6 Primitive Conceptual Categories + 11 Primitive Acts) based
mainly on human-oriented activities. All the Building Blocks of Tumbug were
found to generalize to only five Basic Building Blocks that exactly correspond
to the three components {O, A, V} of traditional Object-Attribute-Value
representation plus two new components {C, S}, which are Change and System.
Collectively this set of five components, called "SCOVA," seems to be a
universal foundation for all knowledge representation.
\\ ( https://arxiv.org/abs/2401.09448 ,  12466kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09491
Date: Tue, 16 Jan 2024 21:46:43 GMT   (3154kb)

Title: Memory, Space, and Planning: Multiscale Predictive Representations
Authors: Ida Momennejad
Categories: cs.AI
Comments: To be published as a chapter in an edited volume by Oxford University
  Press (Editors: Sara Aronowitz and Lynn Nadel)
\\
  Memory is inherently entangled with prediction and planning. Flexible
behavior in biological and artificial agents depends on the interplay of
learning from the past and predicting the future in ever-changing environments.
This chapter reviews computational, behavioral, and neural evidence suggesting
these processes rely on learning the relational structure of experiences, known
as cognitive maps, and draws two key takeaways. First, that these memory
structures are organized as multiscale, compact predictive representations in
hippocampal and prefrontal cortex, or PFC, hierarchies. Second, we argue that
such predictive memory structures are crucial to the complementary functions of
the hippocampus and PFC, both for enabling a recall of detailed and coherent
past episodes as well as generalizing experiences at varying scales for
efficient prediction and planning. These insights advance our understanding of
memory and planning mechanisms in the brain and hold significant implications
for advancing artificial intelligence systems.
\\ ( https://arxiv.org/abs/2401.09491 ,  3154kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09680
Date: Thu, 18 Jan 2024 02:14:13 GMT   (19925kb)

Title: Tiny Multi-Agent DRL for Twins Migration in UAV Metaverses: A
  Multi-Leader Multi-Follower Stackelberg Game Approach
Authors: Jiawen Kang, Yue Zhong, Minrui Xu, Jiangtian Nie, Jinbo Wen, Hongyang
  Du, Dongdong Ye, Xumin Huang, Dusit Niyato, Shengli Xie
Categories: cs.AI cs.GT
\\
  The synergy between Unmanned Aerial Vehicles (UAVs) and metaverses is giving
rise to an emerging paradigm named UAV metaverses, which create a unified
ecosystem that blends physical and virtual spaces, transforming drone
interaction and virtual exploration. UAV Twins (UTs), as the digital twins of
UAVs that revolutionize UAV applications by making them more immersive,
realistic, and informative, are deployed and updated on ground base stations,
e.g., RoadSide Units (RSUs), to offer metaverse services for UAV Metaverse
Users (UMUs). Due to the dynamic mobility of UAVs and limited communication
coverages of RSUs, it is essential to perform real-time UT migration to ensure
seamless immersive experiences for UMUs. However, selecting appropriate RSUs
and optimizing the required bandwidth is challenging for achieving reliable and
efficient UT migration. To address the challenges, we propose a tiny machine
learning-based Stackelberg game framework based on pruning techniques for
efficient UT migration in UAV metaverses. Specifically, we formulate a
multi-leader multi-follower Stackelberg model considering a new immersion
metric of UMUs in the utilities of UAVs. Then, we design a Tiny Multi-Agent
Deep Reinforcement Learning (Tiny MADRL) algorithm to obtain the tiny networks
representing the optimal game solution. Specifically, the actor-critic network
leverages the pruning techniques to reduce the number of network parameters and
achieve model size and computation reduction, allowing for efficient
implementation of Tiny MADRL. Numerical results demonstrate that our proposed
schemes have better performance than traditional schemes.
\\ ( https://arxiv.org/abs/2401.09680 ,  19925kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09789
Date: Thu, 18 Jan 2024 08:20:19 GMT   (3355kb)

Title: A Semantic Approach for Big Data Exploration in Industry 4.0
Authors: Idoia Berges, V\'ictor Julio Ram\'irez-Dur\'an, Arantza Illarramendi
Categories: cs.AI cs.DB
Comments: Published version of paper: Idoia Berges, V\'ictor Julio
  Ram\'irez-Dur\'an, Arantza Illarramendi: A Semantic Approach for Big Data
  Exploration in Industry 4.0. Big Data Res. 25: 100222 (2021). DOI:
  10.1016/j.bdr.2021.100222
Journal-ref: Big Data Res. 25: 100222 (2021)
DOI: 10.1016/j.bdr.2021.100222
\\
  The growing trends in automation, Internet of Things, big data and cloud
computing technologies have led to the fourth industrial revolution (Industry
4.0), where it is possible to visualize and identify patterns and insights,
which results in a better understanding of the data and can improve the
manufacturing process. However, many times, the task of data exploration
results difficult for manufacturing experts because they might be interested in
analyzing also data that does not appear in pre-designed visualizations and
therefore they must be assisted by Information Technology experts. In this
paper, we present a proposal materialized in a semantic-based visual query
system developed for a real Industry 4.0 scenario that allows domain experts to
explore and visualize data in a friendly way. The main novelty of the system is
the combined use that it makes of captured data that are semantically annotated
first, and a 2D customized digital representation of a machine that is also
linked with semantic descriptions. Those descriptions are expressed using terms
of an ontology, where, among others, the sensors that are used to capture
indicators about the performance of a machine that belongs to a Industry 4.0
scenario have been modeled. Moreover, this semantic description allows to:
formulate queries at a higher level of abstraction, provide customized
graphical visualizations of the results based on the format and nature of the
data, and download enriched data enabling further types of analysis.
\\ ( https://arxiv.org/abs/2401.09789 ,  3355kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09851
Date: Thu, 18 Jan 2024 10:05:52 GMT   (4303kb,D)

Title: Behavioral Simulation: Exploring A Possible Next Paradigm for Science
Authors: Cheng Wang, Chuwen Wang, Yu Zhao, Shirong Zeng, Wang Zhang, Ronghui
  Ning
Categories: cs.AI
\\
  Simulation technologies have been widely utilized in many scientific research
fields such as weather forecasting, fluid mechanics and biological populations.
It is the best tool to handle problems in complex systems, where closed-form
expressions are unavailable and the target distribution in the representation
space is too complex to be fully represented by a deep learning (DL) model. We
believe that the development of simulation technologies is consistent with
scientific paradigms. This paper induces the evolution of scientific paradigms
from the perspective of data, algorithms, and computational power. Building
upon this perspective, we divide simulation technologies into three stages
aligning with the emergence of new paradigms, and find that advanced simulation
technologies are typical instances of paradigms integration. Moreover, we
propose the concept of behavioral simulation (BS), specifically sophisticated
behavioral simulation (SBS), representing a higher degree of paradigms
integration based on foundation models to simulate complex social systems
involving sophisticated human strategies and behaviors. BS and further SBS are
designed to tackle challenges concerning the complex human system that
surpasses the capacity of traditional agent-based modeling simulation (ABMS),
which can be regarded as a possible next paradigm for science. Through this
work, we look forward to more powerful BS and SBS applications in scientific
research branches within social science.
\\ ( https://arxiv.org/abs/2401.09851 ,  4303kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09966
Date: Thu, 18 Jan 2024 13:28:44 GMT   (2321kb,D)

Title: Towards Generative Abstract Reasoning: Completing Raven's Progressive
  Matrix via Rule Abstraction and Selection
Authors: Fan Shi, Bin Li, Xiangyang Xue
Categories: cs.AI
\\
  Endowing machines with abstract reasoning ability has been a long-term
research topic in artificial intelligence. Raven's Progressive Matrix (RPM) is
widely used to probe abstract visual reasoning in machine intelligence, where
models need to understand the underlying rules and select the missing
bottom-right images out of candidate sets to complete image matrices. The
participators can display powerful reasoning ability by inferring the
underlying attribute-changing rules and imagining the missing images at
arbitrary positions. However, existing solvers can hardly manifest such an
ability in realistic RPM problems. In this paper, we propose a conditional
generative model to solve answer generation problems through Rule AbstractIon
and SElection (RAISE) in the latent space. RAISE encodes image attributes as
latent concepts and decomposes underlying rules into atomic rules by means of
concepts, which are abstracted as global learnable parameters. When generating
the answer, RAISE selects proper atomic rules out of the global knowledge set
for each concept and composes them into the integrated rule of an RPM. In most
configurations, RAISE outperforms the compared generative solvers in tasks of
generating bottom-right and arbitrary-position answers. We test RAISE in the
odd-one-out task and two held-out configurations to demonstrate how learning
decoupled latent concepts and atomic rules helps find the image breaking the
underlying rules and handle RPMs with unseen combinations of rules and
attributes.
\\ ( https://arxiv.org/abs/2401.09966 ,  2321kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10101
Date: Thu, 18 Jan 2024 16:10:07 GMT   (2825kb,D)

Title: Counterfactual Reasoning with Probabilistic Graphical Models for
  Analyzing Socioecological Systems
Authors: Rafael Caba\~nas, Ana D. Maldonado, Mar\'ia Morales, Pedro A.
  Aguilera, Antonio Salmer\'on
Categories: cs.AI math.PR stat.AP
Comments: 34 pages
\\
  Causal and counterfactual reasoning are emerging directions in data science
that allow us to reason about hypothetical scenarios. This is particularly
useful in domains where experimental data are usually not available. In the
context of environmental and ecological sciences, causality enables us, for
example, to predict how an ecosystem would respond to hypothetical
interventions. A structural causal model is a class of probabilistic graphical
models for causality, which, due to its intuitive nature, can be easily
understood by experts in multiple fields. However, certain queries, called
unidentifiable, cannot be calculated in an exact and precise manner. This paper
proposes applying a novel and recent technique for bounding unidentifiable
queries within the domain of socioecological systems. Our findings indicate
that traditional statistical analysis, including probabilistic graphical
models, can identify the influence between variables. However, such methods do
not offer insights into the nature of the relationship, specifically whether it
involves necessity or sufficiency. This is where counterfactual reasoning
becomes valuable.
\\ ( https://arxiv.org/abs/2401.10101 ,  2825kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09432
Date: Sun, 17 Dec 2023 17:57:50 GMT   (10261kb,D)

Title: RoleCraft-GLM: Advancing Personalized Role-Playing in Large Language
  Models
Authors: Meiling Tao, Xuechen Liang, Tianyu Shi, Lei Yu, Yiting Xie
Categories: cs.CL cs.AI cs.LG
\\
  This study presents RoleCraft-GLM, an innovative framework aimed at enhancing
personalized role-playing with Large Language Models (LLMs). RoleCraft-GLM
addresses the key issue of lacking personalized interactions in conversational
AI, and offers a solution with detailed and emotionally nuanced character
portrayals. We contribute a unique conversational dataset that shifts from
conventional celebrity-centric characters to diverse, non-celebrity personas,
thus enhancing the realism and complexity of language modeling interactions.
Additionally, our approach includes meticulous character development, ensuring
dialogues are both realistic and emotionally resonant. The effectiveness of
RoleCraft-GLM is validated through various case studies, highlighting its
versatility and skill in different scenarios. Our framework excels in
generating dialogues that accurately reflect characters' personality traits and
emotions, thereby boosting user engagement. In conclusion, RoleCraft-GLM marks
a significant leap in personalized AI interactions, and paves the way for more
authentic and immersive AI-assisted role-playing experiences by enabling more
nuanced and emotionally rich dialogues
\\ ( https://arxiv.org/abs/2401.09432 ,  10261kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09553
Date: Wed, 17 Jan 2024 19:11:30 GMT   (427kb)

Title: BERTologyNavigator: Advanced Question Answering with BERT-based
  Semantics
Authors: Shreya Rajpal (1,2), Ricardo Usbeck (1) ((1) Universit\"at Hamburg,
  Hamburg, Germany,(2) Vellore Institute of Technology, Vellore, Tamil Nadu,
  India)
Categories: cs.CL cs.AI
Comments: Accepted in Scholarly QALD Challenge @ ISWC 2023
ACM-class: I.2.4; I.2.7
Journal-ref: Joint Proceedings of Scholarly QALD 2023 and SemREC 2023
  co-located with 22nd International Semantic Web Conference ISWC 2023. Athens,
  Greece, November 6-10, 2023
\\
  The development and integration of knowledge graphs and language models has
significance in artificial intelligence and natural language processing. In
this study, we introduce the BERTologyNavigator -- a two-phased system that
combines relation extraction techniques and BERT embeddings to navigate the
relationships within the DBLP Knowledge Graph (KG). Our approach focuses on
extracting one-hop relations and labelled candidate pairs in the first phases.
This is followed by employing BERT's CLS embeddings and additional heuristics
for relation selection in the second phase. Our system reaches an F1 score of
0.2175 on the DBLP QuAD Final test dataset for Scholarly QALD and 0.98 F1 score
on the subset of the DBLP QuAD test dataset during the QA phase.
\\ ( https://arxiv.org/abs/2401.09553 ,  427kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09566
Date: Wed, 17 Jan 2024 19:43:43 GMT   (92kb,D)

Title: Aligning Large Language Models with Counterfactual DPO
Authors: Bradley Butcher
Categories: cs.CL cs.AI
\\
  Advancements in large language models (LLMs) have demonstrated remarkable
capabilities across a diverse range of applications. These models excel in
generating text completions that are contextually coherent and cover an
extensive array of subjects. However, the vast datasets required for their
training make aligning response styles during the pretraining and instruction
tuning phases challenging. Consequently, an additional alignment phase is
typically employed, wherein the model is further trained with human preference
data to better align its outputs with human expectations. While this process
doesn't introduce new capabilities per se, it does accentuate generation styles
innate to the model. This paper explores the utilization of counterfactual
prompting within the framework of Direct Preference Optimization (DPO) to align
the model's style without relying on human intervention. We demonstrate that
this method effectively instils desirable behaviour, mitigates undesirable
ones, and encourages the model to disregard inappropriate instructions. Our
findings suggest that counterfactual prompting with DPO presents a low-resource
way to fine-tune LLMs to meet the demands for responsible and ethically aligned
AI systems.
\\ ( https://arxiv.org/abs/2401.09566 ,  92kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09615
Date: Wed, 17 Jan 2024 21:55:15 GMT   (52kb)

Title: Learning Shortcuts: On the Misleading Promise of NLU in Language Models
Authors: Geetanjali Bihani, Julia Taylor Rayz
Categories: cs.CL cs.AI
Comments: Accepted at HICSS-SDPS 2024
\\
  The advent of large language models (LLMs) has enabled significant
performance gains in the field of natural language processing. However, recent
studies have found that LLMs often resort to shortcuts when performing tasks,
creating an illusion of enhanced performance while lacking generalizability in
their decision rules. This phenomenon introduces challenges in accurately
assessing natural language understanding in LLMs. Our paper provides a concise
survey of relevant research in this area and puts forth a perspective on the
implications of shortcut learning in the evaluation of language models,
specifically for NLU tasks. This paper urges more research efforts to be put
towards deepening our comprehension of shortcut learning, contributing to the
development of more robust language models, and raising the standards of NLU
evaluation in real-world scenarios.
\\ ( https://arxiv.org/abs/2401.09615 ,  52kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09699
Date: Thu, 18 Jan 2024 03:09:06 GMT   (983kb,D)

Title: Curriculum Recommendations Using Transformer Base Model with InfoNCE
  Loss And Language Switching Method
Authors: Xiaonan Xu, Bin Yuan, Yongyao Mo, Tianbo Song, Shulin Li
Categories: cs.CL cs.AI
Comments: 4pages, 2 figures, ICAICA2023
MSC-class: 68T50
\\
  The Curriculum Recommendations paradigm is dedicated to fostering learning
equality within the ever-evolving realms of educational technology and
curriculum development. In acknowledging the inherent obstacles posed by
existing methodologies, such as content conflicts and disruptions from language
translation, this paradigm aims to confront and overcome these challenges.
Notably, it addresses content conflicts and disruptions introduced by language
translation, hindrances that can impede the creation of an all-encompassing and
personalized learning experience. The paradigm's objective is to cultivate an
educational environment that not only embraces diversity but also customizes
learning experiences to suit the distinct needs of each learner. To overcome
these challenges, our approach builds upon notable contributions in curriculum
development and personalized learning, introducing three key innovations. These
include the integration of Transformer Base Model to enhance computational
efficiency, the implementation of InfoNCE Loss for accurate content-topic
matching, and the adoption of a language switching strategy to alleviate
translation-related ambiguities. Together, these innovations aim to
collectively tackle inherent challenges and contribute to forging a more
equitable and effective learning journey for a diverse range of learners.
Competitive cross-validation scores underscore the efficacy of
sentence-transformers/LaBSE, achieving 0.66314, showcasing our methodology's
effectiveness in diverse linguistic nuances for content alignment prediction.
Index Terms-Curriculum Recommendation, Transformer model with InfoNCE Loss,
Language Switching.
\\ ( https://arxiv.org/abs/2401.09699 ,  983kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09758
Date: Thu, 18 Jan 2024 07:18:03 GMT   (3738kb,D)

Title: Resolving Regular Polysemy in Named Entities
Authors: Shu-Kai Hsieh, Yu-Hsiang Tseng, Hsin-Yu Chou, Ching-Wen Yang, Yu-Yun
  Chang
Categories: cs.CL
\\
  Word sense disambiguation primarily addresses the lexical ambiguity of common
words based on a predefined sense inventory. Conversely, proper names are
usually considered to denote an ad-hoc real-world referent. Once the reference
is decided, the ambiguity is purportedly resolved. However, proper names also
exhibit ambiguities through appellativization, i.e., they act like common words
and may denote different aspects of their referents. We proposed to address the
ambiguities of proper names through the light of regular polysemy, which we
formalized as dot objects. This paper introduces a combined word sense
disambiguation (WSD) model for disambiguating common words against Chinese
Wordnet (CWN) and proper names as dot objects. The model leverages the
flexibility of a gloss-based model architecture, which takes advantage of the
glosses and example sentences of CWN. We show that the model achieves
competitive results on both common and proper nouns, even on a relatively
sparse sense dataset. Aside from being a performant WSD tool, the model further
facilitates the future development of the lexical resource.
\\ ( https://arxiv.org/abs/2401.09758 ,  3738kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09760
Date: Thu, 18 Jan 2024 07:23:51 GMT   (26kb)

Title: A Comparative Study on Annotation Quality of Crowdsourcing and LLM via
  Label Aggregation
Authors: Jiyi Li
Categories: cs.CL cs.HC
Comments: Accepted in ICASSP 2024
\\
  Whether Large Language Models (LLMs) can outperform crowdsourcing on the data
annotation task is attracting interest recently. Some works verified this issue
with the average performance of individual crowd workers and LLM workers on
some specific NLP tasks by collecting new datasets. However, on the one hand,
existing datasets for the studies of annotation quality in crowdsourcing are
not yet utilized in such evaluations, which potentially provide reliable
evaluations from a different viewpoint. On the other hand, the quality of these
aggregated labels is crucial because, when utilizing crowdsourcing, the
estimated labels aggregated from multiple crowd labels to the same instances
are the eventually collected labels. Therefore, in this paper, we first
investigate which existing crowdsourcing datasets can be used for a comparative
study and create a benchmark. We then compare the quality between individual
crowd labels and LLM labels and make the evaluations on the aggregated labels.
In addition, we propose a Crowd-LLM hybrid label aggregation method and verify
the performance. We find that adding LLM labels from good LLMs to existing
crowdsourcing datasets can enhance the quality of the aggregated labels of the
datasets, which is also higher than the quality of LLM labels themselves.
\\ ( https://arxiv.org/abs/2401.09760 ,  26kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09775
Date: Thu, 18 Jan 2024 07:52:12 GMT   (617kb,D)

Title: Controllable Decontextualization of Yes/No Question and Answers into
  Factual Statements
Authors: Lingbo Mo, Besnik Fetahu, Oleg Rokhlenko, Shervin Malmasi
Categories: cs.CL
Comments: Accepted at ECIR 2024
\\
  Yes/No or polar questions represent one of the main linguistic question
categories. They consist of a main interrogative clause, for which the answer
is binary (assertion or negation). Polar questions and answers (PQA) represent
a valuable knowledge resource present in many community and other curated QA
sources, such as forums or e-commerce applications. Using answers to polar
questions alone in other contexts is not trivial. Answers are contextualized,
and presume that the interrogative question clause and any shared knowledge
between the asker and answerer are provided.
  We address the problem of controllable rewriting of answers to polar
questions into decontextualized and succinct factual statements. We propose a
Transformer sequence to sequence model that utilizes soft-constraints to ensure
controllable rewriting, such that the output statement is semantically
equivalent to its PQA input. Evaluation on three separate PQA datasets as
measured through automated and human evaluation metrics show that our proposed
approach achieves the best performance when compared to existing baselines.
\\ ( https://arxiv.org/abs/2401.09775 ,  617kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09783
Date: Thu, 18 Jan 2024 08:05:45 GMT   (1213kb,D)

Title: Leveraging Biases in Large Language Models: "bias-kNN'' for Effective
  Few-Shot Learning
Authors: Yong Zhang, Hanzhang Li, Zhitao Li, Ning Cheng, Ming Li, Jing Xiao,
  Jianzong Wang
Categories: cs.CL
Comments: Accepted by the 49th IEEE International Conference on Acoustics,
  Speech, and Signal Processing (ICASSP 2024)
\\
  Large Language Models (LLMs) have shown significant promise in various
applications, including zero-shot and few-shot learning. However, their
performance can be hampered by inherent biases. Instead of traditionally sought
methods that aim to minimize or correct these biases, this study introduces a
novel methodology named ``bias-kNN''. This approach capitalizes on the biased
outputs, harnessing them as primary features for kNN and supplementing with
gold labels. Our comprehensive evaluations, spanning diverse domain text
classification datasets and different GPT-2 model sizes, indicate the
adaptability and efficacy of the ``bias-kNN'' method. Remarkably, this approach
not only outperforms conventional in-context learning in few-shot scenarios but
also demonstrates robustness across a spectrum of samples, templates and
verbalizers. This study, therefore, presents a unique perspective on harnessing
biases, transforming them into assets for enhanced model performance.
\\ ( https://arxiv.org/abs/2401.09783 ,  1213kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09785
Date: Thu, 18 Jan 2024 08:09:27 GMT   (96kb,D)

Title: Instant Answering in E-Commerce Buyer-Seller Messaging
Authors: Besnik Fetahu, Tejas Mehta, Qun Song, Nikhita Vedula, Oleg Rokhlenko,
  Shervin Malmasi
Categories: cs.CL
Comments: Accepted at ECIR 2024
\\
  E-commerce customers frequently seek detailed product information for
purchase decisions, commonly contacting sellers directly with extended queries.
This manual response requirement imposes additional costs and disrupts buyer's
shopping experience with response time fluctuations ranging from hours to days.
We seek to automate buyer inquiries to sellers in a leading e-commerce store
using a domain-specific federated Question Answering (QA) system. The main
challenge is adapting current QA systems, designed for single questions, to
address detailed customer queries. We address this with a low-latency,
sequence-to-sequence approach, MESSAGE-TO-QUESTION ( M2Q ). It reformulates
buyer messages into succinct questions by identifying and extracting the most
salient information from a message. Evaluation against baselines shows that M2Q
yields relative increases of 757% in question understanding, and 1,746% in
answering rate from the federated QA system. Live deployment shows that
automatic answering saves sellers from manually responding to millions of
messages per year, and also accelerates customer purchase decisions by
eliminating the need for buyers to wait for a reply
\\ ( https://arxiv.org/abs/2401.09785 ,  96kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09798
Date: Thu, 18 Jan 2024 08:36:54 GMT   (47kb)

Title: All in How You Ask for It: Simple Black-Box Method for Jailbreak Attacks
Authors: Kazuhiro Takemoto
Categories: cs.CL cs.AI cs.CY
Comments: 11 pages, 3 figures, 2 tables
\\
  Large Language Models (LLMs) like ChatGPT face `jailbreak' challenges, where
safeguards are bypassed to produce ethically harmful prompts. This study
introduces a simple black-box method to effectively generate jailbreak prompts,
overcoming the limitations of high complexity and computational costs
associated with existing methods. The proposed technique iteratively rewrites
harmful prompts into non-harmful expressions using the target LLM itself, based
on the hypothesis that LLMs can directly sample safeguard-bypassing
expressions. Demonstrated through experiments with ChatGPT (GPT-3.5 and GPT-4)
and Gemini-Pro, this method achieved an attack success rate of over 80% within
an average of 5 iterations and remained effective despite model updates. The
jailbreak prompts generated were naturally-worded and concise, suggesting they
are less detectable. The results indicate that creating effective jailbreak
prompts is simpler than previously considered, and black-box jailbreak attacks
pose a more serious security threat.
\\ ( https://arxiv.org/abs/2401.09798 ,  47kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09815
Date: Thu, 18 Jan 2024 09:13:59 GMT   (8135kb,D)

Title: Simple and effective data augmentation for compositional generalization
Authors: Yuekun Yao and Alexander Koller
Categories: cs.CL
\\
  Compositional generalization, the ability to predict complex meanings from
training on simpler sentences, poses challenges for powerful pretrained seq2seq
models. In this paper, we show that data augmentation methods that sample MRs
and backtranslate them can be effective for compositional generalization, but
only if we sample from the right distribution. Remarkably, sampling from a
uniform distribution performs almost as well as sampling from the test
distribution, and greatly outperforms earlier methods that sampled from the
training distribution. We further conduct experiments to investigate the reason
why this happens and where the benefit of such data augmentation methods come
from.
\\ ( https://arxiv.org/abs/2401.09815 ,  8135kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09839
Date: Thu, 18 Jan 2024 09:54:18 GMT   (663kb,D)

Title: MatSciRE: Leveraging Pointer Networks to Automate Entity and Relation
  Extraction for Material Science Knowledge-base Construction
Authors: Ankan Mullick, Akash Ghosh, G Sai Chaitanya, Samir Ghui, Tapas Nayak,
  Seung-Cheol Lee, Satadeep Bhattacharjee, Pawan Goyal
Categories: cs.CL cs.CE cs.IR
Journal-ref: Computational Material Science 2023 (Elsevier)
DOI: 10.1016/j.commatsci.2023.112659
\\
  Material science literature is a rich source of factual information about
various categories of entities (like materials and compositions) and various
relations between these entities, such as conductivity, voltage, etc.
Automatically extracting this information to generate a material science
knowledge base is a challenging task. In this paper, we propose MatSciRE
(Material Science Relation Extractor), a Pointer Network-based encoder-decoder
framework, to jointly extract entities and relations from material science
articles as a triplet ($entity1, relation, entity2$). Specifically, we target
the battery materials and identify five relations to work on - conductivity,
coulombic efficiency, capacity, voltage, and energy. Our proposed approach
achieved a much better F1-score (0.771) than a previous attempt using
ChemDataExtractor (0.716). The overall graphical framework of MatSciRE is shown
in Fig 1. The material information is extracted from material science
literature in the form of entity-relation triplets using MatSciRE.
\\ ( https://arxiv.org/abs/2401.09839 ,  663kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09899
Date: Thu, 18 Jan 2024 11:24:30 GMT   (4539kb,D)

Title: Meme-ingful Analysis: Enhanced Understanding of Cyberbullying in Memes
  Through Multimodal Explanations
Authors: Prince Jha, Krishanu Maity, Raghav Jain, Apoorv Verma, Sriparna Saha,
  Pushpak Bhattacharyya
Categories: cs.CL
Comments: EACL2024
\\
  Internet memes have gained significant influence in communicating political,
psychological, and sociocultural ideas. While memes are often humorous, there
has been a rise in the use of memes for trolling and cyberbullying. Although a
wide variety of effective deep learning-based models have been developed for
detecting offensive multimodal memes, only a few works have been done on
explainability aspect. Recent laws like "right to explanations" of General Data
Protection Regulation, have spurred research in developing interpretable models
rather than only focusing on performance. Motivated by this, we introduce {\em
MultiBully-Ex}, the first benchmark dataset for multimodal explanation from
code-mixed cyberbullying memes. Here, both visual and textual modalities are
highlighted to explain why a given meme is cyberbullying. A Contrastive
Language-Image Pretraining (CLIP) projection-based multimodal shared-private
multitask approach has been proposed for visual and textual explanation of a
meme. Experimental results demonstrate that training with multimodal
explanations improves performance in generating textual justifications and more
accurately identifying the visual evidence supporting a decision with reliable
performance improvements.
\\ ( https://arxiv.org/abs/2401.09899 ,  4539kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09967
Date: Thu, 18 Jan 2024 13:31:24 GMT   (2568kb,D)

Title: Sketch-Guided Constrained Decoding for Boosting Blackbox Large Language
  Models without Logit Access
Authors: Saibo Geng, Berkay D\"oner, Chris Wendler, Martin Josifoski, Robert
  West
Categories: cs.CL
\\
  Constrained decoding, a technique for enforcing constraints on language model
outputs, offers a way to control text generation without retraining or
architectural modifications. Its application is, however, typically restricted
to models that give users access to next-token distributions (usually via
softmax logits), which poses a limitation with blackbox large language models
(LLMs). This paper introduces sketch-guided constrained decoding (SGCD), a
novel approach to constrained decoding for blackbox LLMs, which operates
without access to the logits of the blackbox LLM. SGCD utilizes a locally
hosted auxiliary model to refine the output of an unconstrained blackbox LLM,
effectively treating this initial output as a "sketch" for further elaboration.
This approach is complementary to traditional logit-based techniques and
enables the application of constrained decoding in settings where full model
transparency is unavailable. We demonstrate the efficacy of SGCD through
experiments in closed information extraction and constituency parsing, showing
how it enhances the utility and flexibility of blackbox LLMs for complex NLP
tasks.
\\ ( https://arxiv.org/abs/2401.09967 ,  2568kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09972
Date: Thu, 18 Jan 2024 13:41:08 GMT   (8865kb,D)

Title: Better Explain Transformers by Illuminating Important Information
Authors: Linxin Song, Yan Cui, Ao Luo, Freddy Lecue, Irene Li
Categories: cs.CL
\\
  Transformer-based models excel in various natural language processing (NLP)
tasks, attracting countless efforts to explain their inner workings. Prior
methods explain Transformers by focusing on the raw gradient and attention as
token attribution scores, where non-relevant information is often considered
during explanation computation, resulting in confusing results. In this work,
we propose highlighting the important information and eliminating irrelevant
information by a refined information flow on top of the layer-wise relevance
propagation (LRP) method. Specifically, we consider identifying syntactic and
positional heads as important attention heads and focus on the relevance
obtained from these important heads. Experimental results demonstrate that
irrelevant information does distort output attribution scores and then should
be masked during explanation computation. Compared to eight baselines on both
classification and question-answering datasets, our method consistently
outperforms with over 3\% to 33\% improvement on explanation metrics, providing
superior explanation performance. Our anonymous code repository is available
at: https://github.com/LinxinS97/Mask-LRP
\\ ( https://arxiv.org/abs/2401.09972 ,  8865kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09984
Date: Thu, 18 Jan 2024 13:58:10 GMT   (337kb,D)

Title: Gradable ChatGPT Translation Evaluation
Authors: Hui Jiao, Bei Peng, Lu Zong, Xiaojun Zhang, Xinwei Li
Categories: cs.CL
Comments: Under review in the journal Procesamiento del Lenguaje Natural
\\
  ChatGPT, as a language model based on large-scale pre-training, has exerted a
profound influence on the domain of machine translation. In ChatGPT, a "Prompt"
refers to a segment of text or instruction employed to steer the model towards
generating a specific category of response. The design of the translation
prompt emerges as a key aspect that can wield influence over factors such as
the style, precision and accuracy of the translation to a certain extent.
However, there is a lack of a common standard and methodology on how to design
and select a translation prompt. Accordingly, this paper proposes a generic
taxonomy, which defines gradable translation prompts in terms of expression
type, translation style, POS information and explicit statement, thus
facilitating the construction of prompts endowed with distinct attributes
tailored for various translation tasks. Specific experiments and cases are
selected to validate and illustrate the effectiveness of the method.
\\ ( https://arxiv.org/abs/2401.09984 ,  337kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10002
Date: Thu, 18 Jan 2024 14:17:40 GMT   (584kb,D)

Title: Distantly Supervised Morpho-Syntactic Model for Relation Extraction
Authors: Nicolas Gutehrl\'e, Iana Atanassova
Categories: cs.CL
Comments: Preprint
\\
  The task of Information Extraction (IE) involves automatically converting
unstructured textual content into structured data. Most research in this field
concentrates on extracting all facts or a specific set of relationships from
documents. In this paper, we present a method for the extraction and
categorisation of an unrestricted set of relationships from text. Our method
relies on morpho-syntactic extraction patterns obtained by a distant
supervision method, and creates Syntactic and Semantic Indices to extract and
classify candidate graphs. We evaluate our approach on six datasets built on
Wikidata and Wikipedia. The evaluation shows that our approach can achieve
Precision scores of up to 0.85, but with lower Recall and F1 scores. Our
approach allows to quickly create rule-based systems for Information Extraction
and to build annotated datasets to train machine-learning and deep-learning
based classifiers.
\\ ( https://arxiv.org/abs/2401.10002 ,  584kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10015
Date: Thu, 18 Jan 2024 14:33:01 GMT   (966kb,D)

Title: Towards Hierarchical Spoken Language Dysfluency Modeling
Authors: Jiachen Lian and Gopala Anumanchipalli
Categories: cs.CL eess.AS
Comments: 2024 EACL Long (main conference). arXiv admin note: substantial text
  overlap with arXiv:2312.12810
\\
  Speech dysfluency modeling is the bottleneck for both speech therapy and
language learning. However, there is no AI solution to systematically tackle
this problem. We first propose to define the concept of dysfluent speech and
dysfluent speech modeling. We then present Hierarchical Unconstrained
Dysfluency Modeling (H-UDM) approach that addresses both dysfluency
transcription and detection to eliminate the need for extensive manual
annotation. Furthermore, we introduce a simulated dysfluent dataset called
VCTK++ to enhance the capabilities of H-UDM in phonetic transcription. Our
experimental results demonstrate the effectiveness and robustness of our
proposed methods in both transcription and detection tasks.
\\ ( https://arxiv.org/abs/2401.10015 ,  966kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10016
Date: Thu, 18 Jan 2024 14:34:49 GMT   (113kb)

Title: Gender Bias in Machine Translation and The Era of Large Language Models
Authors: Eva Vanmassenhove
Categories: cs.CL cs.AI cs.CY
Comments: 24 pages
\\
  This chapter examines the role of Machine Translation in perpetuating gender
bias, highlighting the challenges posed by cross-linguistic settings and
statistical dependencies. A comprehensive overview of relevant existing work
related to gender bias in both conventional Neural Machine Translation
approaches and Generative Pretrained Transformer models employed as Machine
Translation systems is provided. Through an experiment using ChatGPT (based on
GPT-3.5) in an English-Italian translation context, we further assess ChatGPT's
current capacity to address gender bias. The findings emphasize the ongoing
need for advancements in mitigating bias in Machine Translation systems and
underscore the importance of fostering fairness and inclusivity in language
technologies.
\\ ( https://arxiv.org/abs/2401.10016 ,  113kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10019
Date: Thu, 18 Jan 2024 14:40:46 GMT   (998kb,D)

Title: R-Judge: Benchmarking Safety Risk Awareness for LLM Agents
Authors: Tongxin Yuan, Zhiwei He, Lingzhong Dong, Yiming Wang, Ruijie Zhao,
  Tian Xia, Lizhen Xu, Binglin Zhou, Fangqi Li, Zhuosheng Zhang, Rui Wang,
  Gongshen Liu
Categories: cs.CL cs.AI
\\
  Large language models (LLMs) have exhibited great potential in autonomously
completing tasks across real-world applications. Despite this, these LLM agents
introduce unexpected safety risks when operating in interactive environments.
Instead of centering on LLM-generated content safety in most prior studies,
this work addresses the imperative need for benchmarking the behavioral safety
of LLM agents within diverse environments. We introduce R-Judge, a benchmark
crafted to evaluate the proficiency of LLMs in judging safety risks given agent
interaction records. R-Judge comprises 162 agent interaction records,
encompassing 27 key risk scenarios among 7 application categories and 10 risk
types. It incorporates human consensus on safety with annotated safety risk
labels and high-quality risk descriptions. Utilizing R-Judge, we conduct a
comprehensive evaluation of 8 prominent LLMs commonly employed as the backbone
for agents. The best-performing model, GPT-4, achieves 72.29% in contrast to
the human score of 89.38%, showing considerable room for enhancing the risk
awareness of LLMs. Notably, leveraging risk descriptions as environment
feedback significantly improves model performance, revealing the importance of
salient safety risk feedback. Furthermore, we design an effective chain of
safety analysis technique to help the judgment of safety risks and conduct an
in-depth case study to facilitate future research. R-Judge is publicly
available at https://github.com/Lordog/R-Judge.
\\ ( https://arxiv.org/abs/2401.10019 ,  998kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10020
Date: Thu, 18 Jan 2024 14:43:47 GMT   (402kb,D)

Title: Self-Rewarding Language Models
Authors: Weizhe Yuan, Richard Yuanzhe Pang, Kyunghyun Cho, Sainbayar
  Sukhbaatar, Jing Xu, Jason Weston
Categories: cs.CL cs.AI
\\
  We posit that to achieve superhuman agents, future models require superhuman
feedback in order to provide an adequate training signal. Current approaches
commonly train reward models from human preferences, which may then be
bottlenecked by human performance level, and secondly these separate frozen
reward models cannot then learn to improve during LLM training. In this work,
we study Self-Rewarding Language Models, where the language model itself is
used via LLM-as-a-Judge prompting to provide its own rewards during training.
We show that during Iterative DPO training that not only does instruction
following ability improve, but also the ability to provide high-quality rewards
to itself. Fine-tuning Llama 2 70B on three iterations of our approach yields a
model that outperforms many existing systems on the AlpacaEval 2.0 leaderboard,
including Claude 2, Gemini Pro, and GPT-4 0613. While only a preliminary study,
this work opens the door to the possibility of models that can continually
improve in both axes.
\\ ( https://arxiv.org/abs/2401.10020 ,  402kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10030
Date: Thu, 18 Jan 2024 14:56:23 GMT   (257kb,D)

Title: Framing Analysis of Health-Related Narratives: Conspiracy versus
  Mainstream Media
Authors: Markus Reiter-Haas, Beate Kl\"osch, Markus Hadler, Elisabeth Lex
Categories: cs.CL cs.CY
\\
  Understanding how online media frame issues is crucial due to their impact on
public opinion. Research on framing using natural language processing
techniques mainly focuses on specific content features in messages and neglects
their narrative elements. Also, the distinction between framing in different
sources remains an understudied problem. We address those issues and
investigate how the framing of health-related topics, such as COVID-19 and
other diseases, differs between conspiracy and mainstream websites. We
incorporate narrative information into the framing analysis by introducing a
novel frame extraction approach based on semantic graphs. We find that
health-related narratives in conspiracy media are predominantly framed in terms
of beliefs, while mainstream media tend to present them in terms of science. We
hope our work offers new ways for a more nuanced frame analysis.
\\ ( https://arxiv.org/abs/2401.10030 ,  257kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10040
Date: Thu, 18 Jan 2024 15:04:55 GMT   (8851kb,D)

Title: Large Language Models for Scientific Information Extraction: An
  Empirical Study for Virology
Authors: Mahsa Shamsabadi and Jennifer D'Souza and S\"oren Auer
Categories: cs.CL cs.AI cs.DL cs.IT math.IT
Comments: 8 pages, 6 figures, Accepted as Findings of the ACL: EACL 2024
\\
  In this paper, we champion the use of structured and semantic content
representation of discourse-based scholarly communication, inspired by tools
like Wikipedia infoboxes or structured Amazon product descriptions. These
representations provide users with a concise overview, aiding scientists in
navigating the dense academic landscape. Our novel automated approach leverages
the robust text generation capabilities of LLMs to produce structured scholarly
contribution summaries, offering both a practical solution and insights into
LLMs' emergent abilities.
  For LLMs, the prime focus is on improving their general intelligence as
conversational agents. We argue that these models can also be applied
effectively in information extraction (IE), specifically in complex IE tasks
within terse domains like Science. This paradigm shift replaces the traditional
modular, pipelined machine learning approach with a simpler objective expressed
through instructions. Our results show that finetuned FLAN-T5 with 1000x fewer
parameters than the state-of-the-art GPT-davinci is competitive for the task.
\\ ( https://arxiv.org/abs/2401.10040 ,  8851kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10045
Date: Thu, 18 Jan 2024 15:08:58 GMT   (343kb,D)

Title: Antonym vs Synonym Distinction using InterlaCed Encoder NETworks
  (ICE-NET)
Authors: Muhammad Asif Ali, Yan Hu, Jianbin Qin, Di Wang
Categories: cs.CL
\\
  Antonyms vs synonyms distinction is a core challenge in lexico-semantic
analysis and automated lexical resource construction. These pairs share a
similar distributional context which makes it harder to distinguish them.
Leading research in this regard attempts to capture the properties of the
relation pairs, i.e., symmetry, transitivity, and trans-transitivity. However,
the inability of existing research to appropriately model the relation-specific
properties limits their end performance. In this paper, we propose InterlaCed
Encoder NETworks (i.e., ICE-NET) for antonym vs synonym distinction, that aim
to capture and model the relation-specific properties of the antonyms and
synonyms pairs in order to perform the classification task in a
performance-enhanced manner. Experimental evaluation using the benchmark
datasets shows that ICE-NET outperforms the existing research by a relative
score of upto 1.8% in F1-measure. We release the codes for ICE-NET at
https://github.com/asif6827/ICENET.
\\ ( https://arxiv.org/abs/2401.10045 ,  343kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10065
Date: Thu, 18 Jan 2024 15:32:24 GMT   (9152kb,D)

Title: Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs
Authors: Haritz Puerto, Martin Tutek, Somak Aditya, Xiaodan Zhu, Iryna Gurevych
Categories: cs.CL
Comments: Code, prompt templates, prompts, and outputs are publicly available
  at https://github.com/UKPLab/arxiv2024-conditional-reasoning-llms
\\
  Reasoning is a fundamental component for achieving language understanding.
Among the multiple types of reasoning, conditional reasoning, the ability to
draw different conclusions depending on some condition, has been understudied
in large language models (LLMs). Recent prompting methods, such as chain of
thought, have significantly improved LLMs on reasoning tasks. Nevertheless,
there is still little understanding of what triggers reasoning abilities in
LLMs. We hypothesize that code prompts can trigger conditional reasoning in
LLMs trained on text and code. We propose a chain of prompts that transforms a
natural language problem into code and prompts the LLM with the generated code.
Our experiments find that code prompts exhibit a performance boost between 2.6
and 7.7 points on GPT 3.5 across multiple datasets requiring conditional
reasoning. We then conduct experiments to discover how code prompts elicit
conditional reasoning abilities and through which features. We observe that
prompts need to contain natural language text accompanied by high-quality code
that closely represents the semantics of the instance text. Furthermore, we
show that code prompts are more efficient, requiring fewer demonstrations, and
that they trigger superior state tracking of variables or key entities.
\\ ( https://arxiv.org/abs/2401.10065 ,  9152kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10070
Date: Thu, 18 Jan 2024 15:39:38 GMT   (551kb,D)

Title: Communication-Efficient Personalized Federated Learning for
  Speech-to-Text Tasks
Authors: Yichao Du, Zhirui Zhang, Linan Yue, Xu Huang, Yuqing Zhang, Tong Xu,
  Linli Xu and Enhong Chen
Categories: cs.CL cs.SD eess.AS
Comments: ICASSP 2024
\\
  To protect privacy and meet legal regulations, federated learning (FL) has
gained significant attention for training speech-to-text (S2T) systems,
including automatic speech recognition (ASR) and speech translation (ST).
However, the commonly used FL approach (i.e., \textsc{FedAvg}) in S2T tasks
typically suffers from extensive communication overhead due to multi-round
interactions based on the whole model and performance degradation caused by
data heterogeneity among clients.To address these issues, we propose a
personalized federated S2T framework that introduces \textsc{FedLoRA}, a
lightweight LoRA module for client-side tuning and interaction with the server
to minimize communication overhead, and \textsc{FedMem}, a global model
equipped with a $k$-nearest-neighbor ($k$NN) classifier that captures
client-specific distributional shifts to achieve personalization and overcome
data heterogeneity. Extensive experiments based on Conformer and Whisper
backbone models on CoVoST and GigaSpeech benchmarks show that our approach
significantly reduces the communication overhead on all S2T tasks and
effectively personalizes the global model to overcome data heterogeneity.
\\ ( https://arxiv.org/abs/2401.10070 ,  551kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10091
Date: Thu, 18 Jan 2024 15:59:42 GMT   (611kb)

Title: Power in Numbers: Robust reading comprehension by finetuning with four
  adversarial sentences per example
Authors: Ariel Marcus
Categories: cs.CL
\\
  Recent models have achieved human level performance on the Stanford Question
Answering Dataset when using F1 scores to evaluate the reading comprehension
task. Yet, teaching machines to comprehend text has not been solved in the
general case. By appending one adversarial sentence to the context paragraph,
past research has shown that the F1 scores from reading comprehension models
drop almost in half. In this paper, I replicate past adversarial research with
a new model, ELECTRA-Small, and demonstrate that the new model's F1 score drops
from 83.9% to 29.2%. To improve ELECTRA-Small's resistance to this attack, I
finetune the model on SQuAD v1.1 training examples with one to five adversarial
sentences appended to the context paragraph. Like past research, I find that
the finetuned model on one adversarial sentence does not generalize well across
evaluation datasets. However, when finetuned on four or five adversarial
sentences the model attains an F1 score of more than 70% on most evaluation
datasets with multiple appended and prepended adversarial sentences. The
results suggest that with enough examples we can make models robust to
adversarial attacks.
\\ ( https://arxiv.org/abs/2401.10091 ,  611kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10111
Date: Thu, 18 Jan 2024 16:27:18 GMT   (8187kb,D)

Title: Marrying Adapters and Mixup to Efficiently Enhance the Adversarial
  Robustness of Pre-Trained Language Models for Text Classification
Authors: Tuc Nguyen and Thai Le
Categories: cs.CL
Comments: 10 pages and 2 figures
\\
  Existing works show that augmenting training data of neural networks using
both clean and adversarial examples can enhance their generalizability under
adversarial attacks. However, this training approach often leads to performance
degradation on clean inputs. Additionally, it requires frequent re-training of
the entire model to account for new attack types, resulting in significant and
costly computations. Such limitations make adversarial training mechanisms less
practical, particularly for complex Pre-trained Language Models (PLMs) with
millions or even billions of parameters. To overcome these challenges while
still harnessing the theoretical benefits of adversarial training, this study
combines two concepts: (1) adapters, which enable parameter-efficient
fine-tuning, and (2) Mixup, which train NNs via convex combinations of pairs
data pairs. Intuitively, we propose to fine-tune PLMs through convex
combinations of non-data pairs of fine-tuned adapters, one trained with clean
and another trained with adversarial examples. Our experiments show that the
proposed method achieves the best trade-off between training efficiency and
predictive performance, both with and without attacks compared to other
baselines on a variety of downstream tasks.
\\ ( https://arxiv.org/abs/2401.10111 ,  8187kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10186
Date: Thu, 18 Jan 2024 18:15:46 GMT   (887kb,D)

Title: Beyond Reference-Based Metrics: Analyzing Behaviors of Open LLMs on
  Data-to-Text Generation
Authors: Zden\v{e}k Kasner, Ond\v{r}ej Du\v{s}ek
Categories: cs.CL
Comments: 26 pages
\\
  We investigate to which extent open large language models (LLMs) can generate
coherent and relevant text from structured data. To prevent bias from
benchmarks leaked into LLM training data, we collect Quintd-1: an ad-hoc
benchmark for five data-to-text (D2T) generation tasks, consisting of
structured data records in standard formats gathered from public APIs. We
leverage reference-free evaluation metrics and LLMs' in-context learning
capabilities, allowing us to test the models with no human-written references.
Our evaluation focuses on annotating semantic accuracy errors on token-level,
combining human annotators and a metric based on GPT-4. Our systematic
examination of the models' behavior across domains and tasks suggests that
state-of-the-art open LLMs with 7B parameters can generate fluent and coherent
text from various standard data formats in zero-shot settings. However, we also
show that semantic accuracy of the outputs remains a major issue: on our
benchmark, 80% of outputs of open LLMs contain a semantic error according to
human annotators (91% according to GPT-4). Our code, data, and model outputs
are available at https://d2t-llm.github.io.
\\ ( https://arxiv.org/abs/2401.10186 ,  887kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10189
Date: Thu, 18 Jan 2024 18:20:15 GMT   (147kb,D)

Title: Chem-FINESE: Validating Fine-Grained Few-shot Entity Extraction through
  Text Reconstruction
Authors: Qingyun Wang, Zixuan Zhang, Hongxiang Li, Xuan Liu, Jiawei Han, Heng
  Ji, Huimin Zhao
Categories: cs.CL cs.AI cs.LG
Comments: 16 pages. Accepted by Findings of the Association for Computational
  Linguistics: EACL 2024. Code and resources are available at
  https://github.com/EagleW/Chem-FINESE
\\
  Fine-grained few-shot entity extraction in the chemical domain faces two
unique challenges. First, compared with entity extraction tasks in the general
domain, sentences from chemical papers usually contain more entities. Moreover,
entity extraction models usually have difficulty extracting entities of
long-tailed types. In this paper, we propose Chem-FINESE, a novel
sequence-to-sequence (seq2seq) based few-shot entity extraction approach, to
address these two challenges. Our Chem-FINESE has two components: a seq2seq
entity extractor to extract named entities from the input sentence and a
seq2seq self-validation module to reconstruct the original input sentence from
extracted entities. Inspired by the fact that a good entity extraction system
needs to extract entities faithfully, our new self-validation module leverages
entity extraction results to reconstruct the original input sentence. Besides,
we design a new contrastive loss to reduce excessive copying during the
extraction process. Finally, we release ChemNER+, a new fine-grained chemical
entity extraction dataset that is annotated by domain experts with the ChemNER
schema. Experiments in few-shot settings with both ChemNER+ and CHEMET datasets
show that our newly proposed framework has contributed up to 8.26% and 6.84%
absolute F1-score gains respectively.
\\ ( https://arxiv.org/abs/2401.10189 ,  147kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10225
Date: Thu, 18 Jan 2024 18:59:11 GMT   (558kb,D)

Title: ChatQA: Building GPT-4 Level Conversational QA Models
Authors: Zihan Liu, Wei Ping, Rajarshi Roy, Peng Xu, Mohammad Shoeybi, Bryan
  Catanzaro
Categories: cs.CL cs.AI cs.IR cs.LG
\\
  In this work, we introduce ChatQA, a family of conversational question
answering (QA) models, that obtain GPT-4 level accuracies. Specifically, we
propose a two-stage instruction tuning method that can significantly improve
the zero-shot conversational QA results from large language models (LLMs). To
handle retrieval in conversational QA, we fine-tune a dense retriever on a
multi-turn QA dataset, which provides comparable results to using the
state-of-the-art query rewriting model while largely reducing deployment cost.
Notably, our ChatQA-70B can outperform GPT-4 in terms of average score on 10
conversational QA datasets (54.14 vs. 53.90), without relying on any synthetic
data from OpenAI GPT models.
\\ ( https://arxiv.org/abs/2401.10225 ,  558kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09426
Date: Thu, 14 Dec 2023 07:59:02 GMT   (21kb)

Title: Transduce: learning transduction grammars for string transformation
Authors: Francis Frydman, Philippe Mangion
Categories: cs.LG
\\
  The synthesis of string transformation programs from input-output examples
utilizes various techniques, all based on an inductive bias that comprises a
restricted set of basic operators to be combined. A new algorithm, Transduce,
is proposed, which is founded on the construction of abstract transduction
grammars and their generalization. We experimentally demonstrate that Transduce
can learn positional transformations efficiently from one or two positive
examples without inductive bias, achieving a success rate higher than the
current state of the art.
\\ ( https://arxiv.org/abs/2401.09426 ,  21kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09452
Date: Fri, 22 Dec 2023 13:09:17 GMT   (12361kb,D)

Title: Incorporating Riemannian Geometric Features for Learning Coefficient of
  Pressure Distributions on Airplane Wings
Authors: Liwei Hu, Wenyong Wang, Yu Xiang, Stefan Sommer
Categories: cs.LG cs.AI
\\
  The aerodynamic coefficients of aircrafts are significantly impacted by its
geometry, especially when the angle of attack (AoA) is large. In the field of
aerodynamics, traditional polynomial-based parameterization uses as few
parameters as possible to describe the geometry of an airfoil. However, because
the 3D geometry of a wing is more complicated than the 2D airfoil,
polynomial-based parameterizations have difficulty in accurately representing
the entire shape of a wing in 3D space. Existing deep learning-based methods
can extract massive latent neural representations for the shape of 2D airfoils
or 2D slices of wings. Recent studies highlight that directly taking geometric
features as inputs to the neural networks can improve the accuracy of predicted
aerodynamic coefficients. Motivated by geometry theory, we propose to
incorporate Riemannian geometric features for learning Coefficient of Pressure
(CP) distributions on wing surfaces. Our method calculates geometric features
(Riemannian metric, connection, and curvature) and further inputs the geometric
features, coordinates and flight conditions into a deep learning model to
predict the CP distribution. Experimental results show that our method,
compared to state-of-the-art Deep Attention Network (DAN), reduces the
predicted mean square error (MSE) of CP by an average of 8.41% for the DLR-F11
aircraft test set.
\\ ( https://arxiv.org/abs/2401.09452 ,  12361kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09486
Date: Tue, 16 Jan 2024 09:18:46 GMT   (930kb,D)

Title: LoMA: Lossless Compressed Memory Attention
Authors: Yumeng Wang, Zhenyang Xiao
Categories: cs.LG cs.CL
\\
  The ability to handle long texts is one of the most important capabilities of
Large Language Models (LLMs), but as the text length increases, the consumption
of resources also increases dramatically. At present, reducing resource
consumption by compressing the KV cache is a common approach. Although there
are many existing compression methods, they share a common drawback: the
compression is not lossless. That is, information is inevitably lost during the
compression process. If the compression rate is high, the probability of losing
important information increases dramatically. We propose a new method, Lossless
Compressed Memory Attention (LoMA), which allows for lossless compression of
information into special memory token KV pairs according to a set compression
ratio. Our experiments have achieved remarkable results, demonstrating that
LoMA can be efficiently trained and has very effective performance.
\\ ( https://arxiv.org/abs/2401.09486 ,  930kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09489
Date: Tue, 16 Jan 2024 20:13:46 GMT   (1199kb)

Title: PUPAE: Intuitive and Actionable Explanations for Time Series Anomalies
Authors: Audrey Der, Chin-Chia Michael Yeh, Yan Zheng, Junpeng Wang, Zhongfang
  Zhuang, Liang Wang, Wei Zhang, Eamonn J. Keogh
Categories: cs.LG cs.AI
Comments: 9 Page Manuscript, 1 Page Supplementary (Supplement not published in
  conference proceedings.)
Journal-ref: SIAM SDM 2024
\\
  In recent years there has been significant progress in time series anomaly
detection. However, after detecting an (perhaps tentative) anomaly, can we
explain it? Such explanations would be useful to triage anomalies. For example,
in an oil refinery, should we respond to an anomaly by dispatching a hydraulic
engineer, or an intern to replace the battery on a sensor? There have been some
parallel efforts to explain anomalies, however many proposed techniques produce
explanations that are indirect, and often seem more complex than the anomaly
they seek to explain. Our review of the literature/checklists/user-manuals used
by frontline practitioners in various domains reveals an interesting
near-universal commonality. Most practitioners discuss, explain and report
anomalies in the following format: The anomaly would be like normal data A, if
not for the corruption B. The reader will appreciate that is a type of
counterfactual explanation. In this work we introduce a domain agnostic
counterfactual explanation technique to produce explanations for time series
anomalies. As we will show, our method can produce both visual and text-based
explanations that are objectively correct, intuitive and in many circumstances,
directly actionable.
\\ ( https://arxiv.org/abs/2401.09489 ,  1199kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09492
Date: Tue, 16 Jan 2024 22:01:24 GMT   (2607kb)

Title: Uncertainty-Aware Calibration of a Hot-Wire Anemometer With Gaussian
  Process Regression
Authors: Rub\'en Antonio Garc\'ia-Ruiz, Jos\'e Luis Blanco-Claraco, Javier
  L\'opez-Mart\'inez, \'Angel Jes\'us Callej\'on-Ferre
Categories: cs.LG stat.AP stat.ML
Comments: 10 pages, 6 figures, Published in "IEEE Sensors Journal"
DOI: 10.1109/JSEN.2019.2915093
\\
  Expensive ultrasonic anemometers are usually required to measure wind speed
accurately. The aim of this work is to overcome the loss of accuracy of a low
cost hot-wire anemometer caused by the changes of air temperature, by means of
a probabilistic calibration using Gaussian Process Regression. Gaussian Process
Regression is a non-parametric, Bayesian, and supervised learning method
designed to make predictions of an unknown target variable as a function of one
or more known input variables. Our approach is validated against real datasets,
obtaining a good performance in inferring the actual wind speed values. By
performing, before its real use in the field, a calibration of the hot-wire
anemometer taking into account air temperature, permits that the wind speed can
be estimated for the typical range of ambient temperatures, including a
grounded uncertainty estimation for each speed measure.
\\ ( https://arxiv.org/abs/2401.09492 ,  2607kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09498
Date: Wed, 17 Jan 2024 06:11:19 GMT   (1690kb,D)

Title: Technical Report: On the Convergence of Gossip Learning in the Presence
  of Node Inaccessibility
Authors: Tian Liu, Yue Cui, Xueyang Hu, Yecheng Xu, Bo Liu
Categories: cs.LG cs.AI
\\
  Gossip learning (GL), as a decentralized alternative to federated learning
(FL), is more suitable for resource-constrained wireless networks, such as
FANETs that are formed by unmanned aerial vehicles (UAVs). GL can significantly
enhance the efficiency and extend the battery life of UAV networks. Despite the
advantages, the performance of GL is strongly affected by data distribution,
communication speed, and network connectivity. However, how these factors
influence the GL convergence is still unclear. Existing work studied the
convergence of GL based on a virtual quantity for the sake of convenience,
which fail to reflect the real state of the network when some nodes are
inaccessible. In this paper, we formulate and investigate the impact of
inaccessible nodes to GL under a dynamic network topology. We first decompose
the weight divergence by whether the node is accessible or not. Then, we
investigate the GL convergence under the dynamic of node accessibility and
theoretically provide how the number of inaccessible nodes, data
non-i.i.d.-ness, and duration of inaccessibility affect the convergence.
Extensive experiments are carried out in practical settings to comprehensively
verify the correctness of our theoretical findings.
\\ ( https://arxiv.org/abs/2401.09498 ,  1690kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09499
Date: Wed, 17 Jan 2024 08:33:25 GMT   (6479kb,D)

Title: Functional Autoencoder for Smoothing and Representation Learning
Authors: Sidi Wu, C\'edric Beaulac and Jiguo Cao
Categories: cs.LG stat.ML
\\
  A common pipeline in functional data analysis is to first convert the
discretely observed data to smooth functions, and then represent the functions
by a finite-dimensional vector of coefficients summarizing the information.
Existing methods for data smoothing and dimensional reduction mainly focus on
learning the linear mappings from the data space to the representation space,
however, learning only the linear representations may not be sufficient. In
this study, we propose to learn the nonlinear representations of functional
data using neural network autoencoders designed to process data in the form it
is usually collected without the need of preprocessing. We design the encoder
to employ a projection layer computing the weighted inner product of the
functional data and functional weights over the observed timestamp, and the
decoder to apply a recovery layer that maps the finite-dimensional vector
extracted from the functional data back to functional space using a set of
predetermined basis functions. The developed architecture can accommodate both
regularly and irregularly spaced data. Our experiments demonstrate that the
proposed method outperforms functional principal component analysis in terms of
prediction and classification, and maintains superior smoothing ability and
better computational efficiency in comparison to the conventional autoencoders
under both linear and nonlinear settings.
\\ ( https://arxiv.org/abs/2401.09499 ,  6479kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09507
Date: Wed, 17 Jan 2024 11:41:11 GMT   (22112kb,D)

Title: Deep Ensemble Shape Calibration: Multi-Field Post-hoc Calibration in
  Online Advertising
Authors: Shuai Yang, Hao Yang, Zhuang Zou, Linhe Xu, Shuo Yuan, Yifan Zeng
Categories: cs.LG
\\
  In the e-commerce advertising scenario, estimating the true probabilities
(known as a calibrated estimate) on CTR and CVR is critical and can directly
affect the benefits of the buyer, seller and platform. Previous research has
introduced numerous solutions for addressing the calibration problem. These
methods typically involve the training of calibrators using a validation set
and subsequently applying these calibrators to correct the original estimated
values during online inference. However, what sets e-commerce advertising
scenarios is the challenge of multi-field calibration. Multi-field calibration
can be subdivided into two distinct sub-problems: value calibration and shape
calibration. Value calibration is defined as no over- or under-estimation for
each value under concerned fields. Shape calibration is defined as no over- or
under-estimation for each subset of the pCTR within the specified range under
condition of concerned fields. In order to achieve shape calibration and value
calibration, it is necessary to have a strong data utilization ability.Because
the quantity of pCTR specified range for single field-value sample is relative
small, which makes the calibrator more difficult to train. However the existing
methods cannot simultaneously fulfill both value calibration and shape
calibration. To solve these problems, we propose a new method named Deep
Ensemble Shape Calibration (DESC). We introduce innovative basis calibration
functions, which enhance both function expression capabilities and data
utilization by combining these basis calibration functions. A significant
advancement lies in the development of an allocator capable of allocating the
most suitable shape calibrators to different estimation error distributions
within diverse fields and values.
\\ ( https://arxiv.org/abs/2401.09507 ,  22112kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09516
Date: Wed, 17 Jan 2024 16:20:12 GMT   (2879kb,D)

Title: Accelerating Data Generation for Neural Operators via Krylov Subspace
  Recycling
Authors: Hong Wang, Zhongkai Hao, Jie Wang, Zijie Geng, Zhen Wang, Bin Li, Feng
  Wu
Categories: cs.LG cs.AI cs.NA math.NA
\\
  Learning neural operators for solving partial differential equations (PDEs)
has attracted great attention due to its high inference efficiency. However,
training such operators requires generating a substantial amount of labeled
data, i.e., PDE problems together with their solutions. The data generation
process is exceptionally time-consuming, as it involves solving numerous
systems of linear equations to obtain numerical solutions to the PDEs. Many
existing methods solve these systems independently without considering their
inherent similarities, resulting in extremely redundant computations. To tackle
this problem, we propose a novel method, namely Sorting Krylov Recycling (SKR),
to boost the efficiency of solving these systems, thus significantly
accelerating data generation for neural operators training. To the best of our
knowledge, SKR is the first attempt to address the time-consuming nature of
data generation for learning neural operators. The working horse of SKR is
Krylov subspace recycling, a powerful technique for solving a series of
interrelated systems by leveraging their inherent similarities. Specifically,
SKR employs a sorting algorithm to arrange these systems in a sequence, where
adjacent systems exhibit high similarities. Then it equips a solver with Krylov
subspace recycling to solve the systems sequentially instead of independently,
thus effectively enhancing the solving efficiency. Both theoretical analysis
and extensive experiments demonstrate that SKR can significantly accelerate
neural operator data generation, achieving a remarkable speedup of up to 13.9
times.
\\ ( https://arxiv.org/abs/2401.09516 ,  2879kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09517
Date: Wed, 17 Jan 2024 16:31:48 GMT   (1492kb)

Title: Dimensional Neuroimaging Endophenotypes: Neurobiological Representations
  of Disease Heterogeneity Through Machine Learning
Authors: Junhao Wen, Mathilde Antoniades, Zhijian Yang, Gyujoon Hwang, Ioanna
  Skampardoni, Rongguang Wang, Christos Davatzikos
Categories: cs.LG eess.IV q-bio.QM
\\
  Machine learning has been increasingly used to obtain individualized
neuroimaging signatures for disease diagnosis, prognosis, and response to
treatment in neuropsychiatric and neurodegenerative disorders. Therefore, it
has contributed to a better understanding of disease heterogeneity by
identifying disease subtypes that present significant differences in various
brain phenotypic measures. In this review, we first present a systematic
literature overview of studies using machine learning and multimodal MRI to
unravel disease heterogeneity in various neuropsychiatric and neurodegenerative
disorders, including Alzheimer disease, schizophrenia, major depressive
disorder, autism spectrum disorder, multiple sclerosis, as well as their
potential in transdiagnostic settings. Subsequently, we summarize relevant
machine learning methodologies and discuss an emerging paradigm which we call
dimensional neuroimaging endophenotype (DNE). DNE dissects the neurobiological
heterogeneity of neuropsychiatric and neurodegenerative disorders into a low
dimensional yet informative, quantitative brain phenotypic representation,
serving as a robust intermediate phenotype (i.e., endophenotype) largely
reflecting underlying genetics and etiology. Finally, we discuss the potential
clinical implications of the current findings and envision future research
avenues.
\\ ( https://arxiv.org/abs/2401.09517 ,  1492kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09555
Date: Wed, 17 Jan 2024 19:13:05 GMT   (1879kb,D)

Title: Improving Classification Performance With Human Feedback: Label a few,
  we label the rest
Authors: Natan Vidra, Thomas Clifford, Katherine Jijo, Eden Chung, Liang Zhang
Categories: cs.LG cs.AI cs.CL
\\
  In the realm of artificial intelligence, where a vast majority of data is
unstructured, obtaining substantial amounts of labeled data to train supervised
machine learning models poses a significant challenge. To address this, we
delve into few-shot and active learning, where are goal is to improve AI models
with human feedback on a few labeled examples. This paper focuses on
understanding how a continuous feedback loop can refine models, thereby
enhancing their accuracy, recall, and precision through incremental human
input. By employing Large Language Models (LLMs) such as GPT-3.5, BERT, and
SetFit, we aim to analyze the efficacy of using a limited number of labeled
examples to substantially improve model accuracy. We benchmark this approach on
the Financial Phrasebank, Banking, Craigslist, Trec, Amazon Reviews datasets to
prove that with just a few labeled examples, we are able to surpass the
accuracy of zero shot large language models to provide enhanced text
classification performance. We demonstrate that rather than needing to manually
label millions of rows of data, we just need to label a few and the model can
effectively predict the rest.
\\ ( https://arxiv.org/abs/2401.09555 ,  1879kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09561
Date: Wed, 17 Jan 2024 19:31:21 GMT   (215kb,D)

Title: Sharing Knowledge in Multi-Task Deep Reinforcement Learning
Authors: Carlo D'Eramo, Davide Tateo, Andrea Bonarini, Marcello Restelli, Jan
  Peters
Categories: cs.LG
\\
  We study the benefit of sharing representations among tasks to enable the
effective use of deep neural networks in Multi-Task Reinforcement Learning. We
leverage the assumption that learning from different tasks, sharing common
properties, is helpful to generalize the knowledge of them resulting in a more
effective feature extraction compared to learning a single task. Intuitively,
the resulting set of features offers performance benefits when used by
Reinforcement Learning algorithms. We prove this by providing theoretical
guarantees that highlight the conditions for which is convenient to share
representations among tasks, extending the well-known finite-time bounds of
Approximate Value-Iteration to the multi-task setting. In addition, we
complement our analysis by proposing multi-task extensions of three
Reinforcement Learning algorithms that we empirically evaluate on widely used
Reinforcement Learning benchmarks showing significant improvements over the
single-task counterparts in terms of sample efficiency and performance.
\\ ( https://arxiv.org/abs/2401.09561 ,  215kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09574
Date: Wed, 17 Jan 2024 19:55:49 GMT   (7900kb)

Title: Towards Scalable and Robust Model Versioning
Authors: Wenxin Ding, Arjun Nitin Bhagoji, Ben Y. Zhao, Haitao Zheng
Categories: cs.LG cs.CR
Comments: Accepted in IEEE SaTML 2024
\\
  As the deployment of deep learning models continues to expand across
industries, the threat of malicious incursions aimed at gaining access to these
deployed models is on the rise. Should an attacker gain access to a deployed
model, whether through server breaches, insider attacks, or model inversion
techniques, they can then construct white-box adversarial attacks to manipulate
the model's classification outcomes, thereby posing significant risks to
organizations that rely on these models for critical tasks. Model owners need
mechanisms to protect themselves against such losses without the necessity of
acquiring fresh training data - a process that typically demands substantial
investments in time and capital.
  In this paper, we explore the feasibility of generating multiple versions of
a model that possess different attack properties, without acquiring new
training data or changing model architecture. The model owner can deploy one
version at a time and replace a leaked version immediately with a new version.
The newly deployed model version can resist adversarial attacks generated
leveraging white-box access to one or all previously leaked versions. We show
theoretically that this can be accomplished by incorporating parameterized
hidden distributions into the model training data, forcing the model to learn
task-irrelevant features uniquely defined by the chosen data. Additionally,
optimal choices of hidden distributions can produce a sequence of model
versions capable of resisting compound transferability attacks over time.
Leveraging our analytical insights, we design and implement a practical model
versioning method for DNN classifiers, which leads to significant robustness
improvements over existing methods. We believe our work presents a promising
direction for safeguarding DNN services beyond their initial deployment.
\\ ( https://arxiv.org/abs/2401.09574 ,  7900kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09582
Date: Wed, 17 Jan 2024 20:07:47 GMT   (824kb,D)

Title: eipy: An Open-Source Python Package for Multi-modal Data Integration
  using Heterogeneous Ensembles
Authors: Jamie J. R. Bennett, Yan Chak Li, Gaurav Pandey
Categories: cs.LG
\\
  In this paper, we introduce eipy--an open-source Python package for
developing effective, multi-modal heterogeneous ensembles for classification.
eipy simultaneously provides both a rigorous, and user-friendly framework for
comparing and selecting the best-performing multi-modal data integration and
predictive modeling methods by systematically evaluating their performance
using nested cross-validation. The package is designed to leverage
scikit-learn-like estimators as components to build multi-modal predictive
models. An up-to-date user guide, including API reference and tutorials, for
eipy is maintained at https://eipy.readthedocs.io . The main repository for
this project can be found on GitHub at https://github.com/GauravPandeyLab/eipy .
\\ ( https://arxiv.org/abs/2401.09582 ,  824kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09587
Date: Wed, 17 Jan 2024 20:28:15 GMT   (3529kb,D)

Title: Bilevel Optimization under Unbounded Smoothness: A New Algorithm and
  Convergence Analysis
Authors: Jie Hao, Xiaochuan Gong, Mingrui Liu
Categories: cs.LG math.OC
Comments: Accepted by ICLR 2024, Spotlight
\\
  Bilevel optimization is an important formulation for many machine learning
problems. Current bilevel optimization algorithms assume that the gradient of
the upper-level function is Lipschitz. However, recent studies reveal that
certain neural networks such as recurrent neural networks (RNNs) and
long-short-term memory networks (LSTMs) exhibit potential unbounded smoothness,
rendering conventional bilevel optimization algorithms unsuitable. In this
paper, we design a new bilevel optimization algorithm, namely BO-REP, to
address this challenge. This algorithm updates the upper-level variable using
normalized momentum and incorporates two novel techniques for updating the
lower-level variable: \textit{initialization refinement} and \textit{periodic
updates}. Specifically, once the upper-level variable is initialized, a
subroutine is invoked to obtain a refined estimate of the corresponding optimal
lower-level variable, and the lower-level variable is updated only after every
specific period instead of each iteration. When the upper-level problem is
nonconvex and unbounded smooth, and the lower-level problem is strongly convex,
we prove that our algorithm requires $\widetilde{\mathcal{O}}(1/\epsilon^4)$
iterations to find an $\epsilon$-stationary point in the stochastic setting,
where each iteration involves calling a stochastic gradient or Hessian-vector
product oracle. Notably, this result matches the state-of-the-art complexity
results under the bounded smoothness setting and without mean-squared
smoothness of the stochastic gradient, up to logarithmic factors. Our proof
relies on novel technical lemmas for the periodically updated lower-level
variable, which are of independent interest. Our experiments on
hyper-representation learning, hyperparameter optimization, and data
hyper-cleaning for text classification tasks demonstrate the effectiveness of
our proposed algorithm.
\\ ( https://arxiv.org/abs/2401.09587 ,  3529kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09629
Date: Wed, 17 Jan 2024 22:43:00 GMT   (2922kb,D)

Title: Multiple Locally Linear Kernel Machines
Authors: David Picard
Categories: cs.LG stat.ML
Comments: This paper was written in 2014 and was originally submitted but
  rejected at ICML'15
\\
  In this paper we propose a new non-linear classifier based on a combination
of locally linear classifiers. A well known optimization formulation is given
as we cast the problem in a $\ell_1$ Multiple Kernel Learning (MKL) problem
using many locally linear kernels. Since the number of such kernels is huge, we
provide a scalable generic MKL training algorithm handling streaming kernels.
With respect to the inference time, the resulting classifier fits the gap
between high accuracy but slow non-linear classifiers (such as classical MKL)
and fast but low accuracy linear classifiers.
\\ ( https://arxiv.org/abs/2401.09629 ,  2922kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09631
Date: Wed, 17 Jan 2024 22:46:51 GMT   (2165kb,D)

Title: Physics-Informed Calibration of Aeromagnetic Compensation in Magnetic
  Navigation Systems using Liquid Time-Constant Networks
Authors: Favour Nerrise (1 and 2), Andrew Sosa Sosanya (2), Patrick Neary (2)
  ((1) Department of Electrical Engineering, Stanford University, CA, USA, (2)
  SandboxAQ, Palo Alto, CA, USA)
Categories: cs.LG cs.SY eess.SY physics.comp-ph physics.geo-ph
Comments: Accepted at the NeurIPS 2023 Machine Learning and the Physical
  Sciences workshop, 7 pages, 4 figures, see code here:
  https://github.com/fnerrise/LNNs_MagNav/
\\
  Magnetic navigation (MagNav) is a rising alternative to the Global
Positioning System (GPS) and has proven useful for aircraft navigation.
Traditional aircraft navigation systems, while effective, face limitations in
precision and reliability in certain environments and against attacks. Airborne
MagNav leverages the Earth's magnetic field to provide accurate positional
information. However, external magnetic fields induced by aircraft electronics
and Earth's large-scale magnetic fields disrupt the weaker signal of interest.
We introduce a physics-informed approach using Tolles-Lawson coefficients for
compensation and Liquid Time-Constant Networks (LTCs) to remove complex, noisy
signals derived from the aircraft's magnetic sources. Using real flight data
with magnetometer measurements and aircraft measurements, we observe up to a
64% reduction in aeromagnetic compensation error (RMSE nT), outperforming
conventional models. This significant improvement underscores the potential of
a physics-informed, machine learning approach for extracting clean, reliable,
and accurate magnetic signals for MagNav positional estimation.
\\ ( https://arxiv.org/abs/2401.09631 ,  2165kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09641
Date: Wed, 17 Jan 2024 23:27:48 GMT   (1180kb)

Title: Functional Linear Non-Gaussian Acyclic Model for Causal Discovery
Authors: Tian-Le Yang, Kuang-Yao Lee, Kun Zhang, Joe Suzuki
Categories: cs.LG math.ST q-bio.NC stat.ME stat.TH
\\
  In causal discovery, non-Gaussianity has been used to characterize the
complete configuration of a Linear Non-Gaussian Acyclic Model (LiNGAM),
encompassing both the causal ordering of variables and their respective
connection strengths. However, LiNGAM can only deal with the finite-dimensional
case. To expand this concept, we extend the notion of variables to encompass
vectors and even functions, leading to the Functional Linear Non-Gaussian
Acyclic Model (Func-LiNGAM). Our motivation stems from the desire to identify
causal relationships in brain-effective connectivity tasks involving, for
example, fMRI and EEG datasets. We demonstrate why the original LiNGAM fails to
handle these inherently infinite-dimensional datasets and explain the
availability of functional data analysis from both empirical and theoretical
perspectives. {We establish theoretical guarantees of the identifiability of
the causal relationship among non-Gaussian random vectors and even random
functions in infinite-dimensional Hilbert spaces.} To address the issue of
sparsity in discrete time points within intrinsic infinite-dimensional
functional data, we propose optimizing the coordinates of the vectors using
functional principal component analysis. Experimental results on synthetic data
verify the ability of the proposed framework to identify causal relationships
among multivariate functions using the observed samples. For real data, we
focus on analyzing the brain connectivity patterns derived from fMRI data.
\\ ( https://arxiv.org/abs/2401.09641 ,  1180kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09646
Date: Wed, 17 Jan 2024 23:29:46 GMT   (185kb,D)

Title: ClimateGPT: Towards AI Synthesizing Interdisciplinary Research on
  Climate Change
Authors: David Thulke and Yingbo Gao and Petrus Pelser and Rein Brune and
  Rricha Jalota and Floris Fok and Michael Ramos and Ian van Wyk and Abdallah
  Nasir and Hayden Goldstein and Taylor Tragemann and Katie Nguyen and Ariana
  Fowler and Andrew Stanco and Jon Gabriel and Jordan Taylor and Dean Moro and
  Evgenii Tsymbalov and Juliette de Waal and Evgeny Matusov and Mudar Yaghi and
  Mohammad Shihadah and Hermann Ney and Christian Dugast and Jonathan Dotan and
  Daniel Erasmus
Categories: cs.LG cs.AI cs.CL
\\
  This paper introduces ClimateGPT, a model family of domain-specific large
language models that synthesize interdisciplinary research on climate change.
We trained two 7B models from scratch on a science-oriented dataset of 300B
tokens. For the first model, the 4.2B domain-specific tokens were included
during pre-training and the second was adapted to the climate domain after
pre-training. Additionally, ClimateGPT-7B, 13B and 70B are continuously
pre-trained from Llama~2 on a domain-specific dataset of 4.2B tokens. Each
model is instruction fine-tuned on a high-quality and human-generated
domain-specific dataset that has been created in close cooperation with climate
scientists. To reduce the number of hallucinations, we optimize the model for
retrieval augmentation and propose a hierarchical retrieval strategy. To
increase the accessibility of our model to non-English speakers, we propose to
make use of cascaded machine translation and show that this approach can
perform comparably to natively multilingual models while being easier to scale
to a large number of languages. Further, to address the intrinsic
interdisciplinary aspect of climate change we consider different research
perspectives. Therefore, the model can produce in-depth answers focusing on
different perspectives in addition to an overall answer. We propose a suite of
automatic climate-specific benchmarks to evaluate LLMs. On these benchmarks,
ClimateGPT-7B performs on par with the ten times larger Llama-2-70B Chat model
while not degrading results on general domain benchmarks. Our human evaluation
confirms the trends we saw in our benchmarks. All models were trained and
evaluated using renewable energy and are released publicly.
\\ ( https://arxiv.org/abs/2401.09646 ,  185kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09651
Date: Wed, 17 Jan 2024 23:45:53 GMT   (179kb,D)

Title: Convex and Bilevel Optimization for Neuro-Symbolic Inference and
  Learning
Authors: Charles Dickens, Changyu Gao, Connor Pryor, Stephen Wright, Lise
  Getoor
Categories: cs.LG cs.AI math.OC
\\
  We address a key challenge for neuro-symbolic (NeSy) systems by leveraging
convex and bilevel optimization techniques to develop a general gradient-based
framework for end-to-end neural and symbolic parameter learning. The
applicability of our framework is demonstrated with NeuPSL, a state-of-the-art
NeSy architecture. To achieve this, we propose a smooth primal and dual
formulation of NeuPSL inference and show learning gradients are functions of
the optimal dual variables. Additionally, we develop a dual block coordinate
descent algorithm for the new formulation that naturally exploits warm-starts.
This leads to over 100x learning runtime improvements over the current best
NeuPSL inference method. Finally, we provide extensive empirical evaluations
across $8$ datasets covering a range of tasks and demonstrate our learning
framework achieves up to a 16% point prediction performance improvement over
alternative learning methods.
\\ ( https://arxiv.org/abs/2401.09651 ,  179kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09656
Date: Thu, 18 Jan 2024 00:09:54 GMT   (650kb,D)

Title: Mobility Accelerates Learning: Convergence Analysis on Hierarchical
  Federated Learning in Vehicular Networks
Authors: Tan Chen, Jintao Yan, Yuxuan Sun, Sheng Zhou, Deniz G\"und\"uz,
  Zhisheng Niu
Categories: cs.LG cs.AI cs.DC
Comments: Submitted to IEEE for possible publication
\\
  Hierarchical federated learning (HFL) enables distributed training of models
across multiple devices with the help of several edge servers and a cloud edge
server in a privacy-preserving manner. In this paper, we consider HFL with
highly mobile devices, mainly targeting at vehicular networks. Through
convergence analysis, we show that mobility influences the convergence speed by
both fusing the edge data and shuffling the edge models. While mobility is
usually considered as a challenge from the perspective of communication, we
prove that it increases the convergence speed of HFL with edge-level
heterogeneous data, since more diverse data can be incorporated. Furthermore,
we demonstrate that a higher speed leads to faster convergence, since it
accelerates the fusion of data. Simulation results show that mobility increases
the model accuracy of HFL by up to 15.1% when training a convolutional neural
network on the CIFAR-10 dataset.
\\ ( https://arxiv.org/abs/2401.09656 ,  650kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09671
Date: Thu, 18 Jan 2024 01:07:00 GMT   (34515kb,D)

Title: Towards Identifiable Unsupervised Domain Translation: A Diversified
  Distribution Matching Approach
Authors: Sagar Shrestha and Xiao Fu
Categories: cs.LG cs.AI cs.CV
\\
  Unsupervised domain translation (UDT) aims to find functions that convert
samples from one domain (e.g., sketches) to another domain (e.g., photos)
without changing the high-level semantic meaning (also referred to as
``content''). The translation functions are often sought by probability
distribution matching of the transformed source domain and target domain.
CycleGAN stands as arguably the most representative approach among this line of
work. However, it was noticed in the literature that CycleGAN and variants
could fail to identify the desired translation functions and produce
content-misaligned translations. This limitation arises due to the presence of
multiple translation functions -- referred to as ``measure-preserving
automorphism" (MPA) -- in the solution space of the learning criteria. Despite
awareness of such identifiability issues, solutions have remained elusive. This
study delves into the core identifiability inquiry and introduces an MPA
elimination theory. Our analysis shows that MPA is unlikely to exist, if
multiple pairs of diverse cross-domain conditional distributions are matched by
the learning function. Our theory leads to a UDT learner using distribution
matching over auxiliary variable-induced subsets of the domains -- other than
over the entire data domains as in the classical approaches. The proposed
framework is the first to rigorously establish translation identifiability
under reasonable UDT settings, to our best knowledge. Experiments corroborate
with our theoretical claims.
\\ ( https://arxiv.org/abs/2401.09671 ,  34515kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09681
Date: Thu, 18 Jan 2024 02:21:06 GMT   (100kb,D)

Title: Harnessing Density Ratios for Online Reinforcement Learning
Authors: Philip Amortila, Dylan J. Foster, Nan Jiang, Ayush Sekhari, Tengyang
  Xie
Categories: cs.LG stat.ML
Comments: ICLR 2024
\\
  The theories of offline and online reinforcement learning, despite having
evolved in parallel, have begun to show signs of the possibility for a
unification, with algorithms and analysis techniques for one setting often
having natural counterparts in the other. However, the notion of density ratio
modeling, an emerging paradigm in offline RL, has been largely absent from
online RL, perhaps for good reason: the very existence and boundedness of
density ratios relies on access to an exploratory dataset with good coverage,
but the core challenge in online RL is to collect such a dataset without having
one to start. In this work we show -- perhaps surprisingly -- that density
ratio-based algorithms have online counterparts. Assuming only the existence of
an exploratory distribution with good coverage, a structural condition known as
coverability (Xie et al., 2023), we give a new algorithm (GLOW) that uses
density ratio realizability and value function realizability to perform
sample-efficient online exploration. GLOW addresses unbounded density ratios
via careful use of truncation, and combines this with optimism to guide
exploration. GLOW is computationally inefficient; we complement it with a more
efficient counterpart, HyGLOW, for the Hybrid RL setting (Song et al., 2022)
wherein online RL is augmented with additional offline data. HyGLOW is derived
as a special case of a more general meta-algorithm that provides a provable
black-box reduction from hybrid RL to offline RL, which may be of independent
interest.
\\ ( https://arxiv.org/abs/2401.09681 ,  100kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09682
Date: Thu, 18 Jan 2024 02:21:53 GMT   (2738kb,D)

Title: Comparative Study on the Performance of Categorical Variable Encoders in
  Classification and Regression Tasks
Authors: Wenbin Zhu, Runwen Qiu and Ying Fu
Categories: cs.LG
\\
  Categorical variables often appear in datasets for classification and
regression tasks, and they need to be encoded into numerical values before
training. Since many encoders have been developed and can significantly impact
performance, choosing the appropriate encoder for a task becomes a
time-consuming yet important practical issue. This study broadly classifies
machine learning models into three categories: 1) ATI models that implicitly
perform affine transformations on inputs, such as multi-layer perceptron neural
network; 2) Tree-based models that are based on decision trees, such as random
forest; and 3) the rest, such as kNN. Theoretically, we prove that the one-hot
encoder is the best choice for ATI models in the sense that it can mimic any
other encoders by learning suitable weights from the data. We also explain why
the target encoder and its variants are the most suitable encoders for
tree-based models. This study conducted comprehensive computational experiments
to evaluate 14 encoders, including one-hot and target encoders, along with
eight common machine-learning models on 28 datasets. The computational results
agree with our theoretical analysis. The findings in this study shed light on
how to select the suitable encoder for data scientists in fields such as fraud
detection, disease diagnosis, etc.
\\ ( https://arxiv.org/abs/2401.09682 ,  2738kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09728
Date: Thu, 18 Jan 2024 05:17:30 GMT   (1449kb,D)

Title: Offline Imitation Learning by Controlling the Effective Planning Horizon
Authors: Hee-Jun Ahn, Seong-Woong Shim, Byung-Jun Lee
Categories: cs.LG
Comments: Preprint
\\
  In offline imitation learning (IL), we generally assume only a handful of
expert trajectories and a supplementary offline dataset from suboptimal
behaviors to learn the expert policy. While it is now common to minimize the
divergence between state-action visitation distributions so that the agent also
considers the future consequences of an action, a sampling error in an offline
dataset may lead to erroneous estimates of state-action visitations in the
offline case. In this paper, we investigate the effect of controlling the
effective planning horizon (i.e., reducing the discount factor) as opposed to
imposing an explicit regularizer, as previously studied. Unfortunately, it
turns out that the existing algorithms suffer from magnified approximation
errors when the effective planning horizon is shortened, which results in a
significant degradation in performance. We analyze the main cause of the
problem and provide the right remedies to correct the algorithm. We show that
the corrected algorithm improves on popular imitation learning benchmarks by
controlling the effective planning horizon rather than an explicit
regularization.
\\ ( https://arxiv.org/abs/2401.09728 ,  1449kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09750
Date: Thu, 18 Jan 2024 06:32:53 GMT   (11350kb,D)

Title: Exploration and Anti-Exploration with Distributional Random Network
  Distillation
Authors: Kai Yang, Jian Tao, Jiafei Lyu, Xiu Li
Categories: cs.LG
Comments: Submitted to ICML 2024
\\
  Exploration remains a critical issue in deep reinforcement learning for an
agent to attain high returns in unknown environments. Although the prevailing
exploration Random Network Distillation (RND) algorithm has been demonstrated
to be effective in numerous environments, it often needs more discriminative
power in bonus allocation. This paper highlights the ``bonus inconsistency''
issue within RND, pinpointing its primary limitation. To address this issue, we
introduce the Distributional RND (DRND), a derivative of the RND. DRND enhances
the exploration process by distilling a distribution of random networks and
implicitly incorporating pseudo counts to improve the precision of bonus
allocation. This refinement encourages agents to engage in more extensive
exploration. Our method effectively mitigates the inconsistency issue without
introducing significant computational overhead. Both theoretical analysis and
experimental results demonstrate the superiority of our approach over the
original RND algorithm. Our method excels in challenging online exploration
scenarios and effectively serves as an anti-exploration mechanism in D4RL
offline tasks.
\\ ( https://arxiv.org/abs/2401.09750 ,  11350kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09753
Date: Thu, 18 Jan 2024 06:57:05 GMT   (3143kb)

Title: Applications of Machine Learning to Optimizing Polyolefin Manufacturing
Authors: Niket Sharma and Y.A. Liu
Categories: cs.LG cs.CE
Journal-ref: in Liu, Y. A., & Sharma, N. (2023), Integrated Process Modeling,
  Advanced Control and Data Analytics for Optimizing Polyolefin Manufacturing,
  Wiley-VCH GmbH.
DOI: 10.1002/9783527843831.ch10
\\
  This chapter is a preprint from our book by , focusing on leveraging machine
learning (ML) in chemical and polyolefin manufacturing optimization. It's
crafted for both novices and seasoned professionals keen on the latest ML
applications in chemical processes. We trace the evolution of AI and ML in
chemical industries, delineate core ML components, and provide resources for ML
beginners. A detailed discussion on various ML methods is presented, covering
regression, classification, and unsupervised learning techniques, with
performance metrics and examples. Ensemble methods, deep learning networks,
including MLP, DNNs, RNNs, CNNs, and transformers, are explored for their
growing role in chemical applications. Practical workshops guide readers
through predictive modeling using advanced ML algorithms. The chapter
culminates with insights into science-guided ML, advocating for a hybrid
approach that enhances model accuracy. The extensive bibliography offers
resources for further research and practical implementation. This chapter aims
to be a thorough primer on ML's practical application in chemical engineering,
particularly for polyolefin production, and sets the stage for continued
learning in subsequent chapters. Please cite the original work [169,170] when
referencing.
\\ ( https://arxiv.org/abs/2401.09753 ,  3143kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09754
Date: Thu, 18 Jan 2024 06:57:29 GMT   (859kb,D)

Title: Universally Robust Graph Neural Networks by Preserving Neighbor
  Similarity
Authors: Yulin Zhu, Yuni Lai, Xing Ai, Kai Zhou
Categories: cs.LG cs.CR cs.SI
\\
  Despite the tremendous success of graph neural networks in learning
relational data, it has been widely investigated that graph neural networks are
vulnerable to structural attacks on homophilic graphs. Motivated by this, a
surge of robust models is crafted to enhance the adversarial robustness of
graph neural networks on homophilic graphs. However, the vulnerability based on
heterophilic graphs remains a mystery to us. To bridge this gap, in this paper,
we start to explore the vulnerability of graph neural networks on heterophilic
graphs and theoretically prove that the update of the negative classification
loss is negatively correlated with the pairwise similarities based on the
powered aggregated neighbor features. This theoretical proof explains the
empirical observations that the graph attacker tends to connect dissimilar node
pairs based on the similarities of neighbor features instead of ego features
both on homophilic and heterophilic graphs. In this way, we novelly introduce a
novel robust model termed NSPGNN which incorporates a dual-kNN graphs pipeline
to supervise the neighbor similarity-guided propagation. This propagation
utilizes the low-pass filter to smooth the features of node pairs along the
positive kNN graphs and the high-pass filter to discriminate the features of
node pairs along the negative kNN graphs. Extensive experiments on both
homophilic and heterophilic graphs validate the universal robustness of NSPGNN
compared to the state-of-the-art methods.
\\ ( https://arxiv.org/abs/2401.09754 ,  859kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09756
Date: Thu, 18 Jan 2024 07:07:42 GMT   (82kb,D)

Title: Explaining Drift using Shapley Values
Authors: Narayanan U. Edakunni and Utkarsh Tekriwal and Anukriti Jain
Categories: cs.LG cs.AI
\\
  Machine learning models often deteriorate in their performance when they are
used to predict the outcomes over data on which they were not trained. These
scenarios can often arise in real world when the distribution of data changes
gradually or abruptly due to major events like a pandemic. There have been many
attempts in machine learning research to come up with techniques that are
resilient to such Concept drifts. However, there is no principled framework to
identify the drivers behind the drift in model performance. In this paper, we
propose a novel framework - DBShap that uses Shapley values to identify the
main contributors of the drift and quantify their respective contributions. The
proposed framework not only quantifies the importance of individual features in
driving the drift but also includes the change in the underlying relation
between the input and output as a possible driver. The explanation provided by
DBShap can be used to understand the root cause behind the drift and use it to
make the model resilient to the drift.
\\ ( https://arxiv.org/abs/2401.09756 ,  82kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09787
Date: Thu, 18 Jan 2024 08:12:23 GMT   (3419kb,D)

Title: Querying Easily Flip-flopped Samples for Deep Active Learning
Authors: Seong Jin Cho, Gwangsu Kim, Junghyun Lee, Jinwoo Shin, and Chang D.
  Yoo
Categories: cs.LG cs.AI stat.ML
Comments: 34 pages, 17 figures, 5 tables. Accepted to the 12th International
  Conference on Learning Representations (ICLR 2024)
\\
  Active learning is a machine learning paradigm that aims to improve the
performance of a model by strategically selecting and querying unlabeled data.
One effective selection strategy is to base it on the model's predictive
uncertainty, which can be interpreted as a measure of how informative a sample
is. The sample's distance to the decision boundary is a natural measure of
predictive uncertainty, but it is often intractable to compute, especially for
complex decision boundaries formed in multiclass classification tasks. To
address this issue, this paper proposes the {\it least disagree metric} (LDM),
defined as the smallest probability of disagreement of the predicted label, and
an estimator for LDM proven to be asymptotically consistent under mild
assumptions. The estimator is computationally efficient and can be easily
implemented for deep learning models using parameter perturbation. The
LDM-based active learning is performed by querying unlabeled data with the
smallest LDM. Experimental results show that our LDM-based active learning
algorithm obtains state-of-the-art overall performance on all considered
datasets and deep architectures.
\\ ( https://arxiv.org/abs/2401.09787 ,  3419kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09793
Date: Thu, 18 Jan 2024 08:26:33 GMT   (1384kb,D)

Title: PatchAD: Patch-based MLP-Mixer for Time Series Anomaly Detection
Authors: Zhijie Zhong, Zhiwen Yu, Yiyuan Yang, Weizheng Wang, Kaixiang Yang
Categories: cs.LG
Comments: 13 pages, 16 figures, IJCAI 2024 under review, paper id 3166
\\
  Anomaly detection stands as a crucial aspect of time series analysis, aiming
to identify abnormal events in time series samples. The central challenge of
this task lies in effectively learning the representations of normal and
abnormal patterns in a label-lacking scenario. Previous research mostly relied
on reconstruction-based approaches, restricting the representational abilities
of the models. In addition, most of the current deep learning-based methods are
not lightweight enough, which prompts us to design a more efficient framework
for anomaly detection. In this study, we introduce PatchAD, a novel multi-scale
patch-based MLP-Mixer architecture that leverages contrastive learning for
representational extraction and anomaly detection. Specifically, PatchAD is
composed of four distinct MLP Mixers, exclusively utilizing the MLP
architecture for high efficiency and lightweight architecture. Additionally, we
also innovatively crafted a dual project constraint module to mitigate
potential model degradation. Comprehensive experiments demonstrate that PatchAD
achieves state-of-the-art results across multiple real-world multivariate time
series datasets. Our code is publicly
available.\footnote{\url{https://github.com/EmorZz1G/PatchAD}}
\\ ( https://arxiv.org/abs/2401.09793 ,  1384kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09796
Date: Thu, 18 Jan 2024 08:33:09 GMT   (2100kb,D)

Title: A Fast, Performant, Secure Distributed Training Framework For Large
  Language Model
Authors: Wei Huang, Yinggui Wang, Anda Cheng, Aihui Zhou, Chaofan Yu, Lei Wang
Categories: cs.LG cs.CR
Comments: Accept ICASSP2024
\\
  The distributed (federated) LLM is an important method for co-training the
domain-specific LLM using siloed data. However, maliciously stealing model
parameters and data from the server or client side has become an urgent problem
to be solved. In this paper, we propose a secure distributed LLM based on model
slicing. In this case, we deploy the Trusted Execution Environment (TEE) on
both the client and server side, and put the fine-tuned structure (LoRA or
embedding of P-tuning v2) into the TEE. Then, secure communication is executed
in the TEE and general environments through lightweight encryption. In order to
further reduce the equipment cost as well as increase the model performance and
accuracy, we propose a split fine-tuning scheme. In particular, we split the
LLM by layers and place the latter layers in a server-side TEE (the client does
not need a TEE). We then combine the proposed Sparsification Parameter
Fine-tuning (SPF) with the LoRA part to improve the accuracy of the downstream
task. Numerous experiments have shown that our method guarantees accuracy while
maintaining security.
\\ ( https://arxiv.org/abs/2401.09796 ,  2100kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09870
Date: Thu, 18 Jan 2024 10:33:30 GMT   (2922kb,D)

Title: Reconciling Spatial and Temporal Abstractions for Goal Representation
Authors: Mehdi Zadem, Sergio Mover, Sao Mai Nguyen
Categories: cs.LG cs.AI
Comments: Accepted for publication in ICLR 2024
\\
  Goal representation affects the performance of Hierarchical Reinforcement
Learning (HRL) algorithms by decomposing the complex learning problem into
easier subtasks. Recent studies show that representations that preserve
temporally abstract environment dynamics are successful in solving difficult
problems and provide theoretical guarantees for optimality. These methods
however cannot scale to tasks where environment dynamics increase in complexity
i.e. the temporally abstract transition relations depend on larger number of
variables. On the other hand, other efforts have tried to use spatial
abstraction to mitigate the previous issues. Their limitations include
scalability to high dimensional environments and dependency on prior knowledge.
  In this paper, we propose a novel three-layer HRL algorithm that introduces,
at different levels of the hierarchy, both a spatial and a temporal goal
abstraction. We provide a theoretical study of the regret bounds of the learned
policies. We evaluate the approach on complex continuous control tasks,
demonstrating the effectiveness of spatial and temporal abstractions learned by
this approach.
\\ ( https://arxiv.org/abs/2401.09870 ,  2922kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09881
Date: Thu, 18 Jan 2024 10:53:45 GMT   (3795kb,D)

Title: GA-SmaAt-GNet: Generative Adversarial Small Attention GNet for Extreme
  Precipitation Nowcasting
Authors: Eloy Reulen, Siamak Mehrkanoon
Categories: cs.LG physics.ao-ph
Comments: 16 pages, 11 figurs
ACM-class: I.2; I.5
\\
  In recent years, data-driven modeling approaches have gained considerable
traction in various meteorological applications, particularly in the realm of
weather forecasting. However, these approaches often encounter challenges when
dealing with extreme weather conditions. In light of this, we propose
GA-SmaAt-GNet, a novel generative adversarial architecture that makes use of
two methodologies aimed at enhancing the performance of deep learning models
for extreme precipitation nowcasting. Firstly, it uses a novel SmaAt-GNet built
upon the successful SmaAt-UNet architecture as generator. This network
incorporates precipitation masks (binarized precipitation maps) as an
additional data source, leveraging valuable information for improved
predictions. Additionally, GA-SmaAt-GNet utilizes an attention-augmented
discriminator inspired by the well-established Pix2Pix architecture.
Furthermore, we assess the performance of GA-SmaAt-GNet using real-life
precipitation dataset from the Netherlands. Our experimental results reveal a
notable improvement in both overall performance and for extreme precipitation
events. Furthermore, we conduct uncertainty analysis on the proposed
GA-SmaAt-GNet model as well as on the precipitation dataset, providing
additional insights into the predictive capabilities of the model. Finally, we
offer further insights into the predictions of our proposed model using
Grad-CAM. This visual explanation technique generates activation heatmaps,
illustrating areas of the input that are more activated for various parts of
the network.
\\ ( https://arxiv.org/abs/2401.09881 ,  3795kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09886
Date: Thu, 18 Jan 2024 10:59:18 GMT   (1425kb,D)

Title: Cooperative Edge Caching Based on Elastic Federated and Multi-Agent Deep
  Reinforcement Learning in Next-Generation Network
Authors: Qiong Wu, Wenhua Wang, Pingyi Fan, Qiang Fan, Huiling Zhu, Khaled B.
  Letaief
Categories: cs.LG cs.AI
Comments: This paper has been submitted to IEEE TNSM. The source code has been
  released at:
  https://github.com/qiongwu86/Edge-Caching-Based-on-Multi-Agent-Deep-Reinforcement-Learning-and-Federated-Learning
\\
  Edge caching is a promising solution for next-generation networks by
empowering caching units in small-cell base stations (SBSs), which allows user
equipments (UEs) to fetch users' requested contents that have been pre-cached
in SBSs. It is crucial for SBSs to predict accurate popular contents through
learning while protecting users' personal information. Traditional federated
learning (FL) can protect users' privacy but the data discrepancies among UEs
can lead to a degradation in model quality. Therefore, it is necessary to train
personalized local models for each UE to predict popular contents accurately.
In addition, the cached contents can be shared among adjacent SBSs in
next-generation networks, thus caching predicted popular contents in different
SBSs may affect the cost to fetch contents. Hence, it is critical to determine
where the popular contents are cached cooperatively. To address these issues,
we propose a cooperative edge caching scheme based on elastic federated and
multi-agent deep reinforcement learning (CEFMR) to optimize the cost in the
network. We first propose an elastic FL algorithm to train the personalized
model for each UE, where adversarial autoencoder (AAE) model is adopted for
training to improve the prediction accuracy, then {a popular} content
prediction algorithm is proposed to predict the popular contents for each SBS
based on the trained AAE model. Finally, we propose a multi-agent deep
reinforcement learning (MADRL) based algorithm to decide where the predicted
popular contents are collaboratively cached among SBSs. Our experimental
results demonstrate the superiority of our proposed scheme to existing baseline
caching schemes.
\\ ( https://arxiv.org/abs/2401.09886 ,  1425kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09916
Date: Thu, 18 Jan 2024 11:57:05 GMT   (299kb,D)

Title: Enabling On-device Continual Learning with Binary Neural Networks
Authors: Lorenzo Vorabbi, Davide Maltoni, Guido Borghi, Stefano Santi
Categories: cs.LG
\\
  On-device learning remains a formidable challenge, especially when dealing
with resource-constrained devices that have limited computational capabilities.
This challenge is primarily rooted in two key issues: first, the memory
available on embedded devices is typically insufficient to accommodate the
memory-intensive back-propagation algorithm, which often relies on
floating-point precision. Second, the development of learning algorithms on
models with extreme quantization levels, such as Binary Neural Networks (BNNs),
is critical due to the drastic reduction in bit representation. In this study,
we propose a solution that combines recent advancements in the field of
Continual Learning (CL) and Binary Neural Networks to enable on-device training
while maintaining competitive performance. Specifically, our approach leverages
binary latent replay (LR) activations and a novel quantization scheme that
significantly reduces the number of bits required for gradient computation. The
experimental validation demonstrates a significant accuracy improvement in
combination with a noticeable reduction in memory requirement, confirming the
suitability of our approach in expanding the practical applications of deep
learning in real-world scenarios.
\\ ( https://arxiv.org/abs/2401.09916 ,  299kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09918
Date: Thu, 18 Jan 2024 12:03:19 GMT   (2674kb,D)

Title: Probabilistic Truly Unordered Rule Sets
Authors: Lincen Yang, Matthijs van Leeuwen
Categories: cs.LG
Comments: Submitted to JMLR
\\
  Rule set learning has recently been frequently revisited because of its
interpretability. Existing methods have several shortcomings though. First,
most existing methods impose orders among rules, either explicitly or
implicitly, which makes the models less comprehensible. Second, due to the
difficulty of handling conflicts caused by overlaps (i.e., instances covered by
multiple rules), existing methods often do not consider probabilistic rules.
Third, learning classification rules for multi-class target is understudied, as
most existing methods focus on binary classification or multi-class
classification via the ``one-versus-rest" approach.
  To address these shortcomings, we propose TURS, for Truly Unordered Rule
Sets. To resolve conflicts caused by overlapping rules, we propose a novel
model that exploits the probabilistic properties of our rule sets, with the
intuition of only allowing rules to overlap if they have similar probabilistic
outputs. We next formalize the problem of learning a TURS model based on the
MDL principle and develop a carefully designed heuristic algorithm. We
benchmark against a wide range of rule-based methods and demonstrate that our
method learns rule sets that have lower model complexity and highly competitive
predictive performance. In addition, we empirically show that rules in our
model are empirically ``independent" and hence truly unordered.
\\ ( https://arxiv.org/abs/2401.09918 ,  2674kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09940
Date: Thu, 18 Jan 2024 12:41:58 GMT   (1630kb)

Title: Biases in Expected Goals Models Confound Finishing Ability
Authors: Jesse Davis and Pieter Robberechts
Categories: cs.LG stat.AP
\\
  Expected Goals (xG) has emerged as a popular tool for evaluating finishing
skill in soccer analytics. It involves comparing a player's cumulative xG with
their actual goal output, where consistent overperformance indicates strong
finishing ability. However, the assessment of finishing skill in soccer using
xG remains contentious due to players' difficulty in consistently outperforming
their cumulative xG. In this paper, we aim to address the limitations and
nuances surrounding the evaluation of finishing skill using xG statistics.
Specifically, we explore three hypotheses: (1) the deviation between actual and
expected goals is an inadequate metric due to the high variance of shot
outcomes and limited sample sizes, (2) the inclusion of all shots in cumulative
xG calculation may be inappropriate, and (3) xG models contain biases arising
from interdependencies in the data that affect skill measurement. We found that
sustained overperformance of cumulative xG requires both high shot volumes and
exceptional finishing, including all shot types can obscure the finishing
ability of proficient strikers, and that there is a persistent bias that makes
the actual and expected goals closer for excellent finishers than it really is.
Overall, our analysis indicates that we need more nuanced quantitative
approaches for investigating a player's finishing ability, which we achieved
using a technique from AI fairness to learn an xG model that is calibrated for
multiple subgroups of players. As a concrete use case, we show that (1) the
standard biased xG model underestimates Messi's GAX by 17% and (2) Messi's GAX
is 27% higher than the typical elite high-shot-volume attacker, indicating that
Messi is even a more exceptional finisher than people commonly believed.
\\ ( https://arxiv.org/abs/2401.09940 ,  1630kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09943
Date: Thu, 18 Jan 2024 12:45:46 GMT   (1216kb,D)

Title: Infinite-Horizon Graph Filters: Leveraging Power Series to Enhance
  Sparse Information Aggregation
Authors: Ruizhe Zhang, Xinke Jiang, Yuchen Fang, Jiayuan Luo, Yongxin Xu,
  Yichen Zhu, Xu Chu, Junfeng Zhao and Yasha Zhao
Categories: cs.LG cs.SI
Comments: v1
\\
  Graph Neural Networks (GNNs) have shown considerable effectiveness in a
variety of graph learning tasks, particularly those based on the
message-passing approach in recent years. However, their performance is often
constrained by a limited receptive field, a challenge that becomes more acute
in the presence of sparse graphs. In light of the power series, which possesses
infinite expansion capabilities, we propose a novel \underline{G}raph
\underline{P}ower \underline{F}ilter \underline{N}eural Network (GPFN) that
enhances node classification by employing a power series graph filter to
augment the receptive field. Concretely, our GPFN designs a new way to build a
graph filter with an infinite receptive field based on the convergence power
series, which can be analyzed in the spectral and spatial domains. Besides, we
theoretically prove that our GPFN is a general framework that can integrate any
power series and capture long-range dependencies. Finally, experimental results
on three datasets demonstrate the superiority of our GPFN over state-of-the-art
baselines.
\\ ( https://arxiv.org/abs/2401.09943 ,  1216kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09944
Date: Thu, 18 Jan 2024 12:46:26 GMT   (16151kb,D)

Title: WindSeer: Real-time volumetric wind prediction over complex terrain
  aboard a small UAV
Authors: Florian Achermann, Thomas Stastny, Bogdan Danciu, Andrey Kolobov, Jen
  Jen Chung, Roland Siegwart, and Nicholas Lawrance
Categories: cs.LG cs.AI cs.RO
\\
  Real-time high-resolution wind predictions are beneficial for various
applications including safe manned and unmanned aviation. Current weather
models require too much compute and lack the necessary predictive capabilities
as they are valid only at the scale of multiple kilometers and hours - much
lower spatial and temporal resolutions than these applications require. Our
work, for the first time, demonstrates the ability to predict low-altitude wind
in real-time on limited-compute devices, from only sparse measurement data. We
train a neural network, WindSeer, using only synthetic data from computational
fluid dynamics simulations and show that it can successfully predict real wind
fields over terrain with known topography from just a few noisy and spatially
clustered wind measurements. WindSeer can generate accurate predictions at
different resolutions and domain sizes on previously unseen topography without
retraining. We demonstrate that the model successfully predicts historical wind
data collected by weather stations and wind measured onboard drones.
\\ ( https://arxiv.org/abs/2401.09944 ,  16151kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09945
Date: Thu, 18 Jan 2024 12:47:13 GMT   (782kb,D)

Title: HGAttack: Transferable Heterogeneous Graph Adversarial Attack
Authors: He Zhao, Zhiwei Zeng, Yongwei Wang, Deheng Ye and Chunyan Miao
Categories: cs.LG cs.CR cs.IR
\\
  Heterogeneous Graph Neural Networks (HGNNs) are increasingly recognized for
their performance in areas like the web and e-commerce, where resilience
against adversarial attacks is crucial. However, existing adversarial attack
methods, which are primarily designed for homogeneous graphs, fall short when
applied to HGNNs due to their limited ability to address the structural and
semantic complexity of HGNNs. This paper introduces HGAttack, the first
dedicated gray box evasion attack method for heterogeneous graphs. We design a
novel surrogate model to closely resemble the behaviors of the target HGNN and
utilize gradient-based methods for perturbation generation. Specifically, the
proposed surrogate model effectively leverages heterogeneous information by
extracting meta-path induced subgraphs and applying GNNs to learn node
embeddings with distinct semantics from each subgraph. This approach improves
the transferability of generated attacks on the target HGNN and significantly
reduces memory costs. For perturbation generation, we introduce a
semantics-aware mechanism that leverages subgraph gradient information to
autonomously identify vulnerable edges across a wide range of relations within
a constrained perturbation budget. We validate HGAttack's efficacy with
comprehensive experiments on three datasets, providing empirical analyses of
its generated perturbations. Outperforming baseline methods, HGAttack
demonstrated significant efficacy in diminishing the performance of target HGNN
models, affirming the effectiveness of our approach in evaluating the
robustness of HGNNs against adversarial attacks.
\\ ( https://arxiv.org/abs/2401.09945 ,  782kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09949
Date: Thu, 18 Jan 2024 12:51:38 GMT   (4315kb,D)

Title: SymbolNet: Neural Symbolic Regression with Adaptive Dynamic Pruning
Authors: Ho Fung Tsoi, Vladimir Loncar, Sridhara Dasu, Philip Harris
Categories: cs.LG hep-ex physics.ins-det
Comments: 11 pages. Submitted to IEEE TNNLS, under review
\\
  Contrary to the use of genetic programming, the neural network approach to
symbolic regression can scale well with high input dimension and leverage
gradient methods for faster equation searching. Common ways of constraining
expression complexity have relied on multistage pruning methods with
fine-tuning, but these often lead to significant performance loss. In this
work, we propose SymbolNet, a neural network approach to symbolic regression in
a novel framework that enables dynamic pruning of model weights, input
features, and mathematical operators in a single training, where both training
loss and expression complexity are optimized simultaneously. We introduce a
sparsity regularization term per pruning type, which can adaptively adjust its
own strength and lead to convergence to a target sparsity level. In contrast to
most existing symbolic regression methods that cannot efficiently handle
datasets with more than $O$(10) inputs, we demonstrate the effectiveness of our
model on the LHC jet tagging task (16 inputs), MNIST (784 inputs), and SVHN
(3072 inputs).
\\ ( https://arxiv.org/abs/2401.09949 ,  4315kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09953
Date: Thu, 18 Jan 2024 12:58:53 GMT   (460kb,D)

Title: Through the Dual-Prism: A Spectral Perspective on Graph Data
  Augmentation for Graph Classification
Authors: Yutong Xia, Runpeng Yu, Yuxuan Liang, Xavier Bresson, Xinchao Wang,
  Roger Zimmermann
Categories: cs.LG
\\
  Graph Neural Networks (GNNs) have become the preferred tool to process graph
data, with their efficacy being boosted through graph data augmentation
techniques. Despite the evolution of augmentation methods, issues like graph
property distortions and restricted structural changes persist. This leads to
the question: Is it possible to develop more property-conserving and
structure-sensitive augmentation methods? Through a spectral lens, we
investigate the interplay between graph properties, their augmentation, and
their spectral behavior, and found that keeping the low-frequency eigenvalues
unchanged can preserve the critical properties at a large scale when generating
augmented graphs. These observations inform our introduction of the Dual-Prism
(DP) augmentation method, comprising DP-Noise and DP-Mask, which adeptly
retains essential graph properties while diversifying augmented graphs.
Extensive experiments validate the efficiency of our approach, providing a new
and promising direction for graph data augmentation.
\\ ( https://arxiv.org/abs/2401.09953 ,  460kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09986
Date: Thu, 18 Jan 2024 14:02:23 GMT   (1498kb,D)

Title: FLex&Chill: Improving Local Federated Learning Training with Logit
  Chilling
Authors: Kichang Lee, Songkuk Kim, JeongGil Ko
Categories: cs.LG cs.AI
Comments: 9 pages
MSC-class: 68
ACM-class: I.2.11
\\
  Federated learning are inherently hampered by data heterogeneity: non-iid
distributed training data over local clients. We propose a novel model training
approach for federated learning, FLex&Chill, which exploits the Logit Chilling
method. Through extensive evaluations, we demonstrate that, in the presence of
non-iid data characteristics inherent in federated learning systems, this
approach can expedite model convergence and improve inference accuracy.
Quantitatively, from our experiments, we observe up to 6X improvement in the
global federated learning model convergence time, and up to 3.37% improvement
in inference accuracy.
\\ ( https://arxiv.org/abs/2401.09986 ,  1498kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09988
Date: Thu, 18 Jan 2024 14:06:29 GMT   (3865kb,D)

Title: Developing an AI-based Integrated System for Bee Health Evaluation
Authors: Andrew Liang
Categories: cs.LG cs.CV cs.SD eess.AS
\\
  Honey bees pollinate about one-third of the world's food supply, but bee
colonies have alarmingly declined by nearly 40% over the past decade due to
several factors, including pesticides and pests. Traditional methods for
monitoring beehives, such as human inspection, are subjective, disruptive, and
time-consuming. To overcome these limitations, artificial intelligence has been
used to assess beehive health. However, previous studies have lacked an
end-to-end solution and primarily relied on data from a single source, either
bee images or sounds. This study introduces a comprehensive system consisting
of bee object detection and health evaluation. Additionally, it utilized a
combination of visual and audio signals to analyze bee behaviors. An
Attention-based Multimodal Neural Network (AMNN) was developed to adaptively
focus on key features from each type of signal for accurate bee health
assessment. The AMNN achieved an overall accuracy of 92.61%, surpassing eight
existing single-signal Convolutional Neural Networks and Recurrent Neural
Networks. It outperformed the best image-based model by 32.51% and the top
sound-based model by 13.98% while maintaining efficient processing times.
Furthermore, it improved prediction robustness, attaining an F1-score higher
than 90% across all four evaluated health conditions. The study also shows that
audio signals are more reliable than images for assessing bee health. By
seamlessly integrating AMNN with image and sound data in a comprehensive bee
health monitoring system, this approach provides a more efficient and
non-invasive solution for the early detection of bee diseases and the
preservation of bee colonies.
\\ ( https://arxiv.org/abs/2401.09988 ,  3865kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10014
Date: Thu, 18 Jan 2024 14:31:11 GMT   (1021kb,D)

Title: Optimizing Medication Decisions for Patients with Atrial Fibrillation
  through Path Development Network
Authors: Tian Xie
Categories: cs.LG eess.SP
Comments: Master's thesis
\\
  Atrial fibrillation (AF) is a common cardiac arrhythmia characterized by
rapid and irregular contractions of the atria. It significantly elevates the
risk of strokes due to slowed blood flow in the atria, especially in the left
atrial appendage, which is prone to blood clot formation. Such clots can
migrate into cerebral arteries, leading to ischemic stroke. To assess whether
AF patients should be prescribed anticoagulants, doctors often use the
CHA2DS2-VASc scoring system. However, anticoagulant use must be approached with
caution as it can impact clotting functions. This study introduces a machine
learning algorithm that predicts whether patients with AF should be recommended
anticoagulant therapy using 12-lead ECG data. In this model, we use STOME to
enhance time-series data and then process it through a Convolutional Neural
Network (CNN). By incorporating a path development layer, the model achieves a
specificity of 30.6% under the condition of an NPV of 1. In contrast, LSTM
algorithms without path development yield a specificity of only 2.7% under the
same NPV condition.
\\ ( https://arxiv.org/abs/2401.10014 ,  1021kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10119
Date: Thu, 18 Jan 2024 16:50:55 GMT   (411kb,D)

Title: Towards Principled Graph Transformers
Authors: Luis M\"uller and Christopher Morris
Categories: cs.LG cs.AI
\\
  Graph learning architectures based on the k-dimensional Weisfeiler-Leman
(k-WL) hierarchy offer a theoretically well-understood expressive power.
However, such architectures often fail to deliver solid predictive performance
on real-world tasks, limiting their practical impact. In contrast, global
attention-based models such as graph transformers demonstrate strong
performance in practice, but comparing their expressive power with the k-WL
hierarchy remains challenging, particularly since these architectures rely on
positional or structural encodings for their expressivity and predictive
performance. To address this, we show that the recently proposed Edge
Transformer, a global attention model operating on node pairs instead of nodes,
has at least 3-WL expressive power. Empirically, we demonstrate that the Edge
Transformer surpasses other theoretically aligned architectures regarding
predictive performance while not relying on positional or structural encodings.
\\ ( https://arxiv.org/abs/2401.10119 ,  411kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10134
Date: Thu, 18 Jan 2024 17:03:59 GMT   (280kb,D)

Title: Spatial-Temporal Large Language Model for Traffic Prediction
Authors: Chenxi Liu, Sun Yang, Qianxiong Xu, Zhishuai Li, Cheng Long, Ziyue Li,
  Rui Zhao
Categories: cs.LG cs.CL
\\
  Traffic prediction, a critical component for intelligent transportation
systems, endeavors to foresee future traffic at specific locations using
historical data. Although existing traffic prediction models often emphasize
developing complex neural network structures, their accuracy has not seen
improvements accordingly. Recently, Large Language Models (LLMs) have shown
outstanding capabilities in time series analysis. Differing from existing
models, LLMs progress mainly through parameter expansion and extensive
pre-training while maintaining their fundamental structures. In this paper, we
propose a Spatial-Temporal Large Language Model (ST-LLM) for traffic
prediction. Specifically, ST-LLM redefines the timesteps at each location as
tokens and incorporates a spatial-temporal embedding module to learn the
spatial location and global temporal representations of tokens. Then these
representations are fused to provide each token with unified spatial and
temporal information. Furthermore, we propose a novel partially frozen
attention strategy of the LLM, which is designed to capture spatial-temporal
dependencies for traffic prediction. Comprehensive experiments on real traffic
datasets offer evidence that ST-LLM outperforms state-of-the-art models.
Notably, the ST-LLM also exhibits robust performance in both few-shot and
zero-shot prediction scenarios.
\\ ( https://arxiv.org/abs/2401.10134 ,  280kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10149
Date: Thu, 18 Jan 2024 17:22:22 GMT   (1215kb,D)

Title: Multi-Agent Reinforcement Learning for Maritime Operational Technology
  Cyber Security
Authors: Alec Wilson, Ryan Menzies, Neela Morarji, David Foster, Marco Casassa
  Mont, Esin Turkbeyler, Lisa Gralewski
Categories: cs.LG cs.CR cs.MA
Comments: 13 pages, 7 figures, Proceedings of the Conference on Applied Machine
  Learning in Information Security 2023 (CAMLIS)
\\
  This paper demonstrates the potential for autonomous cyber defence to be
applied on industrial control systems and provides a baseline environment to
further explore Multi-Agent Reinforcement Learning's (MARL) application to this
problem domain. It introduces a simulation environment, IPMSRL, of a generic
Integrated Platform Management System (IPMS) and explores the use of MARL for
autonomous cyber defence decision-making on generic maritime based IPMS
Operational Technology (OT). OT cyber defensive actions are less mature than
they are for Enterprise IT. This is due to the relatively brittle nature of OT
infrastructure originating from the use of legacy systems, design-time
engineering assumptions, and lack of full-scale modern security controls. There
are many obstacles to be tackled across the cyber landscape due to continually
increasing cyber-attack sophistication and the limitations of traditional
IT-centric cyber defence solutions. Traditional IT controls are rarely deployed
on OT infrastructure, and where they are, some threats aren't fully addressed.
In our experiments, a shared critic implementation of Multi Agent Proximal
Policy Optimisation (MAPPO) outperformed Independent Proximal Policy
Optimisation (IPPO). MAPPO reached an optimal policy (episode outcome mean of
1) after 800K timesteps, whereas IPPO was only able to reach an episode outcome
mean of 0.966 after one million timesteps. Hyperparameter tuning greatly
improved training performance. Across one million timesteps the tuned
hyperparameters reached an optimal policy whereas the default hyperparameters
only managed to win sporadically, with most simulations resulting in a draw. We
tested a real-world constraint, attack detection alert success, and found that
when alert success probability is reduced to 0.75 or 0.9, the MARL defenders
were still able to win in over 97.5% or 99.5% of episodes, respectively.
\\ ( https://arxiv.org/abs/2401.10149 ,  1215kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10155
Date: Wed, 17 Jan 2024 07:21:36 GMT   (1728kb,D)

Title: A novel hybrid time-varying graph neural network for traffic flow
  forecasting
Authors: Ben Ao Dai, Bao-Lin Ye
Categories: cs.LG
Comments: 12 pages 1figures
\\
  Real-time and accurate traffic flow prediction is the foundation for ensuring
the efficient operation of intelligent transportation systems.In existing
traffic flow prediction methods based on graph neural networks (GNNs),
pre-defined graphs were usually used to describe the spatial correlations of
different traffic nodes in urban road networks. However, the ability of
pre-defined graphs used to describe spatial correlation was limited by prior
knowledge and graph generation methods. Although time-varying graphs based on
data-driven learning can partially overcome the drawbacks of pre-defined
graphs, the learning ability of existing adaptive graphs was limited. For
example, time-varying graphs cannot adequately capture the inherent spatial
correlations in traffic flow data.In order to solve these problems, we have
proposed a hybrid time-varying graph neural network (HTVGNN) for traffic flow
prediction.
\\ ( https://arxiv.org/abs/2401.10155 ,  1728kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10176
Date: Thu, 18 Jan 2024 18:05:35 GMT   (147kb)

Title: Comprehensive OOD Detection Improvements
Authors: Anish Lakkapragada, Amol Khanna, Edward Raff, Nathan Inkawhich
Categories: cs.LG cs.CV
\\
  As machine learning becomes increasingly prevalent in impactful decisions,
recognizing when inference data is outside the model's expected input
distribution is paramount for giving context to predictions.
Out-of-distribution (OOD) detection methods have been created for this task.
Such methods can be split into representation-based or logit-based methods from
whether they respectively utilize the model's embeddings or predictions for OOD
detection. In contrast to most papers which solely focus on one such group, we
address both. We employ dimensionality reduction on feature embeddings in
representation-based methods for both time speedups and improved performance.
Additionally, we propose DICE-COL, a modification of the popular logit-based
method Directed Sparsification (DICE) that resolves an unnoticed flaw. We
demonstrate the effectiveness of our methods on the OpenOODv1.5 benchmark
framework, where they significantly improve performance and set
state-of-the-art results.
\\ ( https://arxiv.org/abs/2401.10176 ,  147kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10185
Date: Thu, 18 Jan 2024 18:12:35 GMT   (15762kb,D)

Title: Transfer Learning in Human Activity Recognition: A Survey
Authors: Sourish Gunesh Dhekane, Thomas Ploetz
Categories: cs.LG eess.SP
Comments: 40 pages, 5 figures, 7 tables
\\
  Sensor-based human activity recognition (HAR) has been an active research
area, owing to its applications in smart environments, assisted living,
fitness, healthcare, etc. Recently, deep learning based end-to-end training has
resulted in state-of-the-art performance in domains such as computer vision and
natural language, where large amounts of annotated data are available. However,
large quantities of annotated data are not available for sensor-based HAR.
Moreover, the real-world settings on which the HAR is performed differ in terms
of sensor modalities, classification tasks, and target users. To address this
problem, transfer learning has been employed extensively. In this survey, we
focus on these transfer learning methods in the application domains of smart
home and wearables-based HAR. In particular, we provide a problem-solution
perspective by categorizing and presenting the works in terms of their
contributions and the challenges they address. We also present an updated view
of the state-of-the-art for both application domains. Based on our analysis of
205 papers, we highlight the gaps in the literature and provide a roadmap for
addressing them. This survey provides a reference to the HAR community, by
summarizing the existing works and providing a promising research agenda.
\\ ( https://arxiv.org/abs/2401.10185 ,  15762kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10191
Date: Thu, 18 Jan 2024 18:25:29 GMT   (6944kb,D)

Title: Divide and not forget: Ensemble of selectively trained experts in
  Continual Learning
Authors: Grzegorz Rype\'s\'c, Sebastian Cygert, Valeriya Khan, Tomasz
  Trzci\'nski, Bartosz Zieli\'nski, Bart{\l}omiej Twardowski
Categories: cs.LG cs.CV
Comments: Accepted to ICLR2024 (main track), code is available at:
  https://github.com/grypesc/SEED
\\
  Class-incremental learning is becoming more popular as it helps models widen
their applicability while not forgetting what they already know. A trend in
this area is to use a mixture-of-expert technique, where different models work
together to solve the task. However, the experts are usually trained all at
once using whole task data, which makes them all prone to forgetting and
increasing computational burden. To address this limitation, we introduce a
novel approach named SEED. SEED selects only one, the most optimal expert for a
considered task, and uses data from this task to fine-tune only this expert.
For this purpose, each expert represents each class with a Gaussian
distribution, and the optimal expert is selected based on the similarity of
those distributions. Consequently, SEED increases diversity and heterogeneity
within the experts while maintaining the high stability of this ensemble
method. The extensive experiments demonstrate that SEED achieves
state-of-the-art performance in exemplar-free settings across various
scenarios, showing the potential of expert diversification through data in
continual learning.
\\ ( https://arxiv.org/abs/2401.10191 ,  6944kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10216
Date: Thu, 18 Jan 2024 18:57:10 GMT   (169kb,D)

Title: Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt
  Tensor Products
Authors: Shengjie Luo, Tianlang Chen, Aditi S. Krishnapriyan
Categories: cs.LG cond-mat.mtrl-sci math.GR physics.chem-ph q-bio.BM
Comments: 36 pages; ICLR 2024 (Spotlight Presentation); Code:
  https://github.com/lsj2408/Gaunt-Tensor-Product
\\
  Developing equivariant neural networks for the E(3) group plays an important
role in modeling 3D data across real-world applications. Enforcing this
equivariance primarily involves the tensor products of irreducible
representations (irreps). However, the computational complexity of such
operations increases significantly as higher-order tensors are used. In this
work, we propose a systematic approach to substantially accelerate the
computation of the tensor products of irreps. We mathematically connect the
commonly used Clebsch-Gordan coefficients to the Gaunt coefficients, which are
integrals of products of three spherical harmonics. Through Gaunt coefficients,
the tensor product of irreps becomes equivalent to the multiplication between
spherical functions represented by spherical harmonics. This perspective
further allows us to change the basis for the equivariant operations from
spherical harmonics to a 2D Fourier basis. Consequently, the multiplication
between spherical functions represented by a 2D Fourier basis can be
efficiently computed via the convolution theorem and Fast Fourier Transforms.
This transformation reduces the complexity of full tensor products of irreps
from $\mathcal{O}(L^6)$ to $\mathcal{O}(L^3)$, where $L$ is the max degree of
irreps. Leveraging this approach, we introduce the Gaunt Tensor Product, which
serves as a new method to construct efficient equivariant operations across
different model architectures. Our experiments on the Open Catalyst Project and
3BPA datasets demonstrate both the increased efficiency and improved
performance of our approach.
\\ ( https://arxiv.org/abs/2401.10216 ,  169kb)
%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-
------------------------------------------------------------------------------
\\
arXiv:2401.09424 (*cross-listing*)
Date: Thu, 30 Nov 2023 02:20:16 GMT   (2818kb,D)

Title: Precipitation Prediction Using an Ensemble of Lightweight Learners
Authors: Xinzhe Li, Sun Rui, Yiming Niu, Yao Liu
Categories: physics.ao-ph cs.AI cs.CV cs.LG
\\
  Precipitation prediction plays a crucial role in modern agriculture and
industry. However, it poses significant challenges due to the diverse patterns
and dynamics in time and space, as well as the scarcity of high precipitation
events.
  To address this challenge, we propose an ensemble learning framework that
leverages multiple learners to capture the diverse patterns of precipitation
distribution. Specifically, the framework consists of a precipitation predictor
with multiple lightweight heads (learners) and a controller that combines the
outputs from these heads. The learners and the controller are separately
optimized with a proposed 3-stage training scheme.
  By utilizing provided satellite images, the proposed approach can effectively
model the intricate rainfall patterns, especially for high precipitation
events. It achieved 1st place on the core test as well as the nowcasting
leaderboards of the Weather4Cast 2023 competition. For detailed implementation,
please refer to our GitHub repository at:
https://github.com/lxz1217/weather4cast-2023-lxz.
\\ ( https://arxiv.org/abs/2401.09424 ,  2818kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09435 (*cross-listing*)
Date: Tue, 19 Dec 2023 18:17:59 GMT   (1052kb,D)

Title: Reasoning with random sets: An agenda for the future
Authors: Fabio Cuzzolin
Categories: math.ST cs.AI stat.ML stat.TH
Comments: 94 pages, 17 figures
MSC-class: 62A01, 62A86, 60A05, 60C05, 60D05, 60E05
\\
  In this paper, we discuss a potential agenda for future work in the theory of
random sets and belief functions, touching upon a number of focal issues: the
development of a fully-fledged theory of statistical reasoning with random
sets, including the generalisation of logistic regression and of the classical
laws of probability; the further development of the geometric approach to
uncertainty, to include general random sets, a wider range of uncertainty
measures and alternative geometric representations; the application of this new
theory to high-impact areas such as climate change, machine learning and
statistical learning theory.
\\ ( https://arxiv.org/abs/2401.09435 ,  1052kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09442 (*cross-listing*)
Date: Wed, 20 Dec 2023 12:46:30 GMT   (8966kb,D)

Title: Object Attribute Matters in Visual Question Answering
Authors: Peize Li, Qingyi Si, Peng Fu, Zheng Lin, Yan Wang
Categories: cs.CV cs.AI
Comments: AAAI 2024
\\
  Visual question answering is a multimodal task that requires the joint
comprehension of visual and textual information. However, integrating visual
and textual semantics solely through attention layers is insufficient to
comprehensively understand and align information from both modalities.
Intuitively, object attributes can naturally serve as a bridge to unify them,
which has been overlooked in previous research. In this paper, we propose a
novel VQA approach from the perspective of utilizing object attribute, aiming
to achieve better object-level visual-language alignment and multimodal scene
understanding. Specifically, we design an attribute fusion module and a
contrastive knowledge distillation module. The attribute fusion module
constructs a multimodal graph neural network to fuse attributes and visual
features through message passing. The enhanced object-level visual features
contribute to solving fine-grained problem like counting-question. The better
object-level visual-language alignment aids in understanding multimodal scenes,
thereby improving the model's robustness. Furthermore, to augment scene
understanding and the out-of-distribution performance, the contrastive
knowledge distillation module introduces a series of implicit knowledge. We
distill knowledge into attributes through contrastive loss, which further
strengthens the representation learning of attribute features and facilitates
visual-linguistic alignment. Intensive experiments on six datasets, COCO-QA,
VQAv2, VQA-CPv2, VQA-CPv1, VQAvs and TDIUC, show the superiority of the
proposed method.
\\ ( https://arxiv.org/abs/2401.09442 ,  8966kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09443 (*cross-listing*)
Date: Wed, 20 Dec 2023 13:47:08 GMT   (551kb,D)

Title: CRD: Collaborative Representation Distance for Practical Anomaly
  Detection
Authors: Chao Han and Yudong Yan
Categories: cs.CV cs.AI cs.LG
\\
  Visual defect detection plays an important role in intelligent industry.
Patch based methods consider visual images as a collection of image patches
according to positions, which have stronger discriminative ability for small
defects in products, e.g. scratches on pills. However, the nearest neighbor
search for the query image and the stored patches will occupy $O(n)$ complexity
in terms of time and space requirements, posing strict challenges for
deployment in edge environments. In this paper, we propose an alternative
approach to the distance calculation of image patches via collaborative
representation models. Starting from the nearest neighbor distance with $L_0$
constraint, we relax the constraint to $L_2$ constraint and solve the distance
quickly in close-formed without actually accessing the original stored
collection of image patches. Furthermore, we point out that the main
computational burden of this close-formed solution can be pre-computed by
high-performance server before deployment. Consequently, the distance
calculation on edge devices only requires a simple matrix multiplication, which
is extremely lightweight and GPU-friendly. Performance on real industrial
scenarios demonstrates that compared to the existing state-of-the-art methods,
this distance achieves several hundred times improvement in computational
efficiency with slight performance drop, while greatly reducing memory
overhead.
\\ ( https://arxiv.org/abs/2401.09443 ,  551kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09446 (*cross-listing*)
Date: Wed, 20 Dec 2023 17:15:10 GMT   (3118kb,D)

Title: Explainable Multimodal Sentiment Analysis on Bengali Memes
Authors: Kazi Toufique Elahi, Tasnuva Binte Rahman, Shakil Shahriar, Samir
  Sarker, Sajib Kumar Saha Joy, Faisal Muhammad Shah
Categories: cs.CV cs.AI cs.CL cs.LG
\\
  Memes have become a distinctive and effective form of communication in the
digital era, attracting online communities and cutting across cultural
barriers. Even though memes are frequently linked with humor, they have an
amazing capacity to convey a wide range of emotions, including happiness,
sarcasm, frustration, and more. Understanding and interpreting the sentiment
underlying memes has become crucial in the age of information. Previous
research has explored text-based, image-based, and multimodal approaches,
leading to the development of models like CAPSAN and PromptHate for detecting
various meme categories. However, the study of low-resource languages like
Bengali memes remains scarce, with limited availability of publicly accessible
datasets. A recent contribution includes the introduction of the MemoSen
dataset. However, the achieved accuracy is notably low, and the dataset suffers
from imbalanced distribution. In this study, we employed a multimodal approach
using ResNet50 and BanglishBERT and achieved a satisfactory result of 0.71
weighted F1-score, performed comparison with unimodal approaches, and
interpreted behaviors of the models using explainable artificial intelligence
(XAI) techniques.
\\ ( https://arxiv.org/abs/2401.09446 ,  3118kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09450 (*cross-listing*)
Date: Fri, 22 Dec 2023 11:15:16 GMT   (1461kb,D)

Title: Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA
  Initiative
Authors: Norman Zerbe, Lars Ole Schwen, Christian Gei{\ss}ler, Katja Wiesemann,
  Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen,
  Tim-Rasmus Kiehl, Bj\"orn Lindequist, Nora Charlotte Pohlan, Sarah Schmell,
  Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias
  K\"uster, Andr\'e Homeyer, Peter Hufnagl
Categories: cs.CY cs.AI cs.CV cs.HC
\\
  Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 11 AI-based image analysis apps from 6 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.
\\ ( https://arxiv.org/abs/2401.09450 ,  1461kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09451 (*cross-listing*)
Date: Fri, 22 Dec 2023 11:49:39 GMT   (236kb,D)

Title: Diffusion-Driven Generative Framework for Molecular Conformation
  Prediction
Authors: Bobin Yang, Zhenghan Chen
Categories: q-bio.BM cs.AI cs.LG physics.chem-ph
Comments: arXiv admin note: text overlap with arXiv:2105.07246 by other authors
\\
  The task of inferring three-dimensional molecular configurations from their
two-dimensional graph representations is of critical significance in the
domains of computational chemistry and the development of pharmaceuticals. It
contributes fundamentally to our grasp of molecular mechanisms and
interactions. The rapid evolution of machine learning, especially in the realm
of deep generative networks, has catalyzed breakthroughs in the precision of
such predictive modeling. Traditional methodologies typically employ a
bifurcated strategy: initially estimating interatomic distances followed by
sculpting the spatial molecular structure via solving a distance geometry
problem. This sequential approach, however, occasionally fails to capture the
intricacies of local atomic arrangements accurately, thus compromising the
integrity of the resultant structural models. Addressing these deficiencies,
this work introduces an avant-garde generative framework: \method{}, which is
predicated on the diffusion principles found in classical non-equilibrium
thermodynamics. \method{} envisages atoms as discrete entities and is adept at
guiding the reversal of diffusion morphing a distribution of stochastic noise
back into coherent molecular forms through a process akin to a Markov chain.
This transformation begins with the initial representation of a molecular graph
in an abstract latent space, progressing to the realization of the
three-dimensional forms via an elaborate bilevel optimization scheme, tailored
to respect the task's specific requirements.
\\ ( https://arxiv.org/abs/2401.09451 ,  236kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09454 (*cross-listing*)
Date: Fri, 22 Dec 2023 17:34:01 GMT   (22862kb,D)

Title: Voila-A: Aligning Vision-Language Models with User's Gaze Attention
Authors: Kun Yan, Lei Ji, Zeyu Wang, Yuntao Wang, Nan Duan, Shuai Ma
Categories: cs.CV cs.AI cs.CL cs.LG
\\
  In recent years, the integration of vision and language understanding has led
to significant advancements in artificial intelligence, particularly through
Vision-Language Models (VLMs). However, existing VLMs face challenges in
handling real-world applications with complex scenes and multiple objects, as
well as aligning their focus with the diverse attention patterns of human
users. In this paper, we introduce gaze information, feasibly collected by AR
or VR devices, as a proxy for human attention to guide VLMs and propose a novel
approach, Voila-A, for gaze alignment to enhance the interpretability and
effectiveness of these models in real-world applications. First, we collect
hundreds of minutes of gaze data to demonstrate that we can mimic human gaze
modalities using localized narratives. We then design an automatic data
annotation pipeline utilizing GPT-4 to generate the VOILA-COCO dataset.
Additionally, we innovate the Voila Perceiver modules to integrate gaze
information into VLMs while preserving their pretrained knowledge. We evaluate
Voila-A using a hold-out validation set and a newly collected VOILA-GAZE
Testset, which features real-life scenarios captured with a gaze-tracking
device. Our experimental results demonstrate that Voila-A significantly
outperforms several baseline models. By aligning model attention with human
gaze patterns, Voila-A paves the way for more intuitive, user-centric VLMs and
fosters engaging human-AI interaction across a wide range of applications.
\\ ( https://arxiv.org/abs/2401.09454 ,  22862kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09455 (*cross-listing*)
Date: Sat, 23 Dec 2023 03:36:35 GMT   (801kb,D)

Title: Dynamic Routing for Integrated Satellite-Terrestrial Networks: A
  Constrained Multi-Agent Reinforcement Learning Approach
Authors: Yifeng Lyu, Han Hu, Rongfei Fan, Zhi Liu, Jianping An, Shiwen Mao
Categories: cs.NI cs.AI cs.LG cs.SY eess.SY
\\
  The integrated satellite-terrestrial network (ISTN) system has experienced
significant growth, offering seamless communication services in remote areas
with limited terrestrial infrastructure. However, designing a routing scheme
for ISTN is exceedingly difficult, primarily due to the heightened complexity
resulting from the inclusion of additional ground stations, along with the
requirement to satisfy various constraints related to satellite service
quality. To address these challenges, we study packet routing with ground
stations and satellites working jointly to transmit packets, while prioritizing
fast communication and meeting energy efficiency and packet loss requirements.
Specifically, we formulate the problem of packet routing with constraints as a
max-min problem using the Lagrange method. Then we propose a novel constrained
Multi-Agent reinforcement learning (MARL) dynamic routing algorithm named
CMADR, which efficiently balances objective improvement and constraint
satisfaction during the updating of policy and Lagrange multipliers. Finally,
we conduct extensive experiments and an ablation study using the OneWeb and
Telesat mega-constellations. Results demonstrate that CMADR reduces the packet
delay by a minimum of 21% and 15%, while meeting stringent energy consumption
and packet loss rate constraints, outperforming several baseline algorithms.
\\ ( https://arxiv.org/abs/2401.09455 ,  801kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09459 (*cross-listing*)
Date: Sat, 30 Dec 2023 13:45:36 GMT   (760kb,D)

Title: What's my role? Modelling responsibility for AI-based safety-critical
  systems
Authors: Philippa Ryan, Zoe Porter, Joanna Al-Qaddoumi, John McDermid, Ibrahim
  Habli
Categories: cs.CY cs.AI
Comments: 22 pages, 7 figures, 2 tables
ACM-class: I.2.0; K.4.0
\\
  AI-Based Safety-Critical Systems (AI-SCS) are being increasingly deployed in
the real world. These can pose a risk of harm to people and the environment.
Reducing that risk is an overarching priority during development and operation.
As more AI-SCS become autonomous, a layer of risk management via human
intervention has been removed. Following an accident it will be important to
identify causal contributions and the different responsible actors behind those
to learn from mistakes and prevent similar future events. Many authors have
commented on the "responsibility gap" where it is difficult for developers and
manufacturers to be held responsible for harmful behaviour of an AI-SCS. This
is due to the complex development cycle for AI, uncertainty in AI performance,
and dynamic operating environment. A human operator can become a "liability
sink" absorbing blame for the consequences of AI-SCS outputs they weren't
responsible for creating, and may not have understanding of.
  This cross-disciplinary paper considers different senses of responsibility
(role, moral, legal and causal), and how they apply in the context of AI-SCS
safety. We use a core concept (Actor(A) is responsible for Occurrence(O)) to
create role responsibility models, producing a practical method to capture
responsibility relationships and provide clarity on the previously identified
responsibility issues. Our paper demonstrates the approach with two examples: a
retrospective analysis of the Tempe Arizona fatal collision involving an
autonomous vehicle, and a safety focused predictive role-responsibility
analysis for an AI-based diabetes co-morbidity predictor. In both examples our
primary focus is on safety, aiming to reduce unfair or disproportionate blame
being placed on operators or developers. We present a discussion and avenues
for future research.
\\ ( https://arxiv.org/abs/2401.09459 ,  760kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09466 (*cross-listing*)
Date: Tue, 9 Jan 2024 10:20:49 GMT   (2801kb,D)

Title: Self Supervised Vision for Climate Downscaling
Authors: Karandeep Singh, Chaeyoon Jeong, Naufal Shidqi, Sungwon Park, Arjun
  Nellikkattil, Elke Zeller, Meeyoung Cha
Categories: physics.ao-ph cs.AI cs.CV cs.LG
\\
  Climate change is one of the most critical challenges that our planet is
facing today. Rising global temperatures are already bringing noticeable
changes to Earth's weather and climate patterns with an increased frequency of
unpredictable and extreme weather events. Future projections for climate change
research are based on Earth System Models (ESMs), the computer models that
simulate the Earth's climate system. ESMs provide a framework to integrate
various physical systems, but their output is bound by the enormous
computational resources required for running and archiving higher-resolution
simulations. For a given resource budget, the ESMs are generally run on a
coarser grid, followed by a computationally lighter $downscaling$ process to
obtain a finer-resolution output. In this work, we present a deep-learning
model for downscaling ESM simulation data that does not require high-resolution
ground truth data for model optimization. This is realized by leveraging
salient data distribution patterns and the hidden dependencies between weather
variables for an $\textit{individual}$ data point at $\textit{runtime}$.
Extensive evaluation with $2$x, $3$x, and $4$x scaling factors demonstrates
that the proposed model consistently obtains superior performance over that of
various baselines. The improved downscaling performance and no dependence on
high-resolution ground truth data make the proposed method a valuable tool for
climate research and mark it as a promising direction for future research.
\\ ( https://arxiv.org/abs/2401.09466 ,  2801kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09467 (*cross-listing*)
Date: Fri, 5 Jan 2024 10:55:20 GMT   (506kb)

Title: Offline Handwriting Signature Verification: A Transfer Learning and
  Feature Selection Approach
Authors: Fatih Ozyurt, Jafar Majidpour, Tarik A. Rashid, Canan Koc
Categories: cs.CV cs.AI eess.IV
Comments: 11 pages
\\
  Handwritten signature verification poses a formidable challenge in biometrics
and document authenticity. The objective is to ascertain the authenticity of a
provided handwritten signature, distinguishing between genuine and forged ones.
This issue has many applications in sectors such as finance, legal
documentation, and security. Currently, the field of computer vision and
machine learning has made significant progress in the domain of handwritten
signature verification. The outcomes, however, may be enhanced depending on the
acquired findings, the structure of the datasets, and the used models. Four
stages make up our suggested strategy. First, we collected a large dataset of
12600 images from 420 distinct individuals, and each individual has 30
signatures of a certain kind (All authors signatures are genuine). In the
subsequent stage, the best features from each image were extracted using a deep
learning model named MobileNetV2. During the feature selection step, three
selectors neighborhood component analysis (NCA), Chi2, and mutual info (MI)
were used to pull out 200, 300, 400, and 500 features, giving a total of 12
feature vectors. Finally, 12 results have been obtained by applying machine
learning techniques such as SVM with kernels (rbf, poly, and linear), KNN, DT,
Linear Discriminant Analysis, and Naive Bayes. Without employing feature
selection techniques, our suggested offline signature verification achieved a
classification accuracy of 91.3%, whereas using the NCA feature selection
approach with just 300 features it achieved a classification accuracy of 97.7%.
High classification accuracy was achieved using the designed and suggested
model, which also has the benefit of being a self-organized framework.
Consequently, using the optimum minimally chosen features, the proposed method
could identify the best model performance and result validation prediction
vectors.
\\ ( https://arxiv.org/abs/2401.09467 ,  506kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09473 (*cross-listing*)
Date: Fri, 12 Jan 2024 11:05:32 GMT   (976kb)

Title: Business and ethical concerns in domestic Conversational Generative
  AI-empowered multi-robot systems
Authors: Rebekah Rousi, Hooman Samani, Niko M\"akitalo, Ville Vakkuri, Simo
  Linkola, Kai-Kristian Kemell, Paulius Daubaris, Ilenia Fronza, Tommi
  Mikkonen, Pekka Abrahamsson
Categories: cs.CY cs.AI
Comments: 15 pages, 4 figures, International Conference on Software Business
\\
  Business and technology are intricately connected through logic and design.
They are equally sensitive to societal changes and may be devastated by
scandal. Cooperative multi-robot systems (MRSs) are on the rise, allowing
robots of different types and brands to work together in diverse contexts.
Generative artificial intelligence has been a dominant topic in recent
artificial intelligence (AI) discussions due to its capacity to mimic humans
through the use of natural language and the production of media, including deep
fakes. In this article, we focus specifically on the conversational aspects of
generative AI, and hence use the term Conversational Generative artificial
intelligence (CGI). Like MRSs, CGIs have enormous potential for revolutionizing
processes across sectors and transforming the way humans conduct business. From
a business perspective, cooperative MRSs alone, with potential conflicts of
interest, privacy practices, and safety concerns, require ethical examination.
MRSs empowered by CGIs demand multi-dimensional and sophisticated methods to
uncover imminent ethical pitfalls. This study focuses on ethics in
CGI-empowered MRSs while reporting the stages of developing the MORUL model.
\\ ( https://arxiv.org/abs/2401.09473 ,  976kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09476 (*cross-listing*)
Date: Sun, 14 Jan 2024 04:16:01 GMT   (292kb)

Title: A Framework for Agricultural Food Supply Chain using Blockchain
Authors: Sudarssan N
Categories: cs.CR cs.AI
Comments: 5 Pages, 5 figures, Under Review
\\
  The main aim of the paper is to create a trust and transparency in the food
supply chain system, ensuring food safety for everyone with the help of
Blockchain Technology. Food supply chain is the process of tracing a crop from
the farmer or producer to the buyer. With the advent of blockchain, providing a
safe and fraud-free environment for the provision of numerous agricultural
necessities has become much easier. Because of the globalization of trade, the
present supply chain market today includes various companies involving
integration of data, complex transactions and distribution. Information tamper
resistance, supply-demand relationships, and traceable oversight are all
difficulties that arise as a result of this. Blockchain is a distributed ledger
technology that can provide information that is resistant to tampering. This
strategy can eliminate the need for a centralized trusted authority,
intermediaries, and business histories, allowing for increased production and
security while maintaining the highest levels of integrity, liability, and
safety. In order to have an integrity and transparency in food supply chain in
the agricultural sector, a framework is proposed here based on block chain and
IoT.
\\ ( https://arxiv.org/abs/2401.09476 ,  292kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09479 (*cross-listing*)
Date: Mon, 15 Jan 2024 05:45:51 GMT   (2021kb,D)

Title: Uncertainty-Aware Hardware Trojan Detection Using Multimodal Deep
  Learning
Authors: Rahul Vishwakarma, Amin Rezaei
Categories: cs.CR cs.AI cs.LG
Comments: 2024 Design, Automation and Test in Europe Conference | The European
  Event for Electronic System Design & Test (accepted)
Journal-ref: 2024 Design, Automation and Test in Europe Conference | The
  European Event for Electronic System Design & Test
\\
  The risk of hardware Trojans being inserted at various stages of chip
production has increased in a zero-trust fabless era. To counter this, various
machine learning solutions have been developed for the detection of hardware
Trojans. While most of the focus has been on either a statistical or deep
learning approach, the limited number of Trojan-infected benchmarks affects the
detection accuracy and restricts the possibility of detecting zero-day Trojans.
To close the gap, we first employ generative adversarial networks to amplify
our data in two alternative representation modalities, a graph and a tabular,
ensuring that the dataset is distributed in a representative manner. Further,
we propose a multimodal deep learning approach to detect hardware Trojans and
evaluate the results from both early fusion and late fusion strategies. We also
estimate the uncertainty quantification metrics of each prediction for
risk-aware decision-making. The outcomes not only confirms the efficacy of our
proposed hardware Trojan detection method but also opens a new door for future
studies employing multimodality and uncertainty quantification to address other
hardware security challenges.
\\ ( https://arxiv.org/abs/2401.09479 ,  2021kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09556 (*cross-listing*)
Date: Wed, 17 Jan 2024 19:15:13 GMT   (1974kb)

Title: Deep learning enhanced mixed integer optimization: Learning to reduce
  model dimensionality
Authors: Niki Triantafyllou, Maria M. Papathanasiou
Categories: math.OC cs.AI cs.LG
\\
  This work introduces a framework to address the computational complexity
inherent in Mixed-Integer Programming (MIP) models by harnessing the potential
of deep learning. We compare the effectiveness of (a) feed-forward neural
networks (ANN) and (b) convolutional neural networks (CNN) in approximating the
active dimensions within MIP problems. We utilize multi-label classification to
account for more than one active dimension. To enhance the framework's
performance, we employ Bayesian optimization for hyperparameter tuning, aiming
to maximize sample-level accuracy. The primary objective is to train the neural
networks to predict all active dimensions accurately, thereby maximizing the
occurrence of global optimum solutions. We apply this framework to a flow-based
facility location allocation Mixed-Integer Linear Programming (MILP)
formulation that describes long-term investment planning and medium-term
tactical planning in a personalized medicine supply chain for cell therapy
manufacturing and distribution.
\\ ( https://arxiv.org/abs/2401.09556 ,  1974kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09572 (*cross-listing*)
Date: Wed, 17 Jan 2024 19:49:11 GMT   (3873kb,D)

Title: Handling Large-scale Cardinality in building recommendation systems
Authors: Dhruva Dixith Kurra, Bo Ling, Chun Zh, Seyedshahin Ashrafzadeh
Categories: cs.IR cs.AI
\\
  Effective recommendation systems rely on capturing user preferences, often
requiring incorporating numerous features such as universally unique
identifiers (UUIDs) of entities. However, the exceptionally high cardinality of
UUIDs poses a significant challenge in terms of model degradation and increased
model size due to sparsity. This paper presents two innovative techniques to
address the challenge of high cardinality in recommendation systems.
Specifically, we propose a bag-of-words approach, combined with layer sharing,
to substantially decrease the model size while improving performance. Our
techniques were evaluated through offline and online experiments on Uber use
cases, resulting in promising results demonstrating our approach's
effectiveness in optimizing recommendation systems and enhancing their overall
performance.
\\ ( https://arxiv.org/abs/2401.09572 ,  3873kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09637 (*cross-listing*)
Date: Wed, 17 Jan 2024 23:14:52 GMT   (1417kb,D)

Title: Impact of Large Language Model Assistance on Patients Reading Clinical
  Notes: A Mixed-Methods Study
Authors: Niklas Mannhardt, Elizabeth Bondi-Kelly, Barbara Lam, Chloe O'Connell,
  Mercy Asiedu, Hussein Mozannar, Monica Agrawal, Alejandro Buendia, Tatiana
  Urman, Irbaz B. Riaz, Catherine E. Ricciardi, Marzyeh Ghassemi, David Sontag
Categories: cs.HC cs.AI cs.CL
\\
  Patients derive numerous benefits from reading their clinical notes,
including an increased sense of control over their health and improved
understanding of their care plan. However, complex medical concepts and jargon
within clinical notes hinder patient comprehension and may lead to anxiety. We
developed a patient-facing tool to make clinical notes more readable,
leveraging large language models (LLMs) to simplify, extract information from,
and add context to notes. We prompt engineered GPT-4 to perform these
augmentation tasks on real clinical notes donated by breast cancer survivors
and synthetic notes generated by a clinician, a total of 12 notes with 3868
words. In June 2023, 200 female-identifying US-based participants were randomly
assigned three clinical notes with varying levels of augmentations using our
tool. Participants answered questions about each note, evaluating their
understanding of follow-up actions and self-reported confidence. We found that
augmentations were associated with a significant increase in action
understanding score (0.63 $\pm$ 0.04 for select augmentations, compared to 0.54
$\pm$ 0.02 for the control) with p=0.002. In-depth interviews of
self-identifying breast cancer patients (N=7) were also conducted via video
conferencing. Augmentations, especially definitions, elicited positive
responses among the seven participants, with some concerns about relying on
LLMs. Augmentations were evaluated for errors by clinicians, and we found
misleading errors occur, with errors more common in real donated notes than
synthetic notes, illustrating the importance of carefully written clinical
notes. Augmentations improve some but not all readability metrics. This work
demonstrates the potential of LLMs to improve patients' experience with
clinical notes at a lower burden to clinicians. However, having a human in the
loop is important to correct potential model errors.
\\ ( https://arxiv.org/abs/2401.09637 ,  1417kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09640 (*cross-listing*)
Date: Wed, 17 Jan 2024 23:27:36 GMT   (47kb)

Title: Blackout Mitigation via Physics-guided RL
Authors: Anmol Dwivedi, Santiago Paternain, Ali Tajer
Categories: eess.SY cs.AI cs.SY
\\
  This paper considers the sequential design of remedial control actions in
response to system anomalies for the ultimate objective of preventing
blackouts. A physics-guided reinforcement learning (RL) framework is designed
to identify effective sequences of real-time remedial look-ahead decisions
accounting for the long-term impact on the system's stability. The paper
considers a space of control actions that involve both discrete-valued
transmission line-switching decisions (line reconnections and removals) and
continuous-valued generator adjustments. To identify an effective blackout
mitigation policy, a physics-guided approach is designed that uses power-flow
sensitivity factors associated with the power transmission network to guide the
RL exploration during agent training. Comprehensive empirical evaluations using
the open-source Grid2Op platform demonstrate the notable advantages of
incorporating physical signals into RL decisions, establishing the gains of the
proposed physics-guided approach compared to its black box counterparts. One
important observation is that strategically~\emph{removing} transmission lines,
in conjunction with multiple real-time generator adjustments, often renders
effective long-term decisions that are likely to prevent or delay blackouts.
\\ ( https://arxiv.org/abs/2401.09640 ,  47kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09666 (*cross-listing*)
Date: Thu, 18 Jan 2024 00:50:41 GMT   (7243kb,D)

Title: Traffic Smoothing Controllers for Autonomous Vehicles Using Deep
  Reinforcement Learning and Real-World Trajectory Data
Authors: Nathan Lichtl\'e, Kathy Jang, Adit Shah, Eugene Vinitsky, Jonathan W.
  Lee, Alexandre M. Bayen
Categories: eess.SY cs.AI cs.MA cs.SY
Comments: Accepted to be published as part of the 26th IEEE International
  Conference on Intelligent Transportation Systems (ITSC) 2023, Bilbao, Spain,
  September 24-28, 2023
\\
  Designing traffic-smoothing cruise controllers that can be deployed onto
autonomous vehicles is a key step towards improving traffic flow, reducing
congestion, and enhancing fuel efficiency in mixed autonomy traffic. We bypass
the common issue of having to carefully fine-tune a large traffic
microsimulator by leveraging real-world trajectory data from the I-24 highway
in Tennessee, replayed in a one-lane simulation. Using standard deep
reinforcement learning methods, we train energy-reducing wave-smoothing
policies. As an input to the agent, we observe the speed and distance of only
the vehicle in front, which are local states readily available on most recent
vehicles, as well as non-local observations about the downstream state of the
traffic. We show that at a low 4% autonomous vehicle penetration rate, we
achieve significant fuel savings of over 15% on trajectories exhibiting many
stop-and-go waves. Finally, we analyze the smoothing effect of the controllers
and demonstrate robustness to adding lane-changing into the simulation as well
as the removal of downstream information.
\\ ( https://arxiv.org/abs/2401.09666 ,  7243kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09691 (*cross-listing*)
Date: Thu, 18 Jan 2024 02:44:18 GMT   (1365kb,D)

Title: Imitation Learning Inputting Image Feature to Each Layer of Neural
  Network
Authors: Koki Yamane, Sho Sakaino, Toshiaki Tsuji
Categories: cs.RO cs.AI cs.LG
Comments: IEEE The 18th International Workshop on Advanced Motion Control
  (AMC2024)
\\
  Imitation learning enables robots to learn and replicate human behavior from
training data. Recent advances in machine learning enable end-to-end learning
approaches that directly process high-dimensional observation data, such as
images. However, these approaches face a critical challenge when processing
data from multiple modalities, inadvertently ignoring data with a lower
correlation to the desired output, especially when using short sampling
periods. This paper presents a useful method to address this challenge, which
amplifies the influence of data with a relatively low correlation to the output
by inputting the data into each neural network layer. The proposed approach
effectively incorporates diverse data sources into the learning process.
Through experiments using a simple pick-and-place operation with raw images and
joint information as input, significant improvements in success rates are
demonstrated even when dealing with data from short sampling periods.
\\ ( https://arxiv.org/abs/2401.09691 ,  1365kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09695 (*cross-listing*)
Date: Thu, 18 Jan 2024 02:53:36 GMT   (241kb)

Title: Should ChatGPT Write Your Breakup Text? Exploring the Role of AI in
  Relationship Dissolution
Authors: Yue Fu, Yixin Chen, Zelia Gomes Da Costa Lai, Alexis Hiniker
Categories: cs.HC cs.AI
\\
  Relationships are essential to our happiness and wellbeing. The dissolution
of a relationship, the final stage of relationship's lifecycle and one of the
most stressful events in an individual's life, can have profound and
long-lasting impacts on people. With the breakup process increasingly
facilitated by computer-mediated communication (CMC), and the likely future
influence of AI-mediated communication (AIMC) tools, we conducted a
semi-structured interview study with 21 participants. We aim to understand: 1)
the current role of technology in the breakup process, 2) the needs and support
individuals have during the process, and 3) how AI might address these needs.
Our research shows that people have distinct needs at various stages of ending
a relationship. Presently, technology is used for information gathering and
community support, acting as a catalyst for breakups, enabling ghosting and
blocking, and facilitating communication. Participants anticipate that AI could
aid in sense-making of their relationship leading up to the breakup, act as a
mediator, assist in crafting appropriate wording, tones, and language during
breakup conversations, and support companionship, reflection, recovery, and
growth after a breakup. Our findings also demonstrate an overlap between the
breakup process and the Transtheoretical Model (TTM) of behavior change.
Through the lens of TTM, we explore the potential support and affordances AI
could offer in breakups, including its benefits and the necessary precautions
regarding AI's role in this sensitive process.
\\ ( https://arxiv.org/abs/2401.09695 ,  241kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09716 (*cross-listing*)
Date: Thu, 18 Jan 2024 04:23:21 GMT   (874kb,D)

Title: HCVP: Leveraging Hierarchical Contrastive Visual Prompt for Domain
  Generalization
Authors: Guanglin Zhou and Zhongyi Han and Shiming Chen and Biwei Huang and
  Liming Zhu and Tongliang Liu and Lina Yao and Kun Zhang
Categories: cs.CV cs.AI
\\
  Domain Generalization (DG) endeavors to create machine learning models that
excel in unseen scenarios by learning invariant features. In DG, the prevalent
practice of constraining models to a fixed structure or uniform
parameterization to encapsulate invariant features can inadvertently blend
specific aspects. Such an approach struggles with nuanced differentiation of
inter-domain variations and may exhibit bias towards certain domains, hindering
the precise learning of domain-invariant features. Recognizing this, we
introduce a novel method designed to supplement the model with domain-level and
task-specific characteristics. This approach aims to guide the model in more
effectively separating invariant features from specific characteristics,
thereby boosting the generalization. Building on the emerging trend of visual
prompts in the DG paradigm, our work introduces the novel \textbf{H}ierarchical
\textbf{C}ontrastive \textbf{V}isual \textbf{P}rompt (HCVP) methodology. This
represents a significant advancement in the field, setting itself apart with a
unique generative approach to prompts, alongside an explicit model structure
and specialized loss functions. Differing from traditional visual prompts that
are often shared across entire datasets, HCVP utilizes a hierarchical prompt
generation network enhanced by prompt contrastive learning. These generative
prompts are instance-dependent, catering to the unique characteristics inherent
to different domains and tasks. Additionally, we devise a prompt modulation
network that serves as a bridge, effectively incorporating the generated visual
prompts into the vision transformer backbone. Experiments conducted on five DG
datasets demonstrate the effectiveness of HCVP, outperforming both established
DG algorithms and adaptation protocols.
\\ ( https://arxiv.org/abs/2401.09716 ,  874kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09717 (*cross-listing*)
Date: Thu, 18 Jan 2024 04:28:56 GMT   (59kb)

Title: Parameter Selection for Analyzing Conversations with Autism Spectrum
  Disorder
Authors: Tahiya Chowdhury and Veronica Romero and Amanda Stent
Categories: eess.AS cs.AI cs.SD
Comments: 5 pages, 4 tables, Proceedings of INTERSPEECH 2023
DOI: 10.21437/Interspeech.2023-1885
\\
  The diagnosis of autism spectrum disorder (ASD) is a complex, challenging
task as it depends on the analysis of interactional behaviors by psychologists
rather than the use of biochemical diagnostics. In this paper, we present a
modeling approach to ASD diagnosis by analyzing acoustic/prosodic and
linguistic features extracted from diagnostic conversations between a
psychologist and children who either are typically developing (TD) or have ASD.
We compare the contributions of different features across a range of
conversation tasks. We focus on finding a minimal set of parameters that
characterize conversational behaviors of children with ASD. Because ASD is
diagnosed through conversational interaction, in addition to analyzing the
behavior of the children, we also investigate whether the psychologist's
conversational behaviors vary across diagnostic groups. Our results can
facilitate fine-grained analysis of conversation data for children with ASD to
support diagnosis and intervention.
\\ ( https://arxiv.org/abs/2401.09717 ,  59kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09748 (*cross-listing*)
Date: Thu, 18 Jan 2024 06:19:05 GMT   (413kb,D)

Title: Bootstrapping OTS-Funcimg Pre-training Model (Botfip) -- A Comprehensive
  Symbolic Regression Framework
Authors: Tianhao Chen, Pengbo Xu, Haibiao Zheng
Categories: cs.SC cs.AI cs.LG
\\
  In the field of scientific computing, many problem-solving approaches tend to
focus only on the process and final outcome, even in AI for science, there is a
lack of deep multimodal information mining behind the data, missing a
multimodal framework akin to that in the image-text domain. In this paper, we
take Symbolic Regression(SR) as our focal point and, drawing inspiration from
the BLIP model in the image-text domain, propose a scientific computing
multimodal framework based on Function Images (Funcimg) and Operation Tree
Sequence (OTS), named Bootstrapping OTS-Funcimg Pre-training Model (Botfip). In
SR experiments, we validate the advantages of Botfip in low-complexity SR
problems, showcasing its potential. As a MED framework, Botfip holds promise
for future applications in a broader range of scientific computing problems.
\\ ( https://arxiv.org/abs/2401.09748 ,  413kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09757 (*cross-listing*)
Date: Thu, 18 Jan 2024 07:07:44 GMT   (947kb,D)

Title: Cooperative Tri-Point Model-Based Ground-to-Air Coverage Extension in
  Beyond 5G Networks
Authors: Ziwei Cai, Min Sheng, Junju Liu, Chenxi Zhao and Jiandong Li
Categories: cs.IT cs.AI math.IT
\\
  The utilization of existing terrestrial infrastructures to provide coverage
for aerial users is a potentially low-cost solution. However, the already
deployed terrestrial base stations (TBSs) result in weak ground-to-air (G2A)
coverage due to the down-tilted antennas. Furthermore, achieving optimal
coverage across the entire airspace through antenna adjustment is challenging
due to the complex signal coverage requirements in three-dimensional space,
especially in the vertical direction. In this paper, we propose a cooperative
tri-point (CoTP) model-based method that utilizes cooperative beams to enhance
the G2A coverage extension. To utilize existing TBSs for establishing effective
cooperation, we prove that the cooperation among three TBSs can ensure G2A
coverage with a minimum coverage overlap, and design the CoTP model to analyze
the G2A coverage extension. Using the model, a cooperative coverage structure
based on Delaunay triangulation is designed to divide triangular prism-shaped
subspaces and corresponding TBS cooperation sets. To enable TBSs in the
cooperation set to cover different height subspaces while maintaining ground
coverage, we design a cooperative beam generation algorithm to maximize the
coverage in the triangular prism-shaped airspace. The simulation results and
field trials demonstrate that the proposed method can efficiently enhance the
G2A coverage extension while guaranteeing ground coverage.
\\ ( https://arxiv.org/abs/2401.09757 ,  947kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09763 (*cross-listing*)
Date: Thu, 18 Jan 2024 07:28:17 GMT   (1791kb)

Title: CLIP Model for Images to Textual Prompts Based on Top-k Neighbors
Authors: Xin Zhang, Xin Zhang, YeMing Cai, Tianzhi Jia
Categories: cs.CV cs.AI
Comments: CLIP model, KNN, image-to-prompts
\\
  Text-to-image synthesis, a subfield of multimodal generation, has gained
significant attention in recent years. We propose a cost-effective approach for
image-to-prompt generation that leverages generative models to generate textual
prompts without the need for large amounts of annotated data. We divide our
method into two stages: online stage and offline stage. We use a combination of
the CLIP model and K-nearest neighbors (KNN) algorithm. The proposed system
consists of two main parts: an offline task and an online task. Our method owns
the highest metric 0.612 among these models, which is 0.013, 0.055, 0.011
higher than Clip, Clip + KNN(top 10) respectively.
\\ ( https://arxiv.org/abs/2401.09763 ,  1791kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09769 (*cross-listing*)
Date: Thu, 18 Jan 2024 07:36:38 GMT   (339kb,D)

Title: Towards Learning from Graphs with Heterophily: Progress and Future
Authors: Chenghua Gong, Yao Cheng, Xiang Li, Caihua Shan, Siqiang Luo, Chuan
  Shi
Categories: cs.SI cs.AI cs.LG
Comments: 9 pages
\\
  Graphs are structured data that models complex relations between real-world
entities. Heterophilous graphs, where linked nodes are prone to be with
different labels or dissimilar features, have recently attracted significant
attention and found many applications. Meanwhile, increasing efforts have been
made to advance learning from heterophilous graphs. Although there exist
surveys on the relevant topic, they focus on heterophilous GNNs, which are only
sub-topics of heterophilous graph learning. In this survey, we comprehensively
overview existing works on learning from graphs with heterophily.First, we
collect over 180 publications and introduce the development of this field.
Then, we systematically categorize existing methods based on a hierarchical
taxonomy including learning strategies, model architectures and practical
applications. Finally, we discuss the primary challenges of existing studies
and highlight promising avenues for future research.More publication details
and corresponding open-source codes can be accessed and will be continuously
updated at our
repositories:https://github.com/gongchenghua/Awesome-Survey-Graphs-with-Heterophily.
\\ ( https://arxiv.org/abs/2401.09769 ,  339kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09773 (*cross-listing*)
Date: Thu, 18 Jan 2024 07:44:04 GMT   (13107kb,D)

Title: SEINE: Structure Encoding and Interaction Network for Nuclei Instance
  Segmentation
Authors: Ye Zhang, Linghan Cai, Ziyue Wang, Yongbing Zhang
Categories: cs.CV cs.AI
Comments: 10 pages, 12 figures, 6 tables, submitted to TMI
\\
  Nuclei instance segmentation in histopathological images is of great
importance for biological analysis and cancer diagnosis but remains challenging
for two reasons. (1) Similar visual presentation of intranuclear and
extranuclear regions of chromophobe nuclei often causes under-segmentation, and
(2) current methods lack the exploration of nuclei structure, resulting in
fragmented instance predictions. To address these problems, this paper proposes
a structure encoding and interaction network, termed SEINE, which develops the
structure modeling scheme of nuclei and exploits the structure similarity
between nuclei to improve the integrality of each segmented instance.
Concretely, SEINE introduces a contour-based structure encoding (SE) that
considers the correlation between nuclei structure and semantics, realizing a
reasonable representation of the nuclei structure. Based on the encoding, we
propose a structure-guided attention (SGA) that takes the clear nuclei as
prototypes to enhance the structure learning for the fuzzy nuclei. To
strengthen the structural learning ability, a semantic feature fusion (SFF) is
presented to boost the semantic consistency of semantic and structure branches.
Furthermore, a position enhancement (PE) method is applied to suppress
incorrect nuclei boundary predictions. Extensive experiments demonstrate the
superiority of our approaches, and SEINE achieves state-of-the-art (SOTA)
performance on four datasets. The code is available at
\href{https://github.com/zhangye-zoe/SEINE}{https://github.com/zhangye-zoe/SEINE}.
\\ ( https://arxiv.org/abs/2401.09773 ,  13107kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09786 (*cross-listing*)
Date: Thu, 18 Jan 2024 08:10:34 GMT   (3541kb,D)

Title: Adaptive Self-training Framework for Fine-grained Scene Graph Generation
Authors: Kibum Kim, Kanghoon Yoon, Yeonjun In, Jinyoung Moon, Donghyun Kim,
  Chanyoung Park
Categories: cs.CV cs.AI
Comments: 9 pages; ICLR 2024
\\
  Scene graph generation (SGG) models have suffered from inherent problems
regarding the benchmark datasets such as the long-tailed predicate distribution
and missing annotation problems. In this work, we aim to alleviate the
long-tailed problem of SGG by utilizing unannotated triplets. To this end, we
introduce a Self-Training framework for SGG (ST-SGG) that assigns pseudo-labels
for unannotated triplets based on which the SGG models are trained. While there
has been significant progress in self-training for image recognition, designing
a self-training framework for the SGG task is more challenging due to its
inherent nature such as the semantic ambiguity and the long-tailed distribution
of predicate classes. Hence, we propose a novel pseudo-labeling technique for
SGG, called Class-specific Adaptive Thresholding with Momentum (CATM), which is
a model-agnostic framework that can be applied to any existing SGG models.
Furthermore, we devise a graph structure learner (GSL) that is beneficial when
adopting our proposed self-training framework to the state-of-the-art
message-passing neural network (MPNN)-based SGG models. Our extensive
experiments verify the effectiveness of ST-SGG on various SGG models,
particularly in enhancing the performance on fine-grained predicate classes.
\\ ( https://arxiv.org/abs/2401.09786 ,  3541kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09795 (*cross-listing*)
Date: Thu, 18 Jan 2024 08:31:38 GMT   (1818kb,D)

Title: A Comparative Analysis on Metaheuristic Algorithms Based Vision
  Transformer Model for Early Detection of Alzheimer's Disease
Authors: Anuvab Sen, Udayon Sen and Subhabrata Roy
Categories: cs.NE cs.AI
Comments: 2023 IEEE 15th International Conference on Computational Intelligence
  and Communication Networks (CICN). arXiv admin note: text overlap with
  arXiv:2309.16796
\\
  A number of life threatening neuro-degenerative disorders had degraded the
quality of life for the older generation in particular. Dementia is one such
symptom which may lead to a severe condition called Alzheimer's disease if not
detected at an early stage. It has been reported that the progression of such
disease from a normal stage is due to the change in several parameters inside
the human brain. In this paper, an innovative metaheuristic algorithms based
ViT model has been proposed for the identification of dementia at different
stage. A sizeable number of test data have been utilized for the validation of
the proposed scheme. It has also been demonstrated that our model exhibits
superior performance in terms of accuracy, precision, recall as well as
F1-score.
\\ ( https://arxiv.org/abs/2401.09795 ,  1818kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09819 (*cross-listing*)
Date: Thu, 18 Jan 2024 09:20:27 GMT   (10704kb,D)

Title: PPNet: A Novel Neural Network Structure for End-to-End Near-Optimal Path
  Planning
Authors: Qinglong Meng, Chongkun Xia, Xueqian Wang, Songping Mai, and Bin Liang
Categories: cs.RO cs.AI cs.LG
\\
  The classical path planners, such as sampling-based path planners, have the
limitations of sensitivity to the initial solution and slow convergence to the
optimal solution. However, finding a near-optimal solution in a short period is
challenging in many applications such as the autonomous vehicle with limited
power/fuel. To achieve an end-to-end near-optimal path planner, we first divide
the path planning problem into two subproblems, which are path's space
segmentation and waypoints generation in the given path's space. We further
propose a two-level cascade neural network named Path Planning Network (PPNet)
to solve the path planning problem by solving the abovementioned subproblems.
Moreover, we propose a novel efficient data generation method for path planning
named EDaGe-PP. The results show the total computation time is less than 1/33
and the success rate of PPNet trained by the dataset that is generated by
EDaGe-PP is about $2 \times$ compared to other methods. We validate PPNet
against state-of-the-art path planning methods. The results show PPNet can find
a near-optimal solution in 15.3ms, which is much shorter than the
state-of-the-art path planners.
\\ ( https://arxiv.org/abs/2401.09819 ,  10704kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09833 (*cross-listing*)
Date: Thu, 18 Jan 2024 09:50:26 GMT   (5468kb,D)

Title: Slicer Networks
Authors: Hang Zhang, Xiang Chen, Rongguang Wang, Renjiu Hu, Dongdong Liu and
  Gaolei Li
Categories: eess.IV cs.AI cs.CV
Comments: 8 figures and 3 tables
\\
  In medical imaging, scans often reveal objects with varied contrasts but
consistent internal intensities or textures. This characteristic enables the
use of low-frequency approximations for tasks such as segmentation and
deformation field estimation. Yet, integrating this concept into neural network
architectures for medical image analysis remains underexplored. In this paper,
we propose the Slicer Network, a novel architecture designed to leverage these
traits. Comprising an encoder utilizing models like vision transformers for
feature extraction and a slicer employing a learnable bilateral grid, the
Slicer Network strategically refines and upsamples feature maps via a
splatting-blurring-slicing process. This introduces an edge-preserving
low-frequency approximation for the network outcome, effectively enlarging the
effective receptive field. The enhancement not only reduces computational
complexity but also boosts overall performance. Experiments across different
medical imaging applications, including unsupervised and keypoints-based image
registration and lesion segmentation, have verified the Slicer Network's
improved accuracy and efficiency.
\\ ( https://arxiv.org/abs/2401.09833 ,  5468kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09852 (*cross-listing*)
Date: Thu, 18 Jan 2024 10:08:24 GMT   (20939kb,D)

Title: Enhancing the Fairness and Performance of Edge Cameras with Explainable
  AI
Authors: Truong Thanh Hung Nguyen, Vo Thanh Khang Nguyen, Quoc Hung Cao, Van
  Binh Truong, Quoc Khanh Nguyen, Hung Cao
Categories: cs.CV cs.AI
Comments: IEEE ICCE 2024
\\
  The rising use of Artificial Intelligence (AI) in human detection on Edge
camera systems has led to accurate but complex models, challenging to interpret
and debug. Our research presents a diagnostic method using Explainable AI (XAI)
for model debugging, with expert-driven problem identification and solution
creation. Validated on the Bytetrack model in a real-world office Edge network,
we found the training dataset as the main bias source and suggested model
augmentation as a solution. Our approach helps identify model biases, essential
for achieving fair and trustworthy models.
\\ ( https://arxiv.org/abs/2401.09852 ,  20939kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09861 (*cross-listing*)
Date: Thu, 18 Jan 2024 10:18:48 GMT   (4165kb,D)

Title: Temporal Insight Enhancement: Mitigating Temporal Hallucination in
  Multimodal Large Language Models
Authors: Li Sun, Liuan Wang, Jun Sun, Takayuki Okatani
Categories: cs.CV cs.AI
Comments: 7 pages, 7 figures
\\
  Recent advancements in Multimodal Large Language Models (MLLMs) have
significantly enhanced the comprehension of multimedia content, bringing
together diverse modalities such as text, images, and videos. However, a
critical challenge faced by these models, especially when processing video
inputs, is the occurrence of hallucinations - erroneous perceptions or
interpretations, particularly at the event level. This study introduces an
innovative method to address event-level hallucinations in MLLMs, focusing on
specific temporal understanding in video content. Our approach leverages a
novel framework that extracts and utilizes event-specific information from both
the event query and the provided video to refine MLLMs' response. We propose a
unique mechanism that decomposes on-demand event queries into iconic actions.
Subsequently, we employ models like CLIP and BLIP2 to predict specific
timestamps for event occurrences. Our evaluation, conducted using the
Charades-STA dataset, demonstrates a significant reduction in temporal
hallucinations and an improvement in the quality of event-related responses.
This research not only provides a new perspective in addressing a critical
limitation of MLLMs but also contributes a quantitatively measurable method for
evaluating MLLMs in the context of temporal-related questions.
\\ ( https://arxiv.org/abs/2401.09861 ,  4165kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09862 (*cross-listing*)
Date: Thu, 18 Jan 2024 10:21:15 GMT   (317kb,D)

Title: Evolutionary Multi-Objective Optimization of Large Language Model
  Prompts for Balancing Sentiments
Authors: Jill Baumann and Oliver Kramer
Categories: cs.NE cs.AI cs.CL cs.LG
Comments: Accepted in EvoApps at EvoStar 2024
\\
  The advent of large language models (LLMs) such as ChatGPT has attracted
considerable attention in various domains due to their remarkable performance
and versatility. As the use of these models continues to grow, the importance
of effective prompt engineering has come to the fore. Prompt optimization
emerges as a crucial challenge, as it has a direct impact on model performance
and the extraction of relevant information. Recently, evolutionary algorithms
(EAs) have shown promise in addressing this issue, paving the way for novel
optimization strategies. In this work, we propose a evolutionary
multi-objective (EMO) approach specifically tailored for prompt optimization
called EMO-Prompts, using sentiment analysis as a case study. We use sentiment
analysis capabilities as our experimental targets. Our results demonstrate that
EMO-Prompts effectively generates prompts capable of guiding the LLM to produce
texts embodying two conflicting emotions simultaneously.
\\ ( https://arxiv.org/abs/2401.09862 ,  317kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09865 (*cross-listing*)
Date: Thu, 18 Jan 2024 10:28:45 GMT   (6450kb,D)

Title: Improving fine-grained understanding in image-text pre-training
Authors: Ioana Bica, Anastasija Ili\'c, Matthias Bauer, Goker Erdogan, Matko
  Bo\v{s}njak, Christos Kaplanis, Alexey A. Gritsenko, Matthias Minderer,
  Charles Blundell, Razvan Pascanu, Jovana Mitrovi\'c
Categories: cs.CV cs.AI cs.LG
Comments: 26 pages
\\
  We introduce SPARse Fine-grained Contrastive Alignment (SPARC), a simple
method for pretraining more fine-grained multimodal representations from
image-text pairs. Given that multiple image patches often correspond to single
words, we propose to learn a grouping of image patches for every token in the
caption. To achieve this, we use a sparse similarity metric between image
patches and language tokens and compute for each token a language-grouped
vision embedding as the weighted average of patches. The token and
language-grouped vision embeddings are then contrasted through a fine-grained
sequence-wise loss that only depends on individual samples and does not require
other batch samples as negatives. This enables more detailed information to be
learned in a computationally inexpensive manner. SPARC combines this
fine-grained loss with a contrastive loss between global image and text
embeddings to learn representations that simultaneously encode global and local
information. We thoroughly evaluate our proposed method and show improved
performance over competing approaches both on image-level tasks relying on
coarse-grained information, e.g. classification, as well as region-level tasks
relying on fine-grained information, e.g. retrieval, object detection, and
segmentation. Moreover, SPARC improves model faithfulness and captioning in
foundational vision-language models.
\\ ( https://arxiv.org/abs/2401.09865 ,  6450kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09880 (*cross-listing*)
Date: Thu, 18 Jan 2024 10:52:46 GMT   (1360kb)

Title: Attention-Based Recurrent Neural Network For Automatic Behavior Laying
  Hen Recognition
Authors: Fr\'ejus A. A. Laleye and Mika\"el A. Mousse
Categories: cs.SD cs.AI cs.CL cs.LG eess.AS
\\
  One of the interests of modern poultry farming is the vocalization of laying
hens which contain very useful information on health behavior. This information
is used as health and well-being indicators that help breeders better monitor
laying hens, which involves early detection of problems for rapid and more
effective intervention. In this work, we focus on the sound analysis for the
recognition of the types of calls of the laying hens in order to propose a
robust system of characterization of their behavior for a better monitoring. To
do this, we first collected and annotated laying hen call signals, then
designed an optimal acoustic characterization based on the combination of time
and frequency domain features. We then used these features to build the
multi-label classification models based on recurrent neural network to assign a
semantic class to the vocalization that characterize the laying hen behavior.
The results show an overall performance with our model based on the combination
of time and frequency domain features that obtained the highest F1-score
(F1=92.75) with a gain of 17% on the models using the frequency domain features
and of 8% on the compared approaches from the litterature.
\\ ( https://arxiv.org/abs/2401.09880 ,  1360kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09900 (*cross-listing*)
Date: Thu, 18 Jan 2024 11:26:20 GMT   (11882kb,D)

Title: XAI-Enhanced Semantic Segmentation Models for Visual Quality Inspection
Authors: Tobias Clement, Truong Thanh Hung Nguyen, Mohamed Abdelaal, Hung Cao
Categories: cs.CV cs.AI
Comments: IEEE ICCE 2024
\\
  Visual quality inspection systems, crucial in sectors like manufacturing and
logistics, employ computer vision and machine learning for precise, rapid
defect detection. However, their unexplained nature can hinder trust, error
identification, and system improvement. This paper presents a framework to
bolster visual quality inspection by using CAM-based explanations to refine
semantic segmentation models. Our approach consists of 1) Model Training, 2)
XAI-based Model Explanation, 3) XAI Evaluation, and 4) Annotation Augmentation
for Model Enhancement, informed by explanations and expert insights.
Evaluations show XAI-enhanced models surpass original DeepLabv3-ResNet101
models, especially in intricate object segmentation.
\\ ( https://arxiv.org/abs/2401.09900 ,  11882kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09942 (*cross-listing*)
Date: Thu, 18 Jan 2024 12:45:14 GMT   (8587kb,D)

Title: Multi-task Learning for Joint Re-identification, Team Affiliation, and
  Role Classification for Sports Visual Tracking
Authors: Amir M. Mansourian, Vladimir Somers, Christophe De Vleeschouwer,
  Shohreh Kasaei
Categories: cs.CV cs.AI
Journal-ref: Proceedings of the 6th International Workshop on Multimedia
  Content Analysis in Sports (MMSports 2023), October 29, 2023, Ottawa, ON,
  Canada
DOI: 10.1145/3606038.3616172
\\
  Effective tracking and re-identification of players is essential for
analyzing soccer videos. But, it is a challenging task due to the non-linear
motion of players, the similarity in appearance of players from the same team,
and frequent occlusions. Therefore, the ability to extract meaningful
embeddings to represent players is crucial in developing an effective tracking
and re-identification system. In this paper, a multi-purpose part-based person
representation method, called PRTreID, is proposed that performs three tasks of
role classification, team affiliation, and re-identification, simultaneously.
In contrast to available literature, a single network is trained with
multi-task supervision to solve all three tasks, jointly. The proposed joint
method is computationally efficient due to the shared backbone. Also, the
multi-task learning leads to richer and more discriminative representations, as
demonstrated by both quantitative and qualitative results. To demonstrate the
effectiveness of PRTreID, it is integrated with a state-of-the-art tracking
method, using a part-based post-processing module to handle long-term tracking.
The proposed tracking method outperforms all existing tracking methods on the
challenging SoccerNet tracking dataset.
\\ ( https://arxiv.org/abs/2401.09942 ,  8587kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09964 (*cross-listing*)
Date: Thu, 18 Jan 2024 13:26:53 GMT   (2959kb,D)

Title: When Neural Code Completion Models Size up the Situation: Attaining
  Cheaper and Faster Completion through Dynamic Model Inference
Authors: Zhensu Sun, Xiaoning Du, Fu Song, Shangwen Wang, Li Li
Categories: cs.SE cs.AI
Comments: Accepted to ICSE24
\\
  Leveraging recent advancements in large language models, modern neural code
completion models have demonstrated the capability to generate highly accurate
code suggestions. However, their massive size poses challenges in terms of
computational costs and environmental impact, hindering their widespread
adoption in practical scenarios. Dynamic inference emerges as a promising
solution, as it allocates minimal computation during inference while
maintaining the model's performance. In this research, we explore dynamic
inference within the context of code completion. Initially, we conducted an
empirical investigation on GPT-2, focusing on the inference capabilities of
intermediate layers for code completion. We found that 54.4% of tokens can be
accurately generated using just the first layer, signifying significant
computational savings potential. Moreover, despite using all layers, the model
still fails to predict 14.5% of tokens correctly, and the subsequent
completions continued from them are rarely considered helpful, with only a 4.2%
Acceptance Rate. These findings motivate our exploration of dynamic inference
in code completion and inspire us to enhance it with a decision-making
mechanism that stops the generation of incorrect code. We thus propose a novel
dynamic inference method specifically tailored for code completion models. This
method aims not only to produce correct predictions with largely reduced
computation but also to prevent incorrect predictions proactively. Our
extensive evaluation shows that it can averagely skip 1.7 layers out of 16
layers in the models, leading to an 11.2% speedup with only a marginal 1.1%
reduction in ROUGE-L.
\\ ( https://arxiv.org/abs/2401.09964 ,  2959kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09983 (*cross-listing*)
Date: Thu, 18 Jan 2024 13:55:32 GMT   (269kb)

Title: Multiobjective Optimization Analysis for Finding Infrastructure-as-Code
  Deployment Configurations
Authors: Eneko Osaba, Josu Diaz-de-Arcaya, Juncal Alonso, Jesus L. Lobo, Gorka
  Benguria and I\~naki Etxaniz
Categories: cs.NE cs.AI
Comments: 9 pages, 1 figure, 4 tables. Paper presented in the 11th
  International Conference on Computer and Communications Management (ICCCM
  2023)
DOI: 10.1145/3617733.3617777
\\
  Multiobjective optimization is a hot topic in the artificial intelligence and
operations research communities. The design and development of multiobjective
methods is a frequent task for researchers and practitioners. As a result of
this vibrant activity, a myriad of techniques have been proposed in the
literature to date, demonstrating a significant effectiveness for dealing with
situations coming from a wide range of real-world areas. This paper is focused
on a multiobjective problem related to optimizing Infrastructure-as-Code
deployment configurations. The system implemented for solving this problem has
been coined as IaC Optimizer Platform (IOP). Despite the fact that a
prototypical version of the IOP has been introduced in the literature before, a
deeper analysis focused on the resolution of the problem is needed, in order to
determine which is the most appropriate multiobjective method for embedding in
the IOP. The main motivation behind the analysis conducted in this work is to
enhance the IOP performance as much as possible. This is a crucial aspect of
this system, deeming that it will be deployed in a real environment, as it is
being developed as part of a H2020 European project. Going deeper, we resort in
this paper to nine different evolutionary computation-based multiobjective
algorithms. For assessing the quality of the considered solvers, 12 different
problem instances have been generated based on real-world settings. Results
obtained by each method after 10 independent runs have been compared using
Friedman's non-parametric tests. Findings reached from the tests carried out
lad to the creation of a multi-algorithm system, capable of applying different
techniques according to the user's needs.
\\ ( https://arxiv.org/abs/2401.09983 ,  269kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09987 (*cross-listing*)
Date: Thu, 18 Jan 2024 14:04:51 GMT   (8164kb,D)

Title: A-KIT: Adaptive Kalman-Informed Transformer
Authors: Nadav Cohen and Itzik Klein
Categories: cs.RO cs.AI cs.SY eess.SY
\\
  The extended Kalman filter (EKF) is a widely adopted method for sensor fusion
in navigation applications. A crucial aspect of the EKF is the online
determination of the process noise covariance matrix reflecting the model
uncertainty. While common EKF implementation assumes a constant process noise,
in real-world scenarios, the process noise varies, leading to inaccuracies in
the estimated state and potentially causing the filter to diverge. To cope with
such situations, model-based adaptive EKF methods were proposed and
demonstrated performance improvements, highlighting the need for a robust
adaptive approach. In this paper, we derive and introduce A-KIT, an adaptive
Kalman-informed transformer to learn the varying process noise covariance
online. The A-KIT framework is applicable to any type of sensor fusion. Here,
we present our approach to nonlinear sensor fusion based on an inertial
navigation system and Doppler velocity log. By employing real recorded data
from an autonomous underwater vehicle, we show that A-KIT outperforms the
conventional EKF by more than 49.5% and model-based adaptive EKF by an average
of 35.4% in terms of position accuracy.
\\ ( https://arxiv.org/abs/2401.09987 ,  8164kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10032 (*cross-listing*)
Date: Thu, 18 Jan 2024 14:57:25 GMT   (4238kb,D)

Title: FreGrad: Lightweight and Fast Frequency-aware Diffusion Vocoder
Authors: Tan Dat Nguyen, Ji-Hoon Kim, Youngjoon Jang, Jaehun Kim, Joon Son
  Chung
Categories: eess.AS cs.AI eess.SP
Comments: Accepted to ICASSP 2024
\\
  The goal of this paper is to generate realistic audio with a lightweight and
fast diffusion-based vocoder, named FreGrad. Our framework consists of the
following three key components: (1) We employ discrete wavelet transform that
decomposes a complicated waveform into sub-band wavelets, which helps FreGrad
to operate on a simple and concise feature space, (2) We design a
frequency-aware dilated convolution that elevates frequency awareness,
resulting in generating speech with accurate frequency information, and (3) We
introduce a bag of tricks that boosts the generation quality of the proposed
model. In our experiments, FreGrad achieves 3.7 times faster training time and
2.2 times faster inference speed compared to our baseline while reducing the
model size by 0.6 times (only 1.78M parameters) without sacrificing the output
quality. Audio samples are available at:
https://mm.kaist.ac.kr/projects/FreGrad.
\\ ( https://arxiv.org/abs/2401.10032 ,  4238kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10034 (*cross-listing*)
Date: Thu, 18 Jan 2024 14:58:17 GMT   (222kb,D)

Title: Evolutionary Computation in the Era of Large Language Model: Survey and
  Roadmap
Authors: Xingyu Wu, Sheng-hao Wu, Jibin Wu, Liang Feng, Kay Chen Tan
Categories: cs.NE cs.AI cs.CL
Comments: evolutionary algorithm (EA), large language model (LLM), optimization
  problem, prompt optimization, architecture search, code generation
\\
  Large Language Models (LLMs), built upon Transformer-based architectures with
massive pretraining on diverse data, have not only revolutionized natural
language processing but also extended their prowess to various domains, marking
a significant stride towards artificial general intelligence. The interplay
between LLMs and Evolutionary Algorithms (EAs), despite differing in objectives
and methodologies, reveals intriguing parallels, especially in their shared
optimization nature, black-box characteristics, and proficiency in handling
complex problems. Meanwhile, EA can not only provide an optimization framework
for LLM's further enhancement under black-box settings but also empower LLM
with flexible global search and iterative mechanism in applications. On the
other hand, LLM's abundant domain knowledge enables EA to perform smarter
searches, while its text processing capability assist in deploying EA across
various tasks. Based on their complementary advantages, this paper presents a
comprehensive review and forward-looking roadmap, categorizing their mutual
inspiration into LLM-enhanced evolutionary optimization and EA-enhanced LLM.
Some integrated synergy methods are further introduced to exemplify the
amalgamation of LLMs and EAs in various application scenarios, including neural
architecture search, code generation, software engineering, and text
generation. As the first comprehensive review specifically focused on the EA
research in the era of LLMs, this paper provides a foundational stepping stone
for understanding and harnessing the collaborative potential of LLMs and EAs.
By presenting a comprehensive review, categorization, and critical analysis, we
contribute to the ongoing discourse on the cross-disciplinary study of these
two powerful paradigms. The identified challenges and future directions offer
guidance to unlock the full potential of this innovative collaboration.
\\ ( https://arxiv.org/abs/2401.10034 ,  222kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10036 (*cross-listing*)
Date: Thu, 18 Jan 2024 15:00:01 GMT   (379kb,D)

Title: LOCALINTEL: Generating Organizational Threat Intelligence from Global
  and Local Cyber Knowledge
Authors: Shaswata Mitra, Subash Neupane, Trisha Chakraborty, Sudip Mittal,
  Aritran Piplai, Manas Gaur, Shahram Rahimi
Categories: cs.CR cs.AI cs.IR cs.LO
\\
  Security Operations Center (SoC) analysts gather threat reports from openly
accessible global threat databases and customize them manually to suit a
particular organization's needs. These analysts also depend on internal
repositories, which act as private local knowledge database for an
organization. Credible cyber intelligence, critical operational details, and
relevant organizational information are all stored in these local knowledge
databases. Analysts undertake a labor intensive task utilizing these global and
local knowledge databases to manually create organization's unique threat
response and mitigation strategies. Recently, Large Language Models (LLMs) have
shown the capability to efficiently process large diverse knowledge sources. We
leverage this ability to process global and local knowledge databases to
automate the generation of organization-specific threat intelligence.
  In this work, we present LOCALINTEL, a novel automated knowledge
contextualization system that, upon prompting, retrieves threat reports from
the global threat repositories and uses its local knowledge database to
contextualize them for a specific organization. LOCALINTEL comprises of three
key phases: global threat intelligence retrieval, local knowledge retrieval,
and contextualized completion generation. The former retrieves intelligence
from global threat repositories, while the second retrieves pertinent knowledge
from the local knowledge database. Finally, the fusion of these knowledge
sources is orchestrated through a generator to produce a contextualized
completion.
\\ ( https://arxiv.org/abs/2401.10036 ,  379kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10061 (*cross-listing*)
Date: Thu, 18 Jan 2024 15:30:58 GMT   (14560kb,D)

Title: DiffusionGPT: LLM-Driven Text-to-Image Generation System
Authors: Jie Qin, Jie Wu, Weifeng Chen, Yuxi Ren, Huixia Li, Hefeng Wu, Xuefeng
  Xiao, Rui Wang, and Shilei Wen
Categories: cs.CV cs.AI
\\
  Diffusion models have opened up new avenues for the field of image
generation, resulting in the proliferation of high-quality models shared on
open-source platforms. However, a major challenge persists in current
text-to-image systems are often unable to handle diverse inputs, or are limited
to single model results. Current unified attempts often fall into two
orthogonal aspects: i) parse Diverse Prompts in input stage; ii) activate
expert model to output. To combine the best of both worlds, we propose
DiffusionGPT, which leverages Large Language Models (LLM) to offer a unified
generation system capable of seamlessly accommodating various types of prompts
and integrating domain-expert models. DiffusionGPT constructs domain-specific
Trees for various generative models based on prior knowledge. When provided
with an input, the LLM parses the prompt and employs the Trees-of-Thought to
guide the selection of an appropriate model, thereby relaxing input constraints
and ensuring exceptional performance across diverse domains. Moreover, we
introduce Advantage Databases, where the Tree-of-Thought is enriched with human
feedback, aligning the model selection process with human preferences. Through
extensive experiments and comparisons, we demonstrate the effectiveness of
DiffusionGPT, showcasing its potential for pushing the boundaries of image
synthesis in diverse domains.
\\ ( https://arxiv.org/abs/2401.10061 ,  14560kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10139 (*cross-listing*)
Date: Thu, 18 Jan 2024 17:06:21 GMT   (318kb,D)

Title: Model Compression Techniques in Biometrics Applications: A Survey
Authors: Eduarda Caldeira, Pedro C. Neto, Marco Huber, Naser Damer, Ana F.
  Sequeira
Categories: cs.CV cs.AI
Comments: Under review at IEEE Journal
\\
  The development of deep learning algorithms has extensively empowered
humanity's task automatization capacity. However, the huge improvement in the
performance of these models is highly correlated with their increasing level of
complexity, limiting their usefulness in human-oriented applications, which are
usually deployed in resource-constrained devices. This led to the development
of compression techniques that drastically reduce the computational and memory
costs of deep learning models without significant performance degradation. This
paper aims to systematize the current literature on this topic by presenting a
comprehensive survey of model compression techniques in biometrics
applications, namely quantization, knowledge distillation and pruning. We
conduct a critical analysis of the comparative value of these techniques,
focusing on their advantages and disadvantages and presenting suggestions for
future work directions that can potentially improve the current methods.
Additionally, we discuss and analyze the link between model bias and model
compression, highlighting the need to direct compression research toward model
fairness in future works.
\\ ( https://arxiv.org/abs/2401.10139 ,  318kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10148 (*cross-listing*)
Date: Thu, 18 Jan 2024 17:22:11 GMT   (12276kb,D)

Title: Explicitly Disentangled Representations in Object-Centric Learning
Authors: Riccardo Majellaro, Jonathan Collu, Aske Plaat, Thomas M. Moerland
Categories: cs.CV cs.AI cs.LG
\\
  Extracting structured representations from raw visual data is an important
and long-standing challenge in machine learning. Recently, techniques for
unsupervised learning of object-centric representations have raised growing
interest. In this context, enhancing the robustness of the latent features can
improve the efficiency and effectiveness of the training of downstream tasks. A
promising step in this direction is to disentangle the factors that cause
variation in the data. Previously, Invariant Slot Attention disentangled
position, scale, and orientation from the remaining features. Extending this
approach, we focus on separating the shape and texture components. In
particular, we propose a novel architecture that biases object-centric models
toward disentangling shape and texture components into two non-overlapping
subsets of the latent space dimensions. These subsets are known a priori, hence
before the training process. Experiments on a range of object-centric
benchmarks reveal that our approach achieves the desired disentanglement while
also numerically improving baseline performance in most cases. In addition, we
show that our method can generate novel textures for a specific object or
transfer textures between objects with distinct shapes.
\\ ( https://arxiv.org/abs/2401.10148 ,  12276kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10158 (*cross-listing*)
Date: Mon, 15 Jan 2024 13:00:48 GMT   (2559kb,D)

Title: DISTINQT: A Distributed Privacy Aware Learning Framework for QoS
  Prediction for Future Mobile and Wireless Networks
Authors: Nikolaos Koursioumpas, Lina Magoula, Ioannis Stavrakakis, Nancy
  Alonistioti, M. A. Gutierrez-Estevez, Ramin Khalili
Categories: cs.NI cs.AI cs.CR cs.DC cs.LG
Comments: 11 Pages Double Column, 9 Figures, Submitted for possible publication
  in the IEEE Transactions on Vehicular Technology (IEEE TVT)
\\
  Beyond 5G and 6G networks are expected to support new and challenging use
cases and applications that depend on a certain level of Quality of Service
(QoS) to operate smoothly. Predicting the QoS in a timely manner is of high
importance, especially for safety-critical applications as in the case of
vehicular communications. Although until recent years the QoS prediction has
been carried out by centralized Artificial Intelligence (AI) solutions, a
number of privacy, computational, and operational concerns have emerged.
Alternative solutions have been surfaced (e.g. Split Learning, Federated
Learning), distributing AI tasks of reduced complexity across nodes, while
preserving the privacy of the data. However, new challenges rise when it comes
to scalable distributed learning approaches, taking into account the
heterogeneous nature of future wireless networks. The current work proposes
DISTINQT, a privacy-aware distributed learning framework for QoS prediction.
Our framework supports multiple heterogeneous nodes, in terms of data types and
model architectures, by sharing computations across them. This, enables the
incorporation of diverse knowledge into a sole learning process that will
enhance the robustness and generalization capabilities of the final QoS
prediction model. DISTINQT also contributes to data privacy preservation by
encoding any raw input data into a non-linear latent representation before any
transmission. Evaluation results showcase that our framework achieves a
statistically identical performance compared to its centralized version and an
average performance improvement of up to 65% against six state-of-the-art
centralized baseline solutions in the Tele-Operated Driving use case.
\\ ( https://arxiv.org/abs/2401.10158 ,  2559kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10178 (*cross-listing*)
Date: Thu, 18 Jan 2024 18:06:22 GMT   (3925kb,D)

Title: Neural Echos: Depthwise Convolutional Filters Replicate Biological
  Receptive Fields
Authors: Zahra Babaiee, Peyman M. Kiasari, Daniela Rus, Radu Grosu
Categories: cs.CV cs.AI cs.NE
Journal-ref: Proceedings of the IEEE/CVF Winter Conference on Applications of
  Computer Vision (2024) 8216-8225
\\
  In this study, we present evidence suggesting that depthwise convolutional
kernels are effectively replicating the structural intricacies of the
biological receptive fields observed in the mammalian retina. We provide
analytics of trained kernels from various state-of-the-art models
substantiating this evidence. Inspired by this intriguing discovery, we propose
an initialization scheme that draws inspiration from the biological receptive
fields. Experimental analysis of the ImageNet dataset with multiple CNN
architectures featuring depthwise convolutions reveals a marked enhancement in
the accuracy of the learned model when initialized with biologically derived
weights. This underlies the potential for biologically inspired computational
models to further our understanding of vision processing systems and to improve
the efficacy of convolutional networks.
\\ ( https://arxiv.org/abs/2401.10178 ,  3925kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10207 (*cross-listing*)
Date: Thu, 18 Jan 2024 18:45:29 GMT   (419kb,D)

Title: Eclectic Rule Extraction for Explainability of Deep Neural Network based
  Intrusion Detection Systems
Authors: Jesse Ables, Nathaniel Childers, William Anderson, Sudip Mittal,
  Shahram Rahimi, Ioana Banicescu, Maria Seale
Categories: cs.CR cs.AI cs.LG
\\
  This paper addresses trust issues created from the ubiquity of black box
algorithms and surrogate explainers in Explainable Intrusion Detection Systems
(X-IDS). While Explainable Artificial Intelligence (XAI) aims to enhance
transparency, black box surrogate explainers, such as Local Interpretable
Model-Agnostic Explanation (LIME) and SHapley Additive exPlanation (SHAP), are
difficult to trust. The black box nature of these surrogate explainers makes
the process behind explanation generation opaque and difficult to understand.
To avoid this problem, one can use transparent white box algorithms such as
Rule Extraction (RE). There are three types of RE algorithms: pedagogical,
decompositional, and eclectic. Pedagogical methods offer fast but untrustworthy
white-box explanations, while decompositional RE provides trustworthy
explanations with poor scalability. This work explores eclectic rule
extraction, which strikes a balance between scalability and trustworthiness. By
combining techniques from pedagogical and decompositional approaches, eclectic
rule extraction leverages the advantages of both, while mitigating some of
their drawbacks. The proposed Hybrid X-IDS architecture features eclectic RE as
a white box surrogate explainer for black box Deep Neural Networks (DNN). The
presented eclectic RE algorithm extracts human-readable rules from hidden
layers, facilitating explainable and trustworthy rulesets. Evaluations on
UNSW-NB15 and CIC-IDS-2017 datasets demonstrate the algorithm's ability to
generate rulesets with 99.9% accuracy, mimicking DNN outputs. The contributions
of this work include the hybrid X-IDS architecture, the eclectic rule
extraction algorithm applicable to intrusion detection datasets, and a thorough
analysis of performance and explainability, demonstrating the trade-offs
involved in rule extraction speed and accuracy.
\\ ( https://arxiv.org/abs/2401.10207 ,  419kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10210 (*cross-listing*)
Date: Thu, 4 Jan 2024 17:57:21 GMT   (5644kb,D)

Title: Mastery Guided Non-parametric Clustering to Scale-up Strategy Prediction
Authors: Anup Shakya, Vasile Rus, Deepak Venugopal
Categories: cs.CY cs.AI cs.LG
Comments: Proceedings of 37th AAAI Conference on Artificial Intelligence
  Artificial Intelligence for Education. arXiv admin note: substantial text
  overlap with arXiv:2308.03892
\\
  Predicting the strategy (sequence of concepts) that a student is likely to
use in problem-solving helps Adaptive Instructional Systems (AISs) better adapt
themselves to different types of learners based on their learning abilities.
This can lead to a more dynamic, engaging, and personalized experience for
students. To scale up training a prediction model (such as LSTMs) over
large-scale education datasets, we develop a non-parametric approach to cluster
symmetric instances in the data. Specifically, we learn a representation based
on Node2Vec that encodes symmetries over mastery or skill level since, to solve
a problem, it is natural that a student's strategy is likely to involve
concepts in which they have gained mastery. Using this representation, we use
DP-Means to group symmetric instances through a coarse-to-fine refinement of
the clusters. We apply our model to learn strategies for Math learning from
large-scale datasets from MATHia, a leading AIS for middle-school math
learning. Our results illustrate that our approach can consistently achieve
high accuracy using a small sample that is representative of the full dataset.
Further, we show that this approach helps us learn strategies with high
accuracy for students at different skill levels, i.e., leveraging symmetries
improves fairness in the prediction model.
\\ ( https://arxiv.org/abs/2401.10210 ,  5644kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10211 (*cross-listing*)
Date: Thu, 4 Jan 2024 20:49:32 GMT   (763kb,D)

Title: Improving PTM Site Prediction by Coupling of Multi-Granularity Structure
  and Multi-Scale Sequence Representation
Authors: Zhengyi Li, Menglu Li, Lida Zhu, Wen Zhang
Categories: q-bio.QM cs.AI cs.LG
\\
  Protein post-translational modification (PTM) site prediction is a
fundamental task in bioinformatics. Several computational methods have been
developed to predict PTM sites. However, existing methods ignore the structure
information and merely utilize protein sequences. Furthermore, designing a more
fine-grained structure representation learning method is urgently needed as PTM
is a biological event that occurs at the atom granularity. In this paper, we
propose a PTM site prediction method by Coupling of Multi-Granularity structure
and Multi-Scale sequence representation, PTM-CMGMS for brevity. Specifically,
multigranularity structure-aware representation learning is designed to learn
neighborhood structure representations at the amino acid, atom, and whole
protein granularity from AlphaFold predicted structures, followed by utilizing
contrastive learning to optimize the structure representations.Additionally,
multi-scale sequence representation learning is used to extract context
sequence information, and motif generated by aligning all context sequences of
PTM sites assists the prediction. Extensive experiments on three datasets show
that PTM-CMGMS outperforms the state-of-the-art methods.
\\ ( https://arxiv.org/abs/2401.10211 ,  763kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10222 (*cross-listing*)
Date: Thu, 18 Jan 2024 18:58:54 GMT   (2190kb,D)

Title: Supervised Fine-tuning in turn Improves Visual Foundation Models
Authors: Xiaohu Jiang, Yixiao Ge, Yuying Ge, Chun Yuan, Ying Shan
Categories: cs.CV cs.AI
Comments: 14 pages, 3 figures, Project page:
  https://github.com/TencentARC/ViSFT/tree/main
\\
  Image-text training like CLIP has dominated the pretraining of vision
foundation models in recent years. Subsequent efforts have been made to
introduce region-level visual learning into CLIP's pretraining but face
scalability challenges due to the lack of large-scale region-level datasets.
Drawing inspiration from supervised fine-tuning (SFT) in natural language
processing such as instruction tuning, we explore the potential of fine-grained
SFT in enhancing the generation of vision foundation models after their
pretraining. Thus a two-stage method ViSFT (Vision SFT) is proposed to unleash
the fine-grained knowledge of vision foundation models. In ViSFT, the vision
foundation model is enhanced by performing visual joint learning on some
in-domain tasks and then tested on out-of-domain benchmarks. With updating
using ViSFT on 8 V100 GPUs in less than 2 days, a vision transformer with over
4.4B parameters shows improvements across various out-of-domain benchmarks
including vision and vision-linguistic scenarios.
\\ ( https://arxiv.org/abs/2401.10222 ,  2190kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09647 (*cross-listing*)
Date: Wed, 17 Jan 2024 23:32:56 GMT   (8102kb,D)

Title: Characterizing Online Eating Disorder Communities with Large Language
  Models
Authors: Minh Duc Chu, Aryan Karnati, Zihao He, Kristina Lerman
Categories: cs.SI cs.CL cs.CY
\\
  The rise in eating disorders, a dangerous mental health condition with high
mortality and morbidity, has been linked to the proliferation of idealized body
images on social media. However, the link between social media and eating
disorders is far more complex. We argue that social media platforms create a
feedback loop that amplifies the growth of content and communities that promote
eating disorders like anorexia and bulimia. Specifically, social media
platforms make it easy for vulnerable individuals to find and connect to
like-minded others, while group dynamic processes encourage them to stay
engaged within communities that promote and glorify harmful behaviors linked to
eating disorders. We characterize this dynamic empirically through a
combination of network and language analysis. We describe a novel framework
that leverages large language models to analyze the discourse within online
communities and probe their attitudes on topics related to eating disorders to
identify potentially harmful content. Our work emphasizes the need for better
social media moderation to disrupt harmful feedback loops and protect
vulnerable individuals.
\\ ( https://arxiv.org/abs/2401.09647 ,  8102kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09724 (*cross-listing*)
Date: Thu, 18 Jan 2024 04:57:12 GMT   (1126kb,D)

Title: Predicting Viral Rumors and Vulnerable Users for Infodemic Surveillance
Authors: Xuan Zhang, Wei Gao
Categories: cs.SI cs.CL
Comments: Accepted by IP&M
\\
  In the age of the infodemic, it is crucial to have tools for effectively
monitoring the spread of rampant rumors that can quickly go viral, as well as
identifying vulnerable users who may be more susceptible to spreading such
misinformation. This proactive approach allows for timely preventive measures
to be taken, mitigating the negative impact of false information on society. We
propose a novel approach to predict viral rumors and vulnerable users using a
unified graph neural network model. We pre-train network-based user embeddings
and leverage a cross-attention mechanism between users and posts, together with
a community-enhanced vulnerability propagation (CVP) method to improve user and
propagation graph representations. Furthermore, we employ two multi-task
training strategies to mitigate negative transfer effects among tasks in
different settings, enhancing the overall performance of our approach. We also
construct two datasets with ground-truth annotations on information virality
and user vulnerability in rumor and non-rumor events, which are automatically
derived from existing rumor detection datasets. Extensive evaluation results of
our joint learning model confirm its superiority over strong baselines in all
three tasks: rumor detection, virality prediction, and user vulnerability
scoring. For instance, compared to the best baselines based on the Weibo
dataset, our model makes 3.8\% and 3.0\% improvements on Accuracy and MacF1 for
rumor detection, and reduces mean squared error (MSE) by 23.9\% and 16.5\% for
virality prediction and user vulnerability scoring, respectively. Our findings
suggest that our approach effectively captures the correlation between rumor
virality and user vulnerability, leveraging this information to improve
prediction performance and provide a valuable tool for infodemic surveillance.
\\ ( https://arxiv.org/abs/2401.09724 ,  1126kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09727 (*cross-listing*)
Date: Thu, 18 Jan 2024 05:06:39 GMT   (1273kb,D)

Title: Large Language Model Lateral Spear Phishing: A Comparative Study in
  Large-Scale Organizational Settings
Authors: Mazal Bethany, Athanasios Galiopoulos, Emet Bethany, Mohammad Bahrami
  Karkevandi, Nishant Vishwamitra, Peyman Najafirad
Categories: cs.CR cs.CL
\\
  The critical threat of phishing emails has been further exacerbated by the
potential of LLMs to generate highly targeted, personalized, and automated
spear phishing attacks. Two critical problems concerning LLM-facilitated
phishing require further investigation: 1) Existing studies on lateral phishing
lack specific examination of LLM integration for large-scale attacks targeting
the entire organization, and 2) Current anti-phishing infrastructure, despite
its extensive development, lacks the capability to prevent LLM-generated
attacks, potentially impacting both employees and IT security incident
management. However, the execution of such investigative studies necessitates a
real-world environment, one that functions during regular business operations
and mirrors the complexity of a large organizational infrastructure. This
setting must also offer the flexibility required to facilitate a diverse array
of experimental conditions, particularly the incorporation of phishing emails
crafted by LLMs. This study is a pioneering exploration into the use of Large
Language Models (LLMs) for the creation of targeted lateral phishing emails,
targeting a large tier 1 university's operation and workforce of approximately
9,000 individuals over an 11-month period. It also evaluates the capability of
email filtering infrastructure to detect such LLM-generated phishing attempts,
providing insights into their effectiveness and identifying potential areas for
improvement. Based on our findings, we propose machine learning-based detection
techniques for such emails to detect LLM-generated phishing emails that were
missed by the existing infrastructure, with an F1-score of 98.96.
\\ ( https://arxiv.org/abs/2401.09727 ,  1273kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09774 (*cross-listing*)
Date: Thu, 18 Jan 2024 07:50:07 GMT   (2295kb,D)

Title: On the Audio Hallucinations in Large Audio-Video Language Models
Authors: Taichi Nishimura and Shota Nakada and Masayoshi Kondo
Categories: cs.MM cs.CL cs.CV cs.SD eess.AS
Comments: 6 pages
\\
  Large audio-video language models can generate descriptions for both video
and audio. However, they sometimes ignore audio content, producing audio
descriptions solely reliant on visual information. This paper refers to this as
audio hallucinations and analyzes them in large audio-video language models. We
gather 1,000 sentences by inquiring about audio information and annotate them
whether they contain hallucinations. If a sentence is hallucinated, we also
categorize the type of hallucination. The results reveal that 332 sentences are
hallucinated with distinct trends observed in nouns and verbs for each
hallucination type. Based on this, we tackle a task of audio hallucination
classification using pre-trained audio-text models in the zero-shot and
fine-tuning settings. Our experimental results reveal that the zero-shot models
achieve higher performance (52.2% in F1) than the random (40.3%) and the
fine-tuning models achieve 87.9%, outperforming the zero-shot models.
\\ ( https://arxiv.org/abs/2401.09774 ,  2295kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09890 (*cross-listing*)
Date: Thu, 18 Jan 2024 11:05:03 GMT   (184kb,D)

Title: A Survey on Hardware Accelerators for Large Language Models
Authors: Christoforos Kachris
Categories: cs.AR cs.CL cs.LG
ACM-class: B.5; C.1; C.3
\\
  Large Language Models (LLMs) have emerged as powerful tools for natural
language processing tasks, revolutionizing the field with their ability to
understand and generate human-like text. As the demand for more sophisticated
LLMs continues to grow, there is a pressing need to address the computational
challenges associated with their scale and complexity. This paper presents a
comprehensive survey on hardware accelerators designed to enhance the
performance and energy efficiency of Large Language Models. By examining a
diverse range of accelerators, including GPUs, FPGAs, and custom-designed
architectures, we explore the landscape of hardware solutions tailored to meet
the unique computational demands of LLMs. The survey encompasses an in-depth
analysis of architecture, performance metrics, and energy efficiency
considerations, providing valuable insights for researchers, engineers, and
decision-makers aiming to optimize the deployment of LLMs in real-world
applications.
\\ ( https://arxiv.org/abs/2401.09890 ,  184kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10005 (*cross-listing*)
Date: Thu, 18 Jan 2024 14:21:56 GMT   (1789kb,D)

Title: Advancing Large Multi-modal Models with Explicit Chain-of-Reasoning and
  Visual Question Generation
Authors: Kohei Uehara, Nabarun Goswami, Hanqin Wang, Toshiaki Baba, Kohtaro
  Tanaka, Tomohiro Hashimoto, Kai Wang, Rei Ito, Takagi Naoya, Ryo Umagami,
  Yingyi Wen, Tanachai Anakewat, Tatsuya Harada
Categories: cs.CV cs.CL
\\
  The increasing demand for intelligent systems capable of interpreting and
reasoning about visual content requires the development of Large Multi-Modal
Models (LMMs) that are not only accurate but also have explicit reasoning
capabilities. This paper presents a novel approach to imbue an LMM with the
ability to conduct explicit reasoning based on visual content and textual
instructions. We introduce a system that can ask a question to acquire
necessary knowledge, thereby enhancing the robustness and explicability of the
reasoning process. Our method comprises the development of a novel dataset
generated by a Large Language Model (LLM), designed to promote chain-of-thought
reasoning combined with a question-asking mechanism. We designed an LMM, which
has high capabilities on region awareness to address the intricate requirements
of image-text alignment. The model undergoes a three-stage training phase,
starting with large-scale image-text alignment using a large-scale datasets,
followed by instruction tuning, and fine-tuning with a focus on
chain-of-thought reasoning. The results demonstrate a stride toward a more
robust, accurate, and interpretable LMM, capable of reasoning explicitly and
seeking information proactively when confronted with ambiguous visual input.
\\ ( https://arxiv.org/abs/2401.10005 ,  1789kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10208 (*cross-listing*)
Date: Thu, 18 Jan 2024 18:50:16 GMT   (2023kb,D)

Title: MM-Interleaved: Interleaved Image-Text Generative Modeling via
  Multi-modal Feature Synchronizer
Authors: Changyao Tian, Xizhou Zhu, Yuwen Xiong, Weiyun Wang, Zhe Chen, Wenhai
  Wang, Yuntao Chen, Lewei Lu, Tong Lu, Jie Zhou, Hongsheng Li, Yu Qiao, Jifeng
  Dai
Categories: cs.CV cs.CL
Comments: 20 pages, 9 figures, 17 tables
\\
  Developing generative models for interleaved image-text data has both
research and practical value. It requires models to understand the interleaved
sequences and subsequently generate images and text. However, existing attempts
are limited by the issue that the fixed number of visual tokens cannot
efficiently capture image details, which is particularly problematic in the
multi-image scenarios. To address this, this paper presents MM-Interleaved, an
end-to-end generative model for interleaved image-text data. It introduces a
multi-scale and multi-image feature synchronizer module, allowing direct access
to fine-grained image features in the previous context during the generation
process. MM-Interleaved is end-to-end pre-trained on both paired and
interleaved image-text corpora. It is further enhanced through a supervised
fine-tuning phase, wherein the model improves its ability to follow complex
multi-modal instructions. Experiments demonstrate the versatility of
MM-Interleaved in recognizing visual details following multi-modal instructions
and generating consistent images following both textual and visual conditions.
Code and models are available at
\url{https://github.com/OpenGVLab/MM-Interleaved}.
\\ ( https://arxiv.org/abs/2401.10208 ,  2023kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09431 (*cross-listing*)
Date: Sun, 17 Dec 2023 00:54:56 GMT   (493kb,D)

Title: A Smoothing Algorithm for l1 Support Vector Machines
Authors: Ibrahim Emirahmetoglu, Jeffrey Hajewski, Suely Oliveira, and David E.
  Stewart
Categories: math.OC cs.LG
Comments: arXiv admin note: text overlap with arXiv:1808.07100
\\
  A smoothing algorithm is presented for solving the soft-margin Support Vector
Machine (SVM) optimization problem with an $\ell^{1}$ penalty. This algorithm
is designed to require a modest number of passes over the data, which is an
important measure of its cost for very large datasets. The algorithm uses
smoothing for the hinge-loss function, and an active set approach for the
$\ell^{1}$ penalty. The smoothing parameter $\alpha$ is initially large, but
typically halved when the smoothed problem is solved to sufficient accuracy.
Convergence theory is presented that shows
$\mathcal{O}(1+\log(1+\log_+(1/\alpha)))$ guarded Newton steps for each value
of $\alpha$ except for asymptotic bands $\alpha=\Theta(1)$ and
$\alpha=\Theta(1/N)$, with only one Newton step provided $\eta\alpha\gg1/N$,
where $N$ is the number of data points and the stopping criterion that the
predicted reduction is less than $\eta\alpha$. The experimental results show
that our algorithm is capable of strong test accuracy without sacrificing
training speed.
\\ ( https://arxiv.org/abs/2401.09431 ,  493kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09441 (*cross-listing*)
Date: Wed, 20 Dec 2023 11:55:06 GMT   (28kb)

Title: Voxceleb-ESP: preliminary experiments detecting Spanish celebrities from
  their voices
Authors: Beltr\'an Labrador, Manuel Otero-Gonzalez, Alicia Lozano-Diez, Daniel
  Ramos, Doroteo T. Toledano, Joaquin Gonzalez-Rodriguez
Categories: cs.SD cs.LG eess.AS
\\
  This paper presents VoxCeleb-ESP, a collection of pointers and timestamps to
YouTube videos facilitating the creation of a novel speaker recognition
dataset. VoxCeleb-ESP captures real-world scenarios, incorporating diverse
speaking styles, noises, and channel distortions. It includes 160 Spanish
celebrities spanning various categories, ensuring a representative distribution
across age groups and geographic regions in Spain. We provide two speaker trial
lists for speaker identification tasks, each of them with same-video or
different-video target trials respectively, accompanied by a cross-lingual
evaluation of ResNet pretrained models. Preliminary speaker identification
results suggest that the complexity of the detection task in VoxCeleb-ESP is
equivalent to that of the original and much larger VoxCeleb in English.
VoxCeleb-ESP contributes to the expansion of speaker recognition benchmarks
with a comprehensive and diverse dataset for the Spanish language.
\\ ( https://arxiv.org/abs/2401.09441 ,  28kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09456 (*cross-listing*)
Date: Sat, 23 Dec 2023 03:58:41 GMT   (36kb)

Title: Parametric Constraints for Bayesian Knowledge Tracing from First
  Principles
Authors: Denis Shchepakin, Sreecharan Sankaranarayanan, Dawn Zimmaro
Categories: cs.CY cs.LG stat.ML
MSC-class: 62F15 (Primary) 62M05, 60J20, 68T30, 91E40 (Secondary)
\\
  Bayesian Knowledge Tracing (BKT) is a probabilistic model of a learner's
state of mastery corresponding to a knowledge component. It considers the
learner's state of mastery as a "hidden" or latent binary variable and updates
this state based on the observed correctness of the learner's response using
parameters that represent transition probabilities between states. BKT is often
represented as a Hidden Markov Model and the Expectation-Maximization (EM)
algorithm is used to infer these parameters. However, this algorithm can suffer
from several issues including producing multiple viable sets of parameters,
settling into a local minima, producing degenerate parameter values, and a high
computational cost during fitting. This paper takes a "from first principles"
approach to deriving constraints that can be imposed on the BKT parameter
space. Starting from the basic mathematical truths of probability and building
up to the behaviors expected of the BKT parameters in real systems, this paper
presents a mathematical derivation that results in succinct constraints that
can be imposed on the BKT parameter space. Since these constraints are
necessary conditions, they can be applied prior to fitting in order to reduce
computational cost and the likelihood of issues that can emerge from the EM
procedure. In order to see that promise through, the paper further introduces a
novel algorithm for estimating BKT parameters subject to the newly defined
constraints. While the issue of degenerate parameter values has been reported
previously, this paper is the first, to our best knowledge, to derive the
constrains from first principles while also presenting an algorithm that
respects those constraints.
\\ ( https://arxiv.org/abs/2401.09456 ,  36kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09471 (*cross-listing*)
Date: Thu, 11 Jan 2024 10:30:09 GMT   (701kb)

Title: Brain Tumor Radiogenomic Classification
Authors: Amr Mohamed, Mahmoud Rabea, Aya Sameh, Ehab Kamal
Categories: eess.IV cs.CV cs.LG
Comments: 6 Pages with 4 Tables, 4 Figures and 4 Images
\\
  The RSNA-MICCAI brain tumor radiogenomic classification challenge aimed to
predict MGMT biomarker status in glioblastoma through binary classification on
Multi parameter mpMRI scans: T1w, T1wCE, T2w and FLAIR. The dataset is splitted
into three main cohorts: training set, validation set which were used during
training, and the testing were only used during final evaluation. Images were
either in a DICOM format or in Png format. different architectures were used to
investigate the problem including the 3D version of Vision Transformer (ViT3D),
ResNet50, Xception and EfficientNet-B3. AUC was used as the main evaluation
metric and the results showed an advantage for both the ViT3D and the Xception
models achieving 0.6015 and 0.61745 respectively on the testing set. compared
to other results, our results proved to be valid given the complexity of the
task. further improvements can be made through exploring different strategies,
different architectures and more diverse datasets.
\\ ( https://arxiv.org/abs/2401.09471 ,  701kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09475 (*cross-listing*)
Date: Sat, 13 Jan 2024 03:29:56 GMT   (20119kb,D)

Title: Triamese-ViT: A 3D-Aware Method for Robust Brain Age Estimation from
  MRIs
Authors: Zhaonian Zhang and Richard Jiang
Categories: cs.CV cs.LG
\\
  The integration of machine learning in medicine has significantly improved
diagnostic precision, particularly in the interpretation of complex structures
like the human brain. Diagnosing challenging conditions such as Alzheimer's
disease has prompted the development of brain age estimation techniques. These
methods often leverage three-dimensional Magnetic Resonance Imaging (MRI)
scans, with recent studies emphasizing the efficacy of 3D convolutional neural
networks (CNNs) like 3D ResNet. However, the untapped potential of Vision
Transformers (ViTs), known for their accuracy and interpretability, persists in
this domain due to limitations in their 3D versions. This paper introduces
Triamese-ViT, an innovative adaptation of the ViT model for brain age
estimation. Our model uniquely combines ViTs from three different orientations
to capture 3D information, significantly enhancing accuracy and
interpretability. Tested on a dataset of 1351 MRI scans, Triamese-ViT achieves
a Mean Absolute Error (MAE) of 3.84, a 0.9 Spearman correlation coefficient
with chronological age, and a -0.29 Spearman correlation coefficient between
the brain age gap (BAG) and chronological age, significantly better than
previous methods for brian age estimation. A key innovation of Triamese-ViT is
its capacity to generate a comprehensive 3D-like attention map, synthesized
from 2D attention maps of each orientation-specific ViT. This feature is
particularly beneficial for in-depth brain age analysis and disease diagnosis,
offering deeper insights into brain health and the mechanisms of age-related
neural changes.
\\ ( https://arxiv.org/abs/2401.09475 ,  20119kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09493 (*cross-listing*)
Date: Wed, 17 Jan 2024 01:17:12 GMT   (31803kb,D)

Title: Identifying Three-Dimensional Radiative Patterns Associated with Early
  Tropical Cyclone Intensification
Authors: Frederick Iat-Hin Tam, Tom Beucler, James H. Ruppert Jr
Categories: physics.ao-ph cs.LG
Comments: 12 pages, 4 figures (main text)
\\
  Cloud radiative feedback impacts early tropical cyclone (TC) intensification,
but limitations in existing diagnostic frameworks make them unsuitable for
studying asymmetric or transient radiative heating. We propose a linear
Variational Encoder-Decoder (VED) to learn the hidden relationship between
radiation and the surface intensification of realistic simulated TCs. Limiting
VED model inputs enables using its uncertainty to identify periods when
radiation has more importance for intensification. A close examination of the
extracted 3D radiative structures suggests that longwave radiative forcing from
inner core deep convection and shallow clouds both contribute to
intensification, with the deep convection having the most impact overall. We
find that deep convection downwind of the shallow clouds is critical to the
intensification of Haiyan. Our work demonstrates that machine learning can
discover thermodynamic-kinematic relationships without relying on axisymmetric
or deterministic assumptions, paving the way towards the objective discovery of
processes leading to TC intensification in realistic conditions.
\\ ( https://arxiv.org/abs/2401.09493 ,  31803kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09494 (*cross-listing*)
Date: Wed, 17 Jan 2024 01:33:37 GMT   (990kb,D)

Title: VeriBug: An Attention-based Framework for Bug-Localization in Hardware
  Designs
Authors: Giuseppe Stracquadanio, Sourav Medya, Stefano Quer, and Debjit Pal
Categories: cs.AR cs.LG
\\
  In recent years, there has been an exponential growth in the size and
complexity of System-on-Chip designs targeting different specialized
applications. The cost of an undetected bug in these systems is much higher
than in traditional processor systems as it may imply the loss of property or
life. The problem is further exacerbated by the ever-shrinking time-to-market
and ever-increasing demand to churn out billions of devices. Despite decades of
research in simulation and formal methods for debugging and verification, it is
still one of the most time-consuming and resource intensive processes in
contemporary hardware design cycle. In this work, we propose VeriBug, which
leverages recent advances in deep learning to accelerate debugging at the
Register-Transfer Level and generates explanations of likely root causes.
First, VeriBug uses control-data flow graph of a hardware design and learns to
execute design statements by analyzing the context of operands and their
assignments. Then, it assigns an importance score to each operand in a design
statement and uses that score for generating explanations for failures.
Finally, VeriBug produces a heatmap highlighting potential buggy source code
portions. Our experiments show that VeriBug can achieve an average bug
localization coverage of 82.5% on open-source designs and different types of
injected bugs.
\\ ( https://arxiv.org/abs/2401.09494 ,  990kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09509 (*cross-listing*)
Date: Wed, 17 Jan 2024 12:55:17 GMT   (4283kb,D)

Title: Exploration of Activation Fault Reliability in Quantized Systolic
  Array-Based DNN Accelerators
Authors: Mahdi Taheri, Natalia Cherezova, Mohammad Saeed Ansari, Maksim
  Jenihhin, Ali Mahani, Masoud Daneshtalab, Jaan Raik
Categories: cs.AR cs.LG
Comments:
\\
  The stringent requirements for the Deep Neural Networks (DNNs) accelerator's
reliability stand along with the need for reducing the computational burden on
the hardware platforms, i.e. reducing the energy consumption and execution time
as well as increasing the efficiency of DNN accelerators. Moreover, the growing
demand for specialized DNN accelerators with tailored requirements,
particularly for safety-critical applications, necessitates a comprehensive
design space exploration to enable the development of efficient and robust
accelerators that meet those requirements. Therefore, the trade-off between
hardware performance, i.e. area and delay, and the reliability of the DNN
accelerator implementation becomes critical and requires tools for analysis.
This paper presents a comprehensive methodology for exploring and enabling a
holistic assessment of the trilateral impact of quantization on model accuracy,
activation fault reliability, and hardware efficiency. A fully automated
framework is introduced that is capable of applying various quantization-aware
techniques, fault injection, and hardware implementation, thus enabling the
measurement of hardware parameters. Moreover, this paper proposes a novel
lightweight protection technique integrated within the framework to ensure the
dependable deployment of the final systolic-array-based FPGA implementation.
The experiments on established benchmarks demonstrate the analysis flow and the
profound implications of quantization on reliability, hardware performance, and
network accuracy, particularly concerning the transient faults in the network's
activations.
\\ ( https://arxiv.org/abs/2401.09509 ,  4283kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09510 (*cross-listing*)
Date: Wed, 17 Jan 2024 13:39:38 GMT   (1996kb,D)

Title: Community Detection in the Multi-View Stochastic Block Model
Authors: Yexin Zhang, Zhongtian Ma, Qiaosheng Zhang, Zhen Wang, Xuelong Li
Categories: cs.SI cs.IT cs.LG eess.SP math.IT
Comments: Submitted to IEEE for possible publication
\\
  This paper considers the problem of community detection on multiple
potentially correlated graphs from an information-theoretical perspective. We
first put forth a random graph model, called the multi-view stochastic block
model (MVSBM), designed to generate correlated graphs on the same set of nodes
(with cardinality $n$). The $n$ nodes are partitioned into two disjoint
communities of equal size. The presence or absence of edges in the graphs for
each pair of nodes depends on whether the two nodes belong to the same
community or not. The objective for the learner is to recover the hidden
communities with observed graphs. Our technical contributions are two-fold: (i)
We establish an information-theoretic upper bound (Theorem~1) showing that
exact recovery of community is achievable when the model parameters of MVSBM
exceed a certain threshold. (ii) Conversely, we derive an information-theoretic
lower bound (Theorem~2) showing that when the model parameters of MVSBM fall
below the aforementioned threshold, then for any estimator, the expected number
of misclassified nodes will always be greater than one. Our results for the
MVSBM recover several prior results for community detection in the standard SBM
as well as in multiple independent SBMs as special cases.
\\ ( https://arxiv.org/abs/2401.09510 ,  1996kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09515 (*cross-listing*)
Date: Wed, 17 Jan 2024 15:30:17 GMT   (8011kb,D)

Title: Enhancing Surveillance Camera FOV Quality via Semantic Line Detection
  and Classification with Deep Hough Transform
Authors: Andrew C. Freeman, Wenjing Shi, Bin Hwang
Categories: cs.CV cs.LG
Comments: Appeared in the WACV 2024 Workshop on Image/Video/Audio Quality in
  Computer Vision and Generative AI
\\
  The quality of recorded videos and images is significantly influenced by the
camera's field of view (FOV). In critical applications like surveillance
systems and self-driving cars, an inadequate FOV can give rise to severe safety
and security concerns, including car accidents and thefts due to the failure to
detect individuals and objects. The conventional methods for establishing the
correct FOV heavily rely on human judgment and lack automated mechanisms to
assess video and image quality based on FOV. In this paper, we introduce an
innovative approach that harnesses semantic line detection and classification
alongside deep Hough transform to identify semantic lines, thus ensuring a
suitable FOV by understanding 3D view through parallel lines. Our approach
yields an effective F1 score of 0.729 on the public EgoCart dataset, coupled
with a notably high median score in the line placement metric. We illustrate
that our method offers a straightforward means of assessing the quality of the
camera's field of view, achieving a classification accuracy of 83.8\%. This
metric can serve as a proxy for evaluating the potential performance of video
and image quality applications.
\\ ( https://arxiv.org/abs/2401.09515 ,  8011kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09579 (*cross-listing*)
Date: Wed, 17 Jan 2024 20:00:16 GMT   (510kb,D)

Title: Fully-blind Neural Network Based Equalization for Severe Nonlinear
  Distortions in 112 Gbit/s Passive Optical Networks
Authors: Vincent Lauinger, Patrick Matalla, Jonas Ney, Norbert Wehn, Sebastian
  Randel, and Laurent Schmalen
Categories: eess.SP cs.LG
Comments: Accepted and to be presented at the Optical Fiber Communication
  Conference (OFC) 2024
\\
  We demonstrate and evaluate a fully-blind digital signal processing (DSP)
chain for 100G passive optical networks (PONs), and analyze different equalizer
topologies based on neural networks with low hardware complexity.
\\ ( https://arxiv.org/abs/2401.09579 ,  510kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09596 (*cross-listing*)
Date: Wed, 17 Jan 2024 21:08:41 GMT   (9200kb,D)

Title: Efficient generative adversarial networks using linear
  additive-attention Transformers
Authors: Emilio Morales-Juarez and Gibran Fuentes-Pineda
Categories: cs.CV cs.LG
Comments: 12 pages, 6 figures
\\
  Although the capacity of deep generative models for image generation, such as
Diffusion Models (DMs) and Generative Adversarial Networks (GANs), has
dramatically improved in recent years, much of their success can be attributed
to computationally expensive architectures. This has limited their adoption and
use to research laboratories and companies with large resources, while
significantly raising the carbon footprint for training, fine-tuning, and
inference. In this work, we present LadaGAN, an efficient generative
adversarial network that is built upon a novel Transformer block named
Ladaformer. The main component of this block is a linear additive-attention
mechanism that computes a single attention vector per head instead of the
quadratic dot-product attention. We employ Ladaformer in both the generator and
discriminator, which reduces the computational complexity and overcomes the
training instabilities often associated with Transformer GANs. LadaGAN
consistently outperforms existing convolutional and Transformer GANs on
benchmark datasets at different resolutions while being significantly more
efficient. Moreover, LadaGAN shows competitive performance compared to
state-of-the-art multi-step generative models (e.g. DMs) using orders of
magnitude less computational resources.
\\ ( https://arxiv.org/abs/2401.09596 ,  9200kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09604 (*cross-listing*)
Date: Wed, 17 Jan 2024 21:30:22 GMT   (3907kb,D)

Title: MedBlindTuner: Towards Privacy-preserving Fine-tuning on Biomedical
  Images with Transformers and Fully Homomorphic Encryption
Authors: Prajwal Panzade, Daniel Takabi, Zhipeng Cai
Categories: cs.CR cs.CV cs.LG
Comments: Accepted for the presentation at W3PHIAI, The 38th Annual AAAI
  Conference on Artificial Intelligence 2024
\\
  Advancements in machine learning (ML) have significantly revolutionized
medical image analysis, prompting hospitals to rely on external ML services.
However, the exchange of sensitive patient data, such as chest X-rays, poses
inherent privacy risks when shared with third parties. Addressing this concern,
we propose MedBlindTuner, a privacy-preserving framework leveraging fully
homomorphic encryption (FHE) and a data-efficient image transformer (DEiT).
MedBlindTuner enables the training of ML models exclusively on FHE-encrypted
medical images. Our experimental evaluation demonstrates that MedBlindTuner
achieves comparable accuracy to models trained on non-encrypted images,
offering a secure solution for outsourcing ML computations while preserving
patient data privacy. To the best of our knowledge, this is the first work that
uses data-efficient image transformers and fully homomorphic encryption in this
domain.
\\ ( https://arxiv.org/abs/2401.09604 ,  3907kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09606 (*cross-listing*)
Date: Wed, 17 Jan 2024 21:32:03 GMT   (8342kb,D)

Title: Robustness Evaluation of Machine Learning Models for Robot Arm Action
  Recognition in Noisy Environments
Authors: Elaheh Motamedi, Kian Behzad, Rojin Zandi, Hojjat Salehinejad and
  Milad Siami
Categories: cs.CV cs.LG cs.RO
Comments: Accepted at ICASSP
\\
  In the realm of robot action recognition, identifying distinct but spatially
proximate arm movements using vision systems in noisy environments poses a
significant challenge. This paper studies robot arm action recognition in noisy
environments using machine learning techniques. Specifically, a vision system
is used to track the robot's movements followed by a deep learning model to
extract the arm's key points. Through a comparative analysis of machine
learning methods, the effectiveness and robustness of this model are assessed
in noisy environments. A case study was conducted using the Tic-Tac-Toe game in
a 3-by-3 grid environment, where the focus is to accurately identify the
actions of the arms in selecting specific locations within this constrained
environment. Experimental results show that our approach can achieve precise
key point detection and action classification despite the addition of noise and
uncertainties to the dataset.
\\ ( https://arxiv.org/abs/2401.09606 ,  8342kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09607 (*cross-listing*)
Date: Wed, 17 Jan 2024 21:32:04 GMT   (701kb,D)

Title: Land Cover Image Classification
Authors: Antonio Rangel, Juan Terven, Diana M. Cordova-Esparza, E.A.
  Chavez-Urbiola
Categories: cs.CV cs.LG eess.IV
Comments: 7 pages, 4 figures, 1 table, published in conference
ACM-class: I.2.10
\\
  Land Cover (LC) image classification has become increasingly significant in
understanding environmental changes, urban planning, and disaster management.
However, traditional LC methods are often labor-intensive and prone to human
error. This paper explores state-of-the-art deep learning models for enhanced
accuracy and efficiency in LC analysis. We compare convolutional neural
networks (CNN) against transformer-based methods, showcasing their applications
and advantages in LC studies. We used EuroSAT, a patch-based LC classification
data set based on Sentinel-2 satellite images and achieved state-of-the-art
results using current transformer models.
\\ ( https://arxiv.org/abs/2401.09607 ,  701kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09622 (*cross-listing*)
Date: Wed, 17 Jan 2024 22:23:29 GMT   (1272kb,D)

Title: SMOOTHIE: A Theory of Hyper-parameter Optimization for Software
  Analytics
Authors: Rahul Yedida and Tim Menzies
Categories: cs.SE cs.LG
Comments: v1
\\
  Hyper-parameter optimization is the black art of tuning a learner's control
parameters. In software analytics, a repeated result is that such tuning can
result in dramatic performance improvements. Despite this, hyper-parameter
optimization is often applied rarely or poorly in software analytics--perhaps
due to the CPU cost of exploring all those parameter options can be
prohibitive.
  We theorize that learners generalize better when the loss landscape is
``smooth''. This theory is useful since the influence on ``smoothness'' of
different hyper-parameter choices can be tested very quickly (e.g. for a deep
learner, after just one epoch).
  To test this theory, this paper implements and tests SMOOTHIE, a novel
hyper-parameter optimizer that guides its optimizations via considerations of
``smothness''. The experiments of this paper test SMOOTHIE on numerous SE tasks
including (a) GitHub issue lifetime prediction; (b) detecting false alarms in
static code warnings; (c) defect prediction, and (d) a set of standard ML
datasets. In all these experiments, SMOOTHIE out-performed state-of-the-art
optimizers. Better yet, SMOOTHIE ran 300% faster than the prior state-of-the
art. We hence conclude that this theory (that hyper-parameter optimization is
best viewed as a ``smoothing'' function for the decision landscape), is both
theoretically interesting and practically very useful.
  To support open science and other researchers working in this area, all our
scripts and datasets are available on-line at
https://github.com/yrahul3910/smoothness-hpo/.
\\ ( https://arxiv.org/abs/2401.09622 ,  1272kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09624 (*cross-listing*)
Date: Wed, 17 Jan 2024 22:30:41 GMT   (7582kb,D)

Title: MITS-GAN: Safeguarding Medical Imaging from Tampering with Generative
  Adversarial Networks
Authors: Giovanni Pasqualino, Luca Guarnera, Alessandro Ortis, Sebastiano
  Battiato
Categories: eess.IV cs.CV cs.LG
\\
  The progress in generative models, particularly Generative Adversarial
Networks (GANs), opened new possibilities for image generation but raised
concerns about potential malicious uses, especially in sensitive areas like
medical imaging. This study introduces MITS-GAN, a novel approach to prevent
tampering in medical images, with a specific focus on CT scans. The approach
disrupts the output of the attacker's CT-GAN architecture by introducing
imperceptible but yet precise perturbations. Specifically, the proposed
approach involves the introduction of appropriate Gaussian noise to the input
as a protective measure against various attacks. Our method aims to enhance
tamper resistance, comparing favorably to existing techniques. Experimental
results on a CT scan dataset demonstrate MITS-GAN's superior performance,
emphasizing its ability to generate tamper-resistant images with negligible
artifacts. As image tampering in medical domains poses life-threatening risks,
our proactive approach contributes to the responsible and ethical use of
generative models. This work provides a foundation for future research in
countering cyber threats in medical imaging. Models and codes are publicly
available at the following link
\url{https://iplab.dmi.unict.it/MITS-GAN-2024/}.
\\ ( https://arxiv.org/abs/2401.09624 ,  7582kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09627 (*cross-listing*)
Date: Wed, 17 Jan 2024 22:34:20 GMT   (2582kb)

Title: SymTC: A Symbiotic Transformer-CNN Net for Instance Segmentation of
  Lumbar Spine MRI
Authors: Jiasong Chen, Linchen Qian, Linhai Ma, Timur Urakov, Weiyong Gu, Liang
  Liang
Categories: eess.IV cs.CV cs.LG
\\
  Intervertebral disc disease, a prevalent ailment, frequently leads to
intermittent or persistent low back pain, and diagnosing and assessing of this
disease rely on accurate measurement of vertebral bone and intervertebral disc
geometries from lumbar MR images. Deep neural network (DNN) models may assist
clinicians with more efficient image segmentation of individual instances
(disks and vertebrae) of the lumbar spine in an automated way, which is termed
as instance image segmentation. In this work, we proposed SymTC, an innovative
lumbar spine MR image segmentation model that combines the strengths of
Transformer and Convolutional Neural Network (CNN). Specifically, we designed a
parallel dual-path architecture to merge CNN layers and Transformer layers, and
we integrated a novel position embedding into the self-attention module of
Transformer, enhancing the utilization of positional information for more
accurate segmentation. To further improves model performance, we introduced a
new data augmentation technique to create synthetic yet realistic MR image
dataset, named SSMSpine, which is made publicly available. We evaluated our
SymTC and the other 15 existing image segmentation models on our private
in-house dataset and the public SSMSpine dataset, using two metrics, Dice
Similarity Coefficient and 95% Hausdorff Distance. The results show that our
SymTC has the best performance for segmenting vertebral bones and
intervertebral discs in lumbar spine MR images. The SymTC code and SSMSpine
dataset are available at https://github.com/jiasongchen/SymTC.
\\ ( https://arxiv.org/abs/2401.09627 ,  2582kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09638 (*cross-listing*)
Date: Wed, 17 Jan 2024 23:17:08 GMT   (1123kb,D)

Title: Automatic 3D Multi-modal Ultrasound Segmentation of Human Placenta using
  Fusion Strategies and Deep Learning
Authors: Sonit Singh, Gordon Stevenson, Brendan Mein, Alec Welsh and Arcot
  Sowmya
Categories: eess.IV cs.CV cs.LG
\\
  Purpose: Ultrasound is the most commonly used medical imaging modality for
diagnosis and screening in clinical practice. Due to its safety profile,
noninvasive nature and portability, ultrasound is the primary imaging modality
for fetal assessment in pregnancy. Current ultrasound processing methods are
either manual or semi-automatic and are therefore laborious, time-consuming and
prone to errors, and automation would go a long way in addressing these
challenges. Automated identification of placental changes at earlier gestation
could facilitate potential therapies for conditions such as fetal growth
restriction and pre-eclampsia that are currently detected only at late
gestational age, potentially preventing perinatal morbidity and mortality.
  Methods: We propose an automatic three-dimensional multi-modal (B-mode and
power Doppler) ultrasound segmentation of the human placenta using deep
learning combined with different fusion strategies.We collected data containing
Bmode and power Doppler ultrasound scans for 400 studies.
  Results: We evaluated different fusion strategies and state-of-the-art image
segmentation networks for placenta segmentation based on standard overlap- and
boundary-based metrics. We found that multimodal information in the form of
B-mode and power Doppler scans outperform any single modality. Furthermore, we
found that B-mode and power Doppler input scans fused at the data level provide
the best results with a mean Dice Similarity Coefficient (DSC) of 0.849.
  Conclusion: We conclude that the multi-modal approach of combining B-mode and
power Doppler scans is effective in segmenting the placenta from 3D ultrasound
scans in a fully automated manner and is robust to quality variation of the
datasets.
\\ ( https://arxiv.org/abs/2401.09638 ,  1123kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09665 (*cross-listing*)
Date: Thu, 18 Jan 2024 00:50:37 GMT   (1764kb,D)

Title: Accelerating Distributed Stochastic Optimization via Self-Repellent
  Random Walks
Authors: Jie Hu and Vishwaraj Doshi and Do Young Eun
Categories: math.PR cs.LG math.OC
Comments: Accepted for oral presentation at the Twelfth International
  Conference on Learning Representations (ICLR 2024)
\\
  We study a family of distributed stochastic optimization algorithms where
gradients are sampled by a token traversing a network of agents in random-walk
fashion. Typically, these random-walks are chosen to be Markov chains that
asymptotically sample from a desired target distribution, and play a critical
role in the convergence of the optimization iterates. In this paper, we take a
novel approach by replacing the standard linear Markovian token by one which
follows a nonlinear Markov chain - namely the Self-Repellent Radom Walk (SRRW).
Defined for any given 'base' Markov chain, the SRRW, parameterized by a
positive scalar {\alpha}, is less likely to transition to states that were
highly visited in the past, thus the name. In the context of MCMC sampling on a
graph, a recent breakthrough in Doshi et al. (2023) shows that the SRRW
achieves O(1/{\alpha}) decrease in the asymptotic variance for sampling. We
propose the use of a 'generalized' version of the SRRW to drive token
algorithms for distributed stochastic optimization in the form of stochastic
approximation, termed SA-SRRW. We prove that the optimization iterate errors of
the resulting SA-SRRW converge to zero almost surely and prove a central limit
theorem, deriving the explicit form of the resulting asymptotic covariance
matrix corresponding to iterate errors. This asymptotic covariance is always
smaller than that of an algorithm driven by the base Markov chain and decreases
at rate O(1/{\alpha}^2) - the performance benefit of using SRRW thereby
amplified in the stochastic optimization context. Empirical results support our
theoretical findings.
\\ ( https://arxiv.org/abs/2401.09665 ,  1764kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09673 (*cross-listing*)
Date: Thu, 18 Jan 2024 01:18:59 GMT   (12733kb,D)

Title: Artwork Protection Against Neural Style Transfer Using Locally Adaptive
  Adversarial Color Attack
Authors: Zhongliang Guo, Kaixuan Wang, Weiye Li, Yifei Qian, Ognjen
  Arandjelovi\'c and Lei Fang
Categories: cs.CV cs.CR cs.LG eess.IV
Comments: 9 pages, 5 figures
\\
  Neural style transfer (NST) is widely adopted in computer vision to generate
new images with arbitrary styles. This process leverages neural networks to
merge aesthetic elements of a style image with the structural aspects of a
content image into a harmoniously integrated visual result. However,
unauthorized NST can exploit artwork. Such misuse raises socio-technical
concerns regarding artists' rights and motivates the development of technical
approaches for the proactive protection of original creations. Adversarial
attack is a concept primarily explored in machine learning security. Our work
introduces this technique to protect artists' intellectual property. In this
paper Locally Adaptive Adversarial Color Attack (LAACA), a method for altering
images in a manner imperceptible to the human eyes but disruptive to NST.
Specifically, we design perturbations targeting image areas rich in
high-frequency content, generated by disrupting intermediate features. Our
experiments and user study confirm that by attacking NST using the proposed
method results in visually worse neural style transfer, thus making it an
effective solution for visual artwork protection.
\\ ( https://arxiv.org/abs/2401.09673 ,  12733kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09693 (*cross-listing*)
Date: Thu, 18 Jan 2024 02:48:06 GMT   (3596kb,D)

Title: EfficientRec an unlimited user-item scale recommendation system based on
  clustering and users interaction embedding profile
Authors: Vu Hong Quan, Le Hoang Ngan, Le Minh Duc, Nguyen Tran Ngoc Linh, and
  Hoang Quynh-Le
Categories: cs.IR cs.LG
Comments: Published in 14th Asian Conference on Intelligent Information and
  Database Systems (ACIIDS), 2022
DOI: 10.1007/978-981-19-8234-7_53
\\
  Recommendation systems are highly interested in technology companies
nowadays. The businesses are constantly growing users and products, causing the
number of users and items to continuously increase over time, to very large
numbers. Traditional recommendation algorithms with complexity dependent on the
number of users and items make them difficult to adapt to the industrial
environment. In this paper, we introduce a new method applying graph neural
networks with a contrastive learning framework in extracting user preferences.
We incorporate a soft clustering architecture that significantly reduces the
computational cost of the inference process. Experiments show that the model is
able to learn user preferences with low computational cost in both training and
prediction phases. At the same time, the model gives a very good accuracy. We
call this architecture EfficientRec with the implication of model compactness
and the ability to scale to unlimited users and products.
\\ ( https://arxiv.org/abs/2401.09693 ,  3596kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09752 (*cross-listing*)
Date: Thu, 18 Jan 2024 06:52:52 GMT   (819kb,D)

Title: Improving Speaker-independent Speech Emotion Recognition Using Dynamic
  Joint Distribution Adaptation
Authors: Cheng Lu, Yuan Zong, Hailun Lian, Yan Zhao, Bj\"orn Schuller, and
  Wenming Zheng
Categories: cs.SD cs.LG eess.AS
Comments: Accepted by ICASSP 2024
\\
  In speaker-independent speech emotion recognition, the training and testing
samples are collected from diverse speakers, leading to a multi-domain shift
challenge across the feature distributions of data from different speakers.
Consequently, when the trained model is confronted with data from new speakers,
its performance tends to degrade. To address the issue, we propose a Dynamic
Joint Distribution Adaptation (DJDA) method under the framework of multi-source
domain adaptation. DJDA firstly utilizes joint distribution adaptation (JDA),
involving marginal distribution adaptation (MDA) and conditional distribution
adaptation (CDA), to more precisely measure the multi-domain distribution
shifts caused by different speakers. This helps eliminate speaker bias in
emotion features, allowing for learning discriminative and speaker-invariant
speech emotion features from coarse-level to fine-level. Furthermore, we
quantify the adaptation contributions of MDA and CDA within JDA by using a
dynamic balance factor based on $\mathcal{A}$-Distance, promoting to
effectively handle the unknown distributions encountered in data from new
speakers. Experimental results demonstrate the superior performance of our DJDA
as compared to other state-of-the-art (SOTA) methods.
\\ ( https://arxiv.org/abs/2401.09752 ,  819kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09791 (*cross-listing*)
Date: Thu, 18 Jan 2024 08:23:29 GMT   (1543kb)

Title: BreastRegNet: A Deep Learning Framework for Registration of Breast
  Faxitron and Histopathology Images
Authors: Negar Golestani, Aihui Wang, Gregory R Bean, and Mirabela Rusu
Categories: eess.IV cs.CV cs.LG
\\
  A standard treatment protocol for breast cancer entails administering
neoadjuvant therapy followed by surgical removal of the tumor and surrounding
tissue. Pathologists typically rely on cabinet X-ray radiographs, known as
Faxitron, to examine the excised breast tissue and diagnose the extent of
residual disease. However, accurately determining the location, size, and
focality of residual cancer can be challenging, and incorrect assessments can
lead to clinical consequences. The utilization of automated methods can improve
the histopathology process, allowing pathologists to choose regions for
sampling more effectively and precisely. Despite the recognized necessity,
there are currently no such methods available. Training such automated
detection models require accurate ground truth labels on ex-vivo radiology
images, which can be acquired through registering Faxitron and histopathology
images and mapping the extent of cancer from histopathology to x-ray images.
This study introduces a deep learning-based image registration approach trained
on mono-modal synthetic image pairs. The models were trained using data from 50
women who received neoadjuvant chemotherapy and underwent surgery. The results
demonstrate that our method is faster and yields significantly lower average
landmark error ($2.1\pm1.96$ mm) over the state-of-the-art iterative
($4.43\pm4.1$ mm) and deep learning ($4.02\pm3.15$ mm) approaches. Improved
performance of our approach in integrating radiology and pathology information
facilitates generating large datasets, which allows training models for more
accurate breast cancer detection.
\\ ( https://arxiv.org/abs/2401.09791 ,  1543kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09804 (*cross-listing*)
Date: Thu, 18 Jan 2024 08:48:54 GMT   (3653kb,D)

Title: Clickbait vs. Quality: How Engagement-Based Optimization Shapes the
  Content Landscape in Online Platforms
Authors: Nicole Immorlica, Meena Jagadeesan, Brendan Lucier
Categories: cs.GT cs.CY cs.LG
\\
  Online content platforms commonly use engagement-based optimization when
making recommendations. This encourages content creators to invest in quality,
but also rewards gaming tricks such as clickbait. To understand the total
impact on the content landscape, we study a game between content creators
competing on the basis of engagement metrics and analyze the equilibrium
decisions about investment in quality and gaming. First, we show the content
created at equilibrium exhibits a positive correlation between quality and
gaming, and we empirically validate this finding on a Twitter dataset. Using
the equilibrium structure of the content landscape, we then examine the
downstream performance of engagement-based optimization along several axes.
Perhaps counterintuitively, the average quality of content consumed by users
can decrease at equilibrium as gaming tricks become more costly for content
creators to employ. Moreover, engagement-based optimization can perform worse
in terms of user utility than a baseline with random recommendations, and
engagement-based optimization is also suboptimal in terms of realized
engagement relative to quality-based optimization. Altogether, our results
highlight the need to consider content creator incentives when evaluating a
platform's choice of optimization metric.
\\ ( https://arxiv.org/abs/2401.09804 ,  3653kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09840 (*cross-listing*)
Date: Thu, 18 Jan 2024 09:54:19 GMT   (4348kb,D)

Title: FREED++: Improving RL Agents for Fragment-Based Molecule Generation by
  Thorough Reproduction
Authors: Alexander Telepov, Artem Tsypin, Kuzma Khrabrov, Sergey Yakukhnov,
  Pavel Strashnov, Petr Zhilyaev, Egor Rumiantsev, Daniel Ezhov, Manvel
  Avetisian, Olga Popova, Artur Kadurin
Categories: q-bio.BM cs.LG stat.ML
Comments: 37 pages, 10 figures, to be published in TMLR journal
  (https://www.jmlr.org/tmlr/)
\\
  A rational design of new therapeutic drugs aims to find a molecular structure
with desired biological functionality, e.g., an ability to activate or suppress
a specific protein via binding to it. Molecular docking is a common technique
for evaluating protein-molecule interactions. Recently, Reinforcement Learning
(RL) has emerged as a promising approach to generating molecules with the
docking score (DS) as a reward. In this work, we reproduce, scrutinize and
improve the recent RL model for molecule generation called FREED
(arXiv:2110.01219). Extensive evaluation of the proposed method reveals several
limitations and challenges despite the outstanding results reported for three
target proteins. Our contributions include fixing numerous implementation bugs
and simplifying the model while increasing its quality, significantly extending
experiments, and conducting an accurate comparison with current
state-of-the-art methods for protein-conditioned molecule generation. We show
that the resulting fixed model is capable of producing molecules with superior
docking scores compared to alternative approaches.
\\ ( https://arxiv.org/abs/2401.09840 ,  4348kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09902 (*cross-listing*)
Date: Thu, 18 Jan 2024 11:32:50 GMT   (4256kb,D)

Title: Interplay between depth and width for interpolation in neural ODEs
Authors: Antonio \'Alvarez-L\'opez, Arselane Hadj Slimane, Enrique Zuazua
  Iriondo
Categories: math.OC cs.LG
Comments: 16 pages, 10 figures, double column
MSC-class: 34H05, 68T07, 93B05 (Primary) 35Q49 (Secondary)
\\
  Neural ordinary differential equations (neural ODEs) have emerged as a
natural tool for supervised learning from a control perspective, yet a complete
understanding of their optimal architecture remains elusive. In this work, we
examine the interplay between their width $p$ and number of layer transitions
$L$ (effectively the depth $L+1$). Specifically, we assess the model
expressivity in terms of its capacity to interpolate either a finite dataset
$D$ comprising $N$ pairs of points or two probability measures in
$\mathbb{R}^d$ within a Wasserstein error margin $\varepsilon>0$. Our findings
reveal a balancing trade-off between $p$ and $L$, with $L$ scaling as
$O(1+N/p)$ for dataset interpolation, and
$L=O\left(1+(p\varepsilon^d)^{-1}\right)$ for measure interpolation.
  In the autonomous case, where $L=0$, a separate study is required, which we
undertake focusing on dataset interpolation. We address the relaxed problem of
$\varepsilon$-approximate controllability and establish an error decay of
$\varepsilon\sim O(\log(p)p^{-1/d})$. This decay rate is a consequence of
applying a universal approximation theorem to a custom-built Lipschitz vector
field that interpolates $D$. In the high-dimensional setting, we further
demonstrate that $p=O(N)$ neurons are likely sufficient to achieve exact
control.
\\ ( https://arxiv.org/abs/2401.09902 ,  4256kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09915 (*cross-listing*)
Date: Thu, 18 Jan 2024 11:54:42 GMT   (591kb,D)

Title: Qadence: a differentiable interface for digital-analog programs
Authors: Dominik Seitz, Niklas Heim, Jo\~ao P. Moutinho, Roland Guichard,
  Vytautas Abramavicius, Aleksander Wennersteen, Gert-Jan Both, Anton Quelle,
  Caroline de Groot, Gergana V. Velikova, Vincent E. Elfving, Mario Dagrada
Categories: quant-ph cs.LG cs.PL cs.SE
\\
  Digital-analog quantum computing (DAQC) is an alternative paradigm for
universal quantum computation combining digital single-qubit gates with global
analog operations acting on a register of interacting qubits. Currently, no
available open-source software is tailored to express, differentiate, and
execute programs within the DAQC paradigm. In this work, we address this
shortfall by presenting Qadence, a high-level programming interface for
building complex digital-analog quantum programs developed at Pasqal. Thanks to
its flexible interface, native differentiability, and focus on real-device
execution, Qadence aims at advancing research on variational quantum algorithms
built for native DAQC platforms such as Rydberg atom arrays.
\\ ( https://arxiv.org/abs/2401.09915 ,  591kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09979 (*cross-listing*)
Date: Thu, 18 Jan 2024 13:46:41 GMT   (57kb,D)

Title: False Discovery Rate Control for Gaussian Graphical Models via
  Neighborhood Screening
Authors: Taulant Koka, Jasin Machkour, Michael Muma
Categories: stat.ML cs.LG
\\
  Gaussian graphical models emerge in a wide range of fields. They model the
statistical relationships between variables as a graph, where an edge between
two variables indicates conditional dependence. Unfortunately, well-established
estimators, such as the graphical lasso or neighborhood selection, are known to
be susceptible to a high prevalence of false edge detections. False detections
may encourage inaccurate or even incorrect scientific interpretations, with
major implications in applications, such as biomedicine or healthcare. In this
paper, we introduce a nodewise variable selection approach to graph learning
and provably control the false discovery rate of the selected edge set at a
self-estimated level. A novel fusion method of the individual neighborhoods
outputs an undirected graph estimate. The proposed method is parameter-free and
does not require tuning by the user. Benchmarks against competing false
discovery rate controlling methods in numerical experiments considering
different graph topologies show a significant gain in performance.
\\ ( https://arxiv.org/abs/2401.09979 ,  57kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09980 (*cross-listing*)
Date: Thu, 18 Jan 2024 13:51:20 GMT   (777kb)

Title: Ventricular Segmentation: A Brief Comparison of U-Net Derivatives
Authors: Ketan Suhaas Saichandran
Categories: eess.IV cs.CV cs.LG
\\
  Medical imaging refers to the technologies and methods utilized to view the
human body and its inside, in order to diagnose, monitor, or even treat medical
disorders. This paper aims to explore the application of deep learning
techniques in the semantic segmentation of Cardiac short-axis MRI (Magnetic
Resonance Imaging) images, aiming to enhance the diagnosis, monitoring, and
treatment of medical disorders related to the heart. The focus centers on
implementing various architectures that are derivatives of U-Net, to
effectively isolate specific parts of the heart for comprehensive anatomical
and functional analysis. Through a combination of images, graphs, and
quantitative metrics, the efficacy of the models and their predictions are
showcased. Additionally, this paper addresses encountered challenges and
outline strategies for future improvements. This abstract provides a concise
overview of the efforts in utilizing deep learning for cardiac image
segmentation, emphasizing both the accomplishments and areas for further
refinement.
\\ ( https://arxiv.org/abs/2401.09980 ,  777kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10095 (*cross-listing*)
Date: Thu, 18 Jan 2024 16:05:00 GMT   (151kb,D)

Title: Learning shallow quantum circuits
Authors: Hsin-Yuan Huang, Yunchao Liu, Michael Broughton, Isaac Kim, Anurag
  Anshu, Zeph Landau, Jarrod R. McClean
Categories: quant-ph cs.IT cs.LG math.IT
Comments: 10 pages, 14 figures (7 inline; 7 floating) + 76-page appendix
\\
  Despite fundamental interests in learning quantum circuits, the existence of
a computationally efficient algorithm for learning shallow quantum circuits
remains an open question. Because shallow quantum circuits can generate
distributions that are classically hard to sample from, existing learning
algorithms do not apply. In this work, we present a polynomial-time classical
algorithm for learning the description of any unknown $n$-qubit shallow quantum
circuit $U$ (with arbitrary unknown architecture) within a small diamond
distance using single-qubit measurement data on the output states of $U$. We
also provide a polynomial-time classical algorithm for learning the description
of any unknown $n$-qubit state $\lvert \psi \rangle = U \lvert 0^n \rangle$
prepared by a shallow quantum circuit $U$ (on a 2D lattice) within a small
trace distance using single-qubit measurements on copies of $\lvert \psi
\rangle$. Our approach uses a quantum circuit representation based on local
inversions and a technique to combine these inversions. This circuit
representation yields an optimization landscape that can be efficiently
navigated and enables efficient learning of quantum circuits that are
classically hard to simulate.
\\ ( https://arxiv.org/abs/2401.10095 ,  151kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10107 (*cross-listing*)
Date: Thu, 18 Jan 2024 16:18:18 GMT   (439kb)

Title: Comparison analysis between standard polysomnographic data and
  in-ear-EEG signals: A preliminary study
Authors: Gianpaolo Palo, Luigi Fiorillo, Giuliana Monachino, Michal Bechny,
  Mark Melnykowycz, Athina Tzovara, Valentina Agostini, and Francesca Dalia
  Faraci
Categories: eess.SP cs.LG physics.med-ph
Comments: 29 pages, 12 figures, 1 table
\\
  Study Objectives: Polysomnography (PSG) currently serves as the benchmark for
evaluating sleep disorders. Its discomfort, impracticality for home-use, and
introduction of bias in sleep quality assessment necessitate the exploration of
less invasive, cost-effective, and portable alternatives. One promising
contender is the in-ear-EEG sensor, which offers advantages in terms of
comfort, fixed electrode positions, resistance to electromagnetic interference,
and user-friendliness. This study aims to establish a methodology to assess the
similarity between the in-ear-EEG signal and standard PSG.
  Methods: We assess the agreement between the PSG and in-ear-EEG derived
hypnograms. We extract features in the time- and frequency- domain from PSG and
in-ear-EEG 30-second epochs. We only consider the epochs where the PSG-scorers
and the in-ear-EEG-scorers were in agreement. We introduce a methodology to
quantify the similarity between PSG derivations and the single-channel
in-ear-EEG. The approach relies on a comparison of distributions of selected
features -- extracted for each sleep stage and subject on both PSG and the
in-ear-EEG signals -- via a Jensen-Shannon Divergence Feature-based Similarity
Index (JSD-FSI).
  Results: We found a high intra-scorer variability, mainly due to the
uncertainty the scorers had in evaluating the in-ear-EEG signals. We show that
the similarity between PSG and in-ear-EEG signals is high (JSD-FSI: 0.61 +/-
0.06 in awake, 0.60 +/- 0.07 in NREM and 0.51 +/- 0.08 in REM), and in line
with the similarity values computed independently on standard
PSG-channel-combinations.
  Conclusions: In-ear-EEG is a valuable solution for home-based sleep
monitoring, however further studies with a larger and more heterogeneous
dataset are needed.
\\ ( https://arxiv.org/abs/2401.10107 ,  439kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10144 (*cross-listing*)
Date: Wed, 17 Jan 2024 14:10:40 GMT   (9549kb,D)

Title: Exploiting Hierarchical Interactions for Protein Surface Learning
Authors: Yiqun Lin, Liang Pan, Yi Li, Ziwei Liu, and Xiaomeng Li
Categories: q-bio.BM cs.LG
Comments: Accepted to J-BHI
\\
  Predicting interactions between proteins is one of the most important yet
challenging problems in structural bioinformatics. Intrinsically, potential
function sites in protein surfaces are determined by both geometric and
chemical features. However, existing works only consider handcrafted or
individually learned chemical features from the atom type and extract geometric
features independently. Here, we identify two key properties of effective
protein surface learning: 1) relationship among atoms: atoms are linked with
each other by covalent bonds to form biomolecules instead of appearing alone,
leading to the significance of modeling the relationship among atoms in
chemical feature learning. 2) hierarchical feature interaction: the neighboring
residue effect validates the significance of hierarchical feature interaction
among atoms and between surface points and atoms (or residues). In this paper,
we present a principled framework based on deep learning techniques, namely
Hierarchical Chemical and Geometric Feature Interaction Network (HCGNet), for
protein surface analysis by bridging chemical and geometric features with
hierarchical interactions. Extensive experiments demonstrate that our method
outperforms the prior state-of-the-art method by 2.3% in site prediction task
and 3.2% in interaction matching task, respectively. Our code is available at
https://github.com/xmed-lab/HCGNet.
\\ ( https://arxiv.org/abs/2401.10144 ,  9549kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10190 (*cross-listing*)
Date: Thu, 18 Jan 2024 18:23:10 GMT   (4356kb,D)

Title: A Kaczmarz-inspired approach to accelerate the optimization of neural
  network wavefunctions
Authors: Gil Goldshlager, Nilin Abrahamsen, Lin Lin
Categories: physics.comp-ph cs.LG physics.chem-ph
\\
  Neural network wavefunctions optimized using the variational Monte Carlo
method have been shown to produce highly accurate results for the electronic
structure of atoms and small molecules, but the high cost of optimizing such
wavefunctions prevents their application to larger systems. We propose the
Subsampled Projected-Increment Natural Gradient Descent (SPRING) optimizer to
reduce this bottleneck. SPRING combines ideas from the recently introduced
minimum-step stochastic reconfiguration optimizer (MinSR) and the classical
randomized Kaczmarz method for solving linear least-squares problems. We
demonstrate that SPRING outperforms both MinSR and the popular
Kronecker-Factored Approximate Curvature method (KFAC) across a number of small
atoms and molecules, given that the learning rates of all methods are optimally
tuned. For example, on the oxygen atom, SPRING attains chemical accuracy after
forty thousand training iterations, whereas both MinSR and KFAC fail to do so
even after one hundred thousand iterations.
\\ ( https://arxiv.org/abs/2401.10190 ,  4356kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10213 (*cross-listing*)
Date: Thu, 4 Jan 2024 06:33:46 GMT   (1261kb)

Title: Improving automatic detection of driver fatigue and distraction using
  machine learning
Authors: Dongjiang Wu
Categories: cs.CV cs.CY cs.LG
Comments: Master's thesis, 55 pages
\\
  Changes and advances in information technology have played an important role
in the development of intelligent vehicle systems in recent years. Driver
fatigue and distracted driving are important factors in traffic accidents.
Thus, onboard monitoring of driving behavior has become a crucial component of
advanced driver assistance systems for intelligent vehicles. In this article,
we present techniques for simultaneously detecting fatigue and distracted
driving behaviors using vision-based and machine learning-based approaches. In
driving fatigue detection, we use facial alignment networks to identify facial
feature points in the images, and calculate the distance of the facial feature
points to detect the opening and closing of the eyes and mouth. Furthermore, we
use a convolutional neural network (CNN) based on the MobileNet architecture to
identify various distracted driving behaviors. Experiments are performed on a
PC based setup with a webcam and results are demonstrated using public datasets
as well as custom datasets created for training and testing. Compared to
previous approaches, we build our own datasets and provide better results in
terms of accuracy and computation time.
\\ ( https://arxiv.org/abs/2401.10213 ,  1261kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10220 (*cross-listing*)
Date: Thu, 18 Jan 2024 18:58:49 GMT   (923kb,D)

Title: AutoFT: Robust Fine-Tuning by Optimizing Hyperparameters on OOD Data
Authors: Caroline Choi, Yoonho Lee, Annie Chen, Allan Zhou, Aditi Raghunathan,
  Chelsea Finn
Categories: cs.CV cs.LG
Comments: 16 pages
\\
  Foundation models encode rich representations that can be adapted to a
desired task by fine-tuning on task-specific data. However, fine-tuning a model
on one particular data distribution often compromises the model's original
performance on other distributions. Current methods for robust fine-tuning
utilize hand-crafted regularization techniques to constrain the fine-tuning
process towards the base foundation model. Yet, it is hard to precisely specify
what characteristics of the foundation model to retain during fine-tuning, as
this depends on how the pre-training, fine-tuning, and evaluation data
distributions relate to each other. We propose AutoFT, a data-driven approach
for guiding foundation model fine-tuning. AutoFT optimizes fine-tuning
hyperparameters to maximize performance on a small out-of-distribution (OOD)
validation set. To guide fine-tuning in a granular way, AutoFT searches a
highly expressive hyperparameter space that includes weight coefficients for
many different losses, in addition to learning rate and weight decay values. We
evaluate AutoFT on nine natural distribution shifts which include domain shifts
and subpopulation shifts. Our experiments show that AutoFT significantly
improves generalization to new OOD data, outperforming existing robust
fine-tuning methods. Notably, AutoFT achieves new state-of-the-art performance
on the WILDS-iWildCam and WILDS-FMoW benchmarks, outperforming the previous
best methods by $6.0\%$ and $1.5\%$, respectively.
\\ ( https://arxiv.org/abs/2401.10220 ,  923kb)
------------------------------------------------------------------------------
\\
arXiv:2401.10227 (*cross-listing*)
Date: Thu, 18 Jan 2024 18:59:19 GMT   (12570kb,D)

Title: A Simple Latent Diffusion Approach for Panoptic Segmentation and Mask
  Inpainting
Authors: Wouter Van Gansbeke, Bert De Brabandere
Categories: cs.CV cs.LG
Comments: Code: https://github.com/segments-ai/latent-diffusion-segmentation
\\
  Panoptic and instance segmentation networks are often trained with
specialized object detection modules, complex loss functions, and ad-hoc
post-processing steps to handle the permutation-invariance of the instance
masks. This work builds upon Stable Diffusion and proposes a latent diffusion
approach for panoptic segmentation, resulting in a simple architecture which
omits these complexities. Our training process consists of two steps: (1)
training a shallow autoencoder to project the segmentation masks to latent
space; (2) training a diffusion model to allow image-conditioned sampling in
latent space. The use of a generative model unlocks the exploration of mask
completion or inpainting, which has applications in interactive segmentation.
The experimental validation yields promising results for both panoptic
segmentation and mask inpainting. While not setting a new state-of-the-art, our
model's simplicity, generality, and mask completion capability are desirable
properties.
\\ ( https://arxiv.org/abs/2401.10227 ,  12570kb)
%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%
------------------------------------------------------------------------------
\\
arXiv:2212.11854
replaced with revised version Thu, 18 Jan 2024 11:52:08 GMT   (310kb,D)

Title: Data-Centric Artificial Intelligence
Authors: Johannes Jakubik, Michael V\"ossing, Niklas K\"uhl, Jannis Walk,
  Gerhard Satzger
Categories: cs.AI
Comments: Accepted for publication at Business & Information Systems
  Engineering
\\ ( https://arxiv.org/abs/2212.11854 ,  310kb)
------------------------------------------------------------------------------
\\
arXiv:2304.04640
replaced with revised version Wed, 17 Jan 2024 20:40:28 GMT   (1346kb,D)

Title: NeuroBench: A Framework for Benchmarking Neuromorphic Computing
  Algorithms and Systems
Authors: Jason Yik, Korneel Van den Berghe, Douwe den Blanken, Younes
  Bouhadjar, Maxime Fabre, Paul Hueber, Denis Kleyko, Noah Pacik-Nelson,
  Pao-Sheng Vincent Sun, Guangzhi Tang, Shenqi Wang, Biyan Zhou, Soikat Hasan
  Ahmed, George Vathakkattil Joseph, Benedetto Leto, Aurora Micheli, Anurag
  Kumar Mishra, Gregor Lenz, Tao Sun, Zergham Ahmed, Mahmoud Akl, Brian
  Anderson, Andreas G. Andreou, Chiara Bartolozzi, Arindam Basu, Petrut Bogdan,
  Sander Bohte, Sonia Buckley, Gert Cauwenberghs, Elisabetta Chicca, Federico
  Corradi, Guido de Croon, Andreea Danielescu, Anurag Daram, Mike Davies, Yigit
  Demirag, Jason Eshraghian, Tobias Fischer, Jeremy Forest, Vittorio Fra, Steve
  Furber, P. Michael Furlong, William Gilpin, Aditya Gilra, Hector A. Gonzalez,
  Giacomo Indiveri, Siddharth Joshi, Vedant Karia, Lyes Khacef, et al. (49
  additional authors not shown)
Categories: cs.AI
Comments: Updated from whitepaper to full perspective article preprint
\\ ( https://arxiv.org/abs/2304.04640 ,  1346kb)
------------------------------------------------------------------------------
\\
arXiv:2305.12788
replaced with revised version Wed, 17 Jan 2024 18:12:47 GMT   (5912kb,D)

Title: GraphCare: Enhancing Healthcare Predictions with Personalized Knowledge
  Graphs
Authors: Pengcheng Jiang, Cao Xiao, Adam Cross, Jimeng Sun
Categories: cs.AI cs.LG
Comments: ICLR 2024
\\ ( https://arxiv.org/abs/2305.12788 ,  5912kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00323
replaced with revised version Thu, 18 Jan 2024 00:10:32 GMT   (887kb,D)

Title: Thought Cloning: Learning to Think while Acting by Imitating Human
  Thinking
Authors: Shengran Hu and Jeff Clune
Categories: cs.AI cs.LG
Comments: Accepted to NeurIPS 2023 as a spotlight
\\ ( https://arxiv.org/abs/2306.00323 ,  887kb)
------------------------------------------------------------------------------
\\
arXiv:2306.09138
replaced with revised version Thu, 18 Jan 2024 12:02:06 GMT   (86kb)

Title: Exploiting Uncertainty for Querying Inconsistent Description Logics
  Knowledge Bases
Authors: Riccardo Zese, Evelina Lamma, Fabrizio Riguzzi
Categories: cs.AI cs.LO
\\ ( https://arxiv.org/abs/2306.09138 ,  86kb)
------------------------------------------------------------------------------
\\
arXiv:2308.14284
replaced with revised version Wed, 17 Jan 2024 21:30:16 GMT   (9802kb,D)

Title: Prompt to Transfer: Sim-to-Real Transfer for Traffic Signal Control with
  Prompt Learning
Authors: Longchao Da, Minchiuan Gao, Hao Mei, Hua Wei
Categories: cs.AI
Comments: 9 pages, 7 figures. Accepted to AAAI 2024
ACM-class: H.4.0
\\ ( https://arxiv.org/abs/2308.14284 ,  9802kb)
------------------------------------------------------------------------------
\\
arXiv:2312.08722
replaced with revised version Thu, 18 Jan 2024 08:46:56 GMT   (4529kb,D)

Title: Quantifying Divergence for Human-AI Collaboration and Cognitive Trust
Authors: M\"uge Kural, Ali Gebe\c{s}\c{c}e, Tilek Chubakov, G\"ozde G\"ul
  \c{S}ahin
Categories: cs.AI
\\ ( https://arxiv.org/abs/2312.08722 ,  4529kb)
------------------------------------------------------------------------------
\\
arXiv:2312.14345
replaced with revised version Wed, 17 Jan 2024 22:05:50 GMT   (2202kb,D)

Title: Logic-Scaffolding: Personalized Aspect-Instructed Recommendation
  Explanation Generation using LLMs
Authors: Behnam Rahdari, Hao Ding, Ziwei Fan, Yifei Ma, Zhuotong Chen, Anoop
  Deoras and Branislav Kveton
Categories: cs.AI cs.CL cs.HC
Comments: The 17th ACM International Conference on Web Search and Data Mining
  (WSDM 2024)
DOI: 10.1145/3616855.3635689
\\ ( https://arxiv.org/abs/2312.14345 ,  2202kb)
------------------------------------------------------------------------------
\\
arXiv:2304.09048
replaced with revised version Thu, 18 Jan 2024 16:14:35 GMT   (1591kb,D)

Title: CodeKGC: Code Language Model for Generative Knowledge Graph Construction
Authors: Zhen Bi, Jing Chen, Yinuo Jiang, Feiyu Xiong, Wei Guo, Huajun Chen,
  Ningyu Zhang
Categories: cs.CL cs.AI cs.IR cs.LG cs.SE
Comments: ACM Transactions on Asian and Low-Resource Language Information
  Processing
\\ ( https://arxiv.org/abs/2304.09048 ,  1591kb)
------------------------------------------------------------------------------
\\
arXiv:2304.11065
replaced with revised version Thu, 18 Jan 2024 15:57:19 GMT   (580kb,D)

Title: Conversational Process Modeling: Can Generative AI Empower Domain
  Experts in Creating and Redesigning Process Models?
Authors: Nataliia Klievtsova, Janik-Vasily Benzin, Timotheus Kampik, Juergen
  Mangler, Stefanie Rinderle-Ma
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2304.11065 ,  580kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05535
replaced with revised version Wed, 17 Jan 2024 19:39:42 GMT   (97kb,D)

Title: Detecting Check-Worthy Claims in Political Debates, Speeches, and
  Interviews Using Audio Data
Authors: Petar Ivanov, Ivan Koychev, Momchil Hardalov, Preslav Nakov
Categories: cs.CL cs.AI cs.IR cs.LG cs.SD eess.AS
Comments: Check-Worthiness, Fact-Checking, Fake News, Misinformation,
  Disinformation, Political Debates, Multimodality
MSC-class: 68T50
ACM-class: F.2.2; I.2.7
Journal-ref: ICASSP 2024
\\ ( https://arxiv.org/abs/2306.05535 ,  97kb)
------------------------------------------------------------------------------
\\
arXiv:2306.09212
replaced with revised version Wed, 17 Jan 2024 19:09:57 GMT   (3151kb,D)

Title: CMMLU: Measuring massive multitask language understanding in Chinese
Authors: Haonan Li and Yixuan Zhang and Fajri Koto and Yifei Yang and Hai Zhao
  and Yeyun Gong and Nan Duan and Timothy Baldwin
Categories: cs.CL
\\ ( https://arxiv.org/abs/2306.09212 ,  3151kb)
------------------------------------------------------------------------------
\\
arXiv:2307.13269
replaced with revised version Thu, 18 Jan 2024 06:53:39 GMT   (343kb,D)

Title: LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA
  Composition
Authors: Chengsong Huang, Qian Liu, Bill Yuchen Lin, Tianyu Pang, Chao Du, Min
  Lin
Categories: cs.CL cs.AI
Comments: Add more related work and experimental results
\\ ( https://arxiv.org/abs/2307.13269 ,  343kb)
------------------------------------------------------------------------------
\\
arXiv:2308.08090
replaced with revised version Thu, 18 Jan 2024 07:23:49 GMT   (582kb,D)

Title: Separate the Wheat from the Chaff: Model Deficiency Unlearning via
  Parameter-Efficient Module Operation
Authors: Xinshuo Hu, Dongfang Li, Baotian Hu, Zihao Zheng, Zhenyu Liu, Min
  Zhang
Categories: cs.CL
Comments: AAAI 2024; The first two authors contributed equally to this paper
\\ ( https://arxiv.org/abs/2308.08090 ,  582kb)
------------------------------------------------------------------------------
\\
arXiv:2309.07382
replaced with revised version Thu, 18 Jan 2024 18:23:37 GMT   (317kb,D)

Title: Less is More for Long Document Summary Evaluation by LLMs
Authors: Yunshu Wu, Hayate Iso, Pouya Pezeshkpour, Nikita Bhutani, Estevam
  Hruschka
Categories: cs.CL
Comments: EACL (main)
\\ ( https://arxiv.org/abs/2309.07382 ,  317kb)
------------------------------------------------------------------------------
\\
arXiv:2310.08483
replaced with revised version Thu, 18 Jan 2024 11:43:52 GMT   (1700kb,D)

Title: Understanding the Humans Behind Online Misinformation: An Observational
  Study Through the Lens of the COVID-19 Pandemic
Authors: Mohit Chandra, Anush Mattapalli, Munmun De Choudhury
Categories: cs.CL cs.SI
\\ ( https://arxiv.org/abs/2310.08483 ,  1700kb)
------------------------------------------------------------------------------
\\
arXiv:2310.08744
replaced with revised version Wed, 17 Jan 2024 23:03:05 GMT   (38170kb,D)

Title: Circuit Component Reuse Across Tasks in Transformer Language Models
Authors: Jack Merullo, Carsten Eickhoff, Ellie Pavlick
Categories: cs.CL cs.LG
Comments: Accepted at ICLR 2024
\\ ( https://arxiv.org/abs/2310.08744 ,  38170kb)
------------------------------------------------------------------------------
\\
arXiv:2310.12086
replaced with revised version Thu, 18 Jan 2024 16:20:06 GMT   (4532kb,D)

Title: FactCHD: Benchmarking Fact-Conflicting Hallucination Detection
Authors: Xiang Chen, Duanzheng Song, Honghao Gui, Chenxi Wang, Ningyu Zhang,
  Jiang Yong, Fei Huang, Chengfei Lv, Dan Zhang, Huajun Chen
Categories: cs.CL cs.AI cs.CV cs.IR cs.LG
Comments: Work in progress
\\ ( https://arxiv.org/abs/2310.12086 ,  4532kb)
------------------------------------------------------------------------------
\\
arXiv:2310.12798
replaced with revised version Thu, 18 Jan 2024 09:03:24 GMT   (971kb,D)

Title: MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and
  Uni-Modal Adapter
Authors: Zhiyuan Liu, Sihang Li, Yanchen Luo, Hao Fei, Yixin Cao, Kenji
  Kawaguchi, Xiang Wang, Tat-Seng Chua
Categories: cs.CL cs.MM
Comments: EMNLP main conference. 9 pages
\\ ( https://arxiv.org/abs/2310.12798 ,  971kb)
------------------------------------------------------------------------------
\\
arXiv:2310.18913
replaced with revised version Thu, 18 Jan 2024 14:23:07 GMT   (2662kb,D)

Title: Debiasing Algorithm through Model Adaptation
Authors: Tomasz Limisiewicz and David Mare\v{c}ek and Tom\'a\v{s} Musil
Categories: cs.CL cs.AI stat.ML
Comments: Accepted to ICLR 2024
\\ ( https://arxiv.org/abs/2310.18913 ,  2662kb)
------------------------------------------------------------------------------
\\
arXiv:2312.03122
replaced with revised version Thu, 18 Jan 2024 16:53:15 GMT   (1674kb)

Title: Assertion Enhanced Few-Shot Learning: Instructive Technique for Large
  Language Models to Generate Educational Explanations
Authors: Tasmia Shahriar, Noboru Matsuda and Kelly Ramos
Categories: cs.CL
\\ ( https://arxiv.org/abs/2312.03122 ,  1674kb)
------------------------------------------------------------------------------
\\
arXiv:2312.16171
replaced with revised version Thu, 18 Jan 2024 18:41:09 GMT   (1183kb,D)

Title: Principled Instructions Are All You Need for Questioning LLaMA-1/2,
  GPT-3.5/4
Authors: Sondos Mahmoud Bsharat and Aidar Myrzakhan and Zhiqiang Shen
Categories: cs.CL cs.AI
Comments: Github at: https://github.com/VILA-Lab/ATLAS
\\ ( https://arxiv.org/abs/2312.16171 ,  1183kb)
------------------------------------------------------------------------------
\\
arXiv:2312.17484
replaced with revised version Sun, 14 Jan 2024 07:55:12 GMT   (10780kb,D)

Title: Truth Forest: Toward Multi-Scale Truthfulness in Large Language Models
  through Intervention without Tuning
Authors: Zhongzhi Chen, Xingwu Sun, Xianfeng Jiao, Fengzong Lian, Zhanhui Kang,
  Di Wang, Cheng-Zhong Xu
Categories: cs.CL cs.AI
Comments: Accepted as AAAI 2024
\\ ( https://arxiv.org/abs/2312.17484 ,  10780kb)
------------------------------------------------------------------------------
\\
arXiv:2401.06805
replaced with revised version Thu, 18 Jan 2024 07:31:47 GMT   (2460kb,D)

Title: Exploring the Reasoning Abilities of Multimodal Large Language Models
  (MLLMs): A Comprehensive Survey on Emerging Trends in Multimodal Reasoning
Authors: Yiqi Wang, Wentao Chen, Xiaotian Han, Xudong Lin, Haiteng Zhao,
  Yongfei Liu, Bohan Zhai, Jianbo Yuan, Quanzeng You, Hongxia Yang
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2401.06805 ,  2460kb)
------------------------------------------------------------------------------
\\
arXiv:2401.06951
replaced with revised version Thu, 18 Jan 2024 02:18:43 GMT   (4255kb,D)

Title: E^2-LLM: Efficient and Extreme Length Extension of Large Language Models
Authors: Jiaheng Liu, Zhiqi Bai, Yuanxing Zhang, Chenchen Zhang, Yu Zhang, Ge
  Zhang, Jiakai Wang, Haoran Que, Yukang Chen, Wenbo Su, Tiezheng Ge, Jie Fu,
  Wenhu Chen, Bo Zheng
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2401.06951 ,  4255kb)
------------------------------------------------------------------------------
\\
arXiv:2401.07284
replaced with revised version Thu, 18 Jan 2024 11:29:37 GMT   (734kb,D)

Title: Improving Domain Adaptation through Extended-Text Reading Comprehension
Authors: Ting Jiang, Shaohan Huang, Shengyue Luo, Zihan Zhang, Haizhen Huang,
  Furu Wei, Weiwei Deng, Feng Sun, Qi Zhang, Deqing Wang, Fuzhen Zhuang
Categories: cs.CL
Comments: Work in Progress
\\ ( https://arxiv.org/abs/2401.07284 ,  734kb)
------------------------------------------------------------------------------
\\
arXiv:2401.07510
replaced with revised version Thu, 18 Jan 2024 07:47:00 GMT   (0kb,I)

Title: Developing ChatGPT for Biology and Medicine: A Complete Review of
  Biomedical Question Answering
Authors: Qing Li, Lei Li, Yu Li
Categories: cs.CL cs.AI
Comments: There are some mistakes in introducing medical language question
  answering Models and medical multimodal question answering models, such as
  their dataset should be displayed for pretraining
MSC-class: cs.CL
ACM-class: I.2.1
\\ ( https://arxiv.org/abs/2401.07510 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2401.07525
replaced with revised version Wed, 17 Jan 2024 23:06:15 GMT   (328kb,D)

Title: TAROT: A Hierarchical Framework with Multitask Co-Pretraining on
  Semi-Structured Data towards Effective Person-Job Fit
Authors: Yihan Cao, Xu Chen, Lun Du, Hao Chen, Qiang Fu, Shi Han, Yushu Du,
  Yanbin Kang, Guangming Lu, Zi Li
Categories: cs.CL cs.AI
Comments: ICASSP 2024 camera ready. 5 pages, 1 figure, 3 tables
\\ ( https://arxiv.org/abs/2401.07525 ,  328kb)
------------------------------------------------------------------------------
\\
arXiv:2401.07927
replaced with revised version Wed, 17 Jan 2024 20:14:05 GMT   (183kb,D)

Title: Are self-explanations from Large Language Models faithful?
Authors: Andreas Madsen, Sarath Chandar, Siva Reddy
Categories: cs.CL cs.AI cs.LG
\\ ( https://arxiv.org/abs/2401.07927 ,  183kb)
------------------------------------------------------------------------------
\\
arXiv:2401.08406
replaced with revised version Wed, 17 Jan 2024 20:03:15 GMT   (1300kb,D)

Title: RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on
  Agriculture
Authors: Angels Balaguer, Vinamra Benara, Renato Luiz de Freitas Cunha, Roberto
  de M. Estev\~ao Filho, Todd Hendry, Daniel Holstein, Jennifer Marsman, Nick
  Mecklenburg, Sara Malvar, Leonardo O. Nunes, Rafael Padilha, Morris Sharp,
  Bruno Silva, Swati Sharma, Vijay Aski, Ranveer Chandra
Categories: cs.CL cs.LG
\\ ( https://arxiv.org/abs/2401.08406 ,  1300kb)
------------------------------------------------------------------------------
\\
arXiv:2401.08417
replaced with revised version Thu, 18 Jan 2024 09:31:28 GMT   (180kb,D)

Title: Contrastive Preference Optimization: Pushing the Boundaries of LLM
  Performance in Machine Translation
Authors: Haoran Xu, Amr Sharaf, Yunmo Chen, Weiting Tan, Lingfeng Shen,
  Benjamin Van Durme, Kenton Murray, Young Jin Kim
Categories: cs.CL
\\ ( https://arxiv.org/abs/2401.08417 ,  180kb)
------------------------------------------------------------------------------
\\
arXiv:2112.08440
replaced with revised version Wed, 17 Jan 2024 22:41:32 GMT   (14274kb,D)

Title: Climate-Invariant Machine Learning
Authors: Tom Beucler, Pierre Gentine, Janni Yuval, Ankitesh Gupta, Liran Peng,
  Jerry Lin, Sungduk Yu, Stephan Rasp, Fiaz Ahmed, Paul A. O'Gorman, J. David
  Neelin, Nicholas J. Lutsko, Michael Pritchard
Categories: cs.LG physics.ao-ph physics.comp-ph
Comments: 26+28 pages, 9+15 figures, 0+3 tables in the main text +
  supplementary materials. Accepted for publication in Science Advances on Jan
  5, 2024
\\ ( https://arxiv.org/abs/2112.08440 ,  14274kb)
------------------------------------------------------------------------------
\\
arXiv:2208.13125
replaced with revised version Wed, 17 Jan 2024 22:55:00 GMT   (4912kb,D)

Title: Normality-Guided Distributional Reinforcement Learning for Continuous
  Control
Authors: Ju-Seung Byun, Andrew Perrault
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2208.13125 ,  4912kb)
------------------------------------------------------------------------------
\\
arXiv:2210.15629
replaced with revised version Thu, 18 Jan 2024 00:43:41 GMT   (3690kb,D)

Title: Language Control Diffusion: Efficiently Scaling through Space, Time, and
  Tasks
Authors: Edwin Zhang, Yujie Lu, William Wang, Amy Zhang
Categories: cs.LG cs.AI cs.CL
Comments: ICLR 2024, Project and code available at
  https://github.com/ezhang7423/language-control-diffusion
\\ ( https://arxiv.org/abs/2210.15629 ,  3690kb)
------------------------------------------------------------------------------
\\
arXiv:2212.14630
replaced with revised version Thu, 18 Jan 2024 12:31:30 GMT   (3277kb,D)

Title: Detecting Change Intervals with Isolation Distributional Kernel
Authors: Yang Cao, Ye Zhu, Kai Ming Ting, Flora D. Salim, Hong Xian Li, Luxing
  Yang, Gang Li
Categories: cs.LG
\\ ( https://arxiv.org/abs/2212.14630 ,  3277kb)
------------------------------------------------------------------------------
\\
arXiv:2302.00695
replaced with revised version Thu, 18 Jan 2024 07:39:29 GMT   (2963kb,D)

Title: Versatile Energy-Based Probabilistic Models for High Energy Physics
Authors: Taoli Cheng, Aaron Courville
Categories: cs.LG hep-ex hep-ph stat.ML
Comments: 17 pages, 9 figures. NeurIPS 2023 camera ready
\\ ( https://arxiv.org/abs/2302.00695 ,  2963kb)
------------------------------------------------------------------------------
\\
arXiv:2303.02472
replaced with revised version Thu, 18 Jan 2024 07:27:09 GMT   (1216kb,D)

Title: ESD: Expected Squared Difference as a Tuning-Free Trainable Calibration
  Measure
Authors: Hee Suk Yoon, Joshua Tian Jin Tee, Eunseop Yoon, Sunjae Yoon, Gwangsu
  Kim, Yingzhen Li, Chang D. Yoo
Categories: cs.LG cs.AI cs.CL cs.CV
Comments: ICLR 2023
\\ ( https://arxiv.org/abs/2303.02472 ,  1216kb)
------------------------------------------------------------------------------
\\
arXiv:2303.09906
replaced with revised version Thu, 18 Jan 2024 05:42:20 GMT   (922kb,D)

Title: Discovering mesoscopic descriptions of collective movement with neural
  stochastic modelling
Authors: Utkarsh Pratiush, Arshed Nabeel, Vishwesha Guttal, Prathosh AP
Categories: cs.LG physics.soc-ph q-bio.QM
Comments: (v2) Minor corrections and clarifications. Added funding sources
\\ ( https://arxiv.org/abs/2303.09906 ,  922kb)
------------------------------------------------------------------------------
\\
arXiv:2304.01300
replaced with revised version Thu, 18 Jan 2024 14:33:34 GMT   (4163kb)

Title: On Mitigating the Utility-Loss in Differentially Private Learning: A new
  Perspective by a Geometrically Inspired Kernel Approach
Authors: Mohit Kumar, Bernhard A. Moser, Lukas Fischer
Categories: cs.LG cs.AI cs.CR
\\ ( https://arxiv.org/abs/2304.01300 ,  4163kb)
------------------------------------------------------------------------------
\\
arXiv:2304.05527
replaced with revised version Wed, 17 Jan 2024 20:16:04 GMT   (2301kb,D)

Title: Black Box Variational Inference with a Deterministic Objective: Faster,
  More Accurate, and Even More Black Box
Authors: Ryan Giordano, Martin Ingram, Tamara Broderick
Categories: cs.LG stat.ME stat.ML
\\ ( https://arxiv.org/abs/2304.05527 ,  2301kb)
------------------------------------------------------------------------------
\\
arXiv:2305.02749
replaced with revised version Thu, 18 Jan 2024 09:57:32 GMT   (991kb,D)

Title: Explainable Reinforcement Learning via a Causal World Model
Authors: Zhongwei Yu, Jingqing Ruan, Dengpeng Xing
Categories: cs.LG
Comments: Accepted by IJCAI 2023
\\ ( https://arxiv.org/abs/2305.02749 ,  991kb)
------------------------------------------------------------------------------
\\
arXiv:2305.04099
replaced with revised version Wed, 17 Jan 2024 23:18:50 GMT   (7545kb,D)

Title: Symbolic Regression on FPGAs for Fast Machine Learning Inference
Authors: Ho Fung Tsoi, Adrian Alan Pol, Vladimir Loncar, Ekaterina Govorkova,
  Miles Cranmer, Sridhara Dasu, Peter Elmer, Philip Harris, Isobel Ojalvo,
  Maurizio Pierini
Categories: cs.LG hep-ex physics.ins-det
Comments: 9 pages. Accepted to 26th International Conference on Computing in
  High Energy & Nuclear Physics (CHEP 2023)
\\ ( https://arxiv.org/abs/2305.04099 ,  7545kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17198
replaced with revised version Thu, 18 Jan 2024 16:25:38 GMT   (5478kb,D)

Title: A Model-Based Solution to the Offline Multi-Agent Reinforcement Learning
  Coordination Problem
Authors: Paul Barde, Jakob Foerster, Derek Nowrouzezahrai, Amy Zhang
Categories: cs.LG cs.AI cs.MA
\\ ( https://arxiv.org/abs/2305.17198 ,  5478kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18417
replaced with revised version Thu, 18 Jan 2024 15:50:01 GMT   (16516kb,D)

Title: Determinantal Point Process Attention Over Grid Cell Code Supports Out
  of Distribution Generalization
Authors: Shanka Subhra Mondal, Steven Frankland, Taylor Webb, and Jonathan D.
  Cohen
Categories: cs.LG q-bio.NC
Comments: 29 pages (including Appendix), 21 figures
\\ ( https://arxiv.org/abs/2305.18417 ,  16516kb)
------------------------------------------------------------------------------
\\
arXiv:2305.19838
replaced with revised version Thu, 18 Jan 2024 13:26:17 GMT   (4392kb,D)

Title: Relaxing the Additivity Constraints in Decentralized No-Regret
  High-Dimensional Bayesian Optimization
Authors: Anthony Bardou, Patrick Thiran and Thomas Begin
Categories: cs.LG
\\ ( https://arxiv.org/abs/2305.19838 ,  4392kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00788
replaced with revised version Thu, 18 Jan 2024 16:00:30 GMT   (145kb,D)

Title: Understanding Augmentation-based Self-Supervised Representation Learning
  via RKHS Approximation and Regression
Authors: Runtian Zhai, Bingbin Liu, Andrej Risteski, Zico Kolter, Pradeep
  Ravikumar
Categories: cs.LG stat.ML
Comments: ICLR 2024 spotlight. 34 pages
\\ ( https://arxiv.org/abs/2306.00788 ,  145kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04961
replaced with revised version Thu, 18 Jan 2024 16:47:33 GMT   (205kb,D)

Title: Recovering Simultaneously Structured Data via Non-Convex Iteratively
  Reweighted Least Squares
Authors: Christian K\"ummerle and Johannes Maly
Categories: cs.LG cs.IT math.IT math.OC
Comments: 35 pages, 7 figures
\\ ( https://arxiv.org/abs/2306.04961 ,  205kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05109
replaced with revised version Thu, 18 Jan 2024 10:41:37 GMT   (2476kb,D)

Title: Yet Another ICU Benchmark: A Flexible Multi-Center Framework for
  Clinical ML
Authors: Robin van de Water, Hendrik Schmidt, Paul Elbers, Patrick Thoral, Bert
  Arnrich, Patrick Rockenschaub
Categories: cs.LG
Comments: Main benchmark: https://github.com/rvandewater/YAIB, Cohort
  generation: https://github.com/rvandewater/YAIB-cohorts, Models:
  https://github.com/rvandewater/YAIB-models
\\ ( https://arxiv.org/abs/2306.05109 ,  2476kb)
------------------------------------------------------------------------------
\\
arXiv:2307.13275
replaced with revised version Thu, 18 Jan 2024 15:14:42 GMT   (6252kb,D)

Title: CTAGE: Curvature-Based Topology-Aware Graph Embedding for Learning
  Molecular Representations
Authors: Yili Chen, Zhengyu Li, Zheng Wan, Hui Yu, Xian Wei
Categories: cs.LG cs.AI q-bio.QM
\\ ( https://arxiv.org/abs/2307.13275 ,  6252kb)
------------------------------------------------------------------------------
\\
arXiv:2308.05021
replaced with revised version Thu, 18 Jan 2024 18:18:59 GMT   (128kb,D)

Title: On Error Propagation of Diffusion Models
Authors: Yangming Li, Mihaela van der Schaar
Categories: cs.LG cs.CV
Comments: Accepted by ICLR-2024
\\ ( https://arxiv.org/abs/2308.05021 ,  128kb)
------------------------------------------------------------------------------
\\
arXiv:2308.08469
replaced with revised version Thu, 18 Jan 2024 06:01:28 GMT   (2286kb,D)

Title: LLM4TS: Aligning Pre-Trained LLMs as Data-Efficient Time-Series
  Forecasters
Authors: Ching Chang, Wei-Yao Wang, Wen-Chih Peng, Tien-Fu Chen
Categories: cs.LG
Comments: This paper is currently under review. The code will be made available
  upon acceptance
\\ ( https://arxiv.org/abs/2308.08469 ,  2286kb)
------------------------------------------------------------------------------
\\
arXiv:2309.12971
replaced with revised version Thu, 18 Jan 2024 06:57:18 GMT   (580kb,D)

Title: Higher-order Graph Convolutional Network with Flower-Petals Laplacians
  on Simplicial Complexes
Authors: Yiming Huang, Yujie Zeng, Qiang Wu, Linyuan L\"u
Categories: cs.LG cond-mat.stat-mech cs.AI cs.SI physics.soc-ph
\\ ( https://arxiv.org/abs/2309.12971 ,  580kb)
------------------------------------------------------------------------------
\\
arXiv:2309.14068
replaced with revised version Thu, 18 Jan 2024 18:16:33 GMT   (3829kb,D)

Title: Soft Mixture Denoising: Beyond the Expressive Bottleneck of Diffusion
  Models
Authors: Yangming Li, Boris van Breugel, Mihaela van der Schaar
Categories: cs.LG cs.CV
Comments: Accepted by ICLR-2024
\\ ( https://arxiv.org/abs/2309.14068 ,  3829kb)
------------------------------------------------------------------------------
\\
arXiv:2309.15188
replaced with revised version Thu, 18 Jan 2024 17:21:42 GMT   (448kb,D)

Title: ICML 2023 Topological Deep Learning Challenge : Design and Results
Authors: Mathilde Papillon, Mustafa Hajij, Helen Jenne, Johan Mathe, Audun
  Myers, Theodore Papamarkou, Tolga Birdal, Tamal Dey, Tim Doster, Tegan
  Emerson, Gurusankar Gopalakrishnan, Devendra Govil, Aldo Guzm\'an-S\'aenz,
  Henry Kvinge, Neal Livesay, Soham Mukherjee, Shreyas N. Samaga, Karthikeyan
  Natesan Ramamurthy, Maneel Reddy Karri, Paul Rosen, Sophia Sanborn, Robin
  Walters, Jens Agerberg, Sadrodin Barikbin, Claudio Battiloro, Gleb Bazhenov,
  Guillermo Bernardez, Aiden Brent, Sergio Escalera, Simone Fiorellino, Dmitrii
  Gavrilev, Mohammed Hassanin, Paul H\"ausner, Odin Hoff Gardaa, Abdelwahed
  Khamis, Manuel Lecha, German Magai, Tatiana Malygina, Rub\'en Ballester,
  Kalyan Nadimpalli, Alexander Nikitin, Abraham Rabinowitz, Alessandro
  Salatiello, Simone Scardapane, Luca Scofano, Suraj Singh, Jens Sj\"olund,
  Pavel Snopov, Indro Spinelli, Lev Telyatnikov, Lucia Testa, Maosheng Yang,
  Yixiao Yue, Olga Zaghen, Ali Zia, Nina Miolane
Categories: cs.LG
DOI: 10.5281/zenodo.7958513
\\ ( https://arxiv.org/abs/2309.15188 ,  448kb)
------------------------------------------------------------------------------
\\
arXiv:2309.16467
replaced with revised version Thu, 18 Jan 2024 18:25:38 GMT   (6324kb,D)

Title: Compositional Program Generation for Few-Shot Systematic Generalization
Authors: Tim Klinger and Luke Liu and Soham Dan and Maxwell Crouse and
  Parikshit Ram and Alexander Gray
Categories: cs.LG
Comments: 7 pages of text with 1 page of references
\\ ( https://arxiv.org/abs/2309.16467 ,  6324kb)
------------------------------------------------------------------------------
\\
arXiv:2310.15141
replaced with revised version Thu, 18 Jan 2024 04:42:34 GMT   (226kb,D)

Title: SpecTr: Fast Speculative Decoding via Optimal Transport
Authors: Ziteng Sun and Ananda Theertha Suresh and Jae Hun Ro and Ahmad Beirami
  and Himanshu Jain and Felix Yu
Categories: cs.LG cs.CL cs.DS cs.IT math.IT
Comments: NeurIPS 2023
\\ ( https://arxiv.org/abs/2310.15141 ,  226kb)
------------------------------------------------------------------------------
\\
arXiv:2310.20496
replaced with revised version Thu, 18 Jan 2024 16:51:21 GMT   (3319kb,D)

Title: BasisFormer: Attention-based Time Series Forecasting with Learnable and
  Interpretable Basis
Authors: Zelin Ni and Hang Yu and Shizhan Liu and Jianguo Li and Weiyao Lin
Categories: cs.LG
Comments: NeurIPS 2023(poster)
\\ ( https://arxiv.org/abs/2310.20496 ,  3319kb)
------------------------------------------------------------------------------
\\
arXiv:2310.20708
replaced with revised version Thu, 18 Jan 2024 09:30:45 GMT   (2866kb,D)

Title: Unexpected Improvements to Expected Improvement for Bayesian
  Optimization
Authors: Sebastian Ament, Samuel Daulton, David Eriksson, Maximilian Balandat,
  Eytan Bakshy
Categories: cs.LG cs.NA math.NA stat.ML
Comments: NeurIPS 2023 Spotlight
\\ ( https://arxiv.org/abs/2310.20708 ,  2866kb)
------------------------------------------------------------------------------
\\
arXiv:2311.00964
replaced with revised version Thu, 18 Jan 2024 04:11:57 GMT   (117kb,D)

Title: On Finding Bi-objective Pareto-optimal Fraud Prevention Rule Sets for
  Fintech Applications
Authors: Chengyao Wen, Yin Lou
Categories: cs.LG q-fin.ST
\\ ( https://arxiv.org/abs/2311.00964 ,  117kb)
------------------------------------------------------------------------------
\\
arXiv:2311.05081
replaced with revised version Wed, 17 Jan 2024 23:21:31 GMT   (6258kb,D)

Title: Generalized test utilities for long-tail performance in extreme
  multi-label classification
Authors: Erik Schultheis, Marek Wydmuch, Wojciech Kot{\l}owski, Rohit Babbar,
  Krzysztof Dembczy\'nski
Categories: cs.LG
Comments: This is the authors' version of the work accepted to NeurIPS 2023;
  the final version of the paper, errors and typos corrected, and minor
  modifications to improve clarity
\\ ( https://arxiv.org/abs/2311.05081 ,  6258kb)
------------------------------------------------------------------------------
\\
arXiv:2311.07202
replaced with revised version Thu, 18 Jan 2024 04:23:26 GMT   (139kb,D)

Title: Input Convex LSTM: A Convex Approach for Fast Lyapunov-Based Model
  Predictive Control
Authors: Zihao Wang, Zhe Wu
Categories: cs.LG cs.CE cs.SY eess.SY
Comments: Submitted to 6th Annual Learning for Dynamics & Control Conference
  (L4DC 2024)
\\ ( https://arxiv.org/abs/2311.07202 ,  139kb)
------------------------------------------------------------------------------
\\
arXiv:2311.13184
replaced with revised version Thu, 18 Jan 2024 14:32:15 GMT   (354kb,D)

Title: Large Language Model-Enhanced Algorithm Selection: Towards Comprehensive
  Algorithm Representation
Authors: Xingyu Wu, Yan Zhong, Jibin Wu, Bingbing Jiang, Kay Chen Tan
Categories: cs.LG cs.CL
\\ ( https://arxiv.org/abs/2311.13184 ,  354kb)
------------------------------------------------------------------------------
\\
arXiv:2311.13594
replaced with revised version Thu, 18 Jan 2024 15:39:09 GMT   (3658kb,D)

Title: Labeling Neural Representations with Inverse Recognition
Authors: Kirill Bykov, Laura Kopf, Shinichi Nakajima, Marius Kloft, Marina
  M.-C. H\"ohne
Categories: cs.LG cs.AI stat.ML
Comments: 25 pages, 16 figures
Journal-ref: 37th Conference on Neural Information Processing Systems (NeurIPS
  2023)
\\ ( https://arxiv.org/abs/2311.13594 ,  3658kb)
------------------------------------------------------------------------------
\\
arXiv:2312.04273
replaced with revised version Thu, 18 Jan 2024 01:52:47 GMT   (120kb,D)

Title: Invariant Random Forest: Tree-Based Model Solution for OOD
  Generalization
Authors: Yufan Liao, Qi Wu, Xing Yan
Categories: cs.LG
Comments: AAAI Conference on Artificial Intelligence, 2024 (Oral Presentation)
\\ ( https://arxiv.org/abs/2312.04273 ,  120kb)
------------------------------------------------------------------------------
\\
arXiv:2312.06305
replaced with revised version Thu, 18 Jan 2024 10:26:13 GMT   (89kb,D)

Title: A Meta-Level Learning Algorithm for Sequential Hyper-Parameter Space
  Reduction in AutoML
Authors: Giorgos Borboudakis, Paulos Charonyktakis, Konstantinos Paraschakis,
  Ioannis Tsamardinos
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2312.06305 ,  89kb)
------------------------------------------------------------------------------
\\
arXiv:2312.11034
replaced with revised version Thu, 18 Jan 2024 05:20:27 GMT   (2065kb,D)

Title: Partial Label Learning with a Partner
Authors: Chongjie Si, Zekun Jiang, Xuehui Wang, Yan Wang, Xiaokang Yang, Wei
  Shen
Categories: cs.LG
Comments: 2024, AAAI oral
\\ ( https://arxiv.org/abs/2312.11034 ,  2065kb)
------------------------------------------------------------------------------
\\
arXiv:2312.12469
replaced with revised version Thu, 18 Jan 2024 03:28:25 GMT   (5341kb,D)

Title: Distilling Autoregressive Models to Obtain High-Performance
  Non-Autoregressive Solvers for Vehicle Routing Problems with Faster Inference
  Speed
Authors: Yubin Xiao, Di Wang, Boyang Li, Mingzhao Wang, Xuan Wu, Changliang
  Zhou, You Zhou
Categories: cs.LG cs.AI
Comments: 11 pages, 5 figures, accepted by AAAI24
\\ ( https://arxiv.org/abs/2312.12469 ,  5341kb)
------------------------------------------------------------------------------
\\
arXiv:2312.12838
replaced with revised version Thu, 18 Jan 2024 15:27:37 GMT   (3777kb,D)

Title: FedA3I: Annotation Quality-Aware Aggregation for Federated Medical Image
  Segmentation against Heterogeneous Annotation Noise
Authors: Nannan Wu, Zhaobin Sun, Zengqiang Yan, Li Yu
Categories: cs.LG cs.CV
Comments: Accepted at AAAI'24
\\ ( https://arxiv.org/abs/2312.12838 ,  3777kb)
------------------------------------------------------------------------------
\\
arXiv:2401.02860
replaced with revised version Thu, 18 Jan 2024 04:05:05 GMT   (2120kb,D)

Title: Framework for Variable-lag Motif Following Relation Inference In Time
  Series using Matrix Profile analysis
Authors: Naaek Chinpattanakarn and Chainarong Amornbunchornvej
Categories: cs.LG cs.AI
Comments: Revising based on an expert's comments in the research community
MSC-class: 91-08, 68T09
ACM-class: G.3; I.2.6; J.4
\\ ( https://arxiv.org/abs/2401.02860 ,  2120kb)
------------------------------------------------------------------------------
\\
arXiv:2401.07231
replaced with revised version Thu, 18 Jan 2024 02:04:04 GMT   (220kb,D)

Title: Use of Prior Knowledge to Discover Causal Additive Models with
  Unobserved Variables and its Application to Time Series Data
Authors: Takashi Nicholas Maeda, Shohei Shimizu
Categories: cs.LG stat.ME stat.ML
\\ ( https://arxiv.org/abs/2401.07231 ,  220kb)
------------------------------------------------------------------------------
\\
arXiv:2401.08727
replaced with revised version Thu, 18 Jan 2024 05:25:22 GMT   (427kb,D)

Title: MA2GCN: Multi Adjacency relationship Attention Graph Convolutional
  Networks for Traffic Prediction using Trajectory data
Authors: Zhengke Sun, Yuliang Ma
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2401.08727 ,  427kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09180
replaced with revised version Thu, 18 Jan 2024 09:51:46 GMT   (949kb,D)

Title: Unsupervised Multiple Domain Translation through Controlled
  Disentanglement in Variational Autoencoder
Authors: Antonio Almud\'evar and Th\'eo Mariotte and Alfonso Ortega and Marie
  Tahon
Categories: cs.LG cs.CV
\\ ( https://arxiv.org/abs/2401.09180 ,  949kb)
------------------------------------------------------------------------------
\\
arXiv:2401.09192
replaced with revised version Thu, 18 Jan 2024 01:41:29 GMT   (1088kb,D)

Title: Preparing Lessons for Progressive Training on Language Models
Authors: Yu Pan, Ye Yuan, Yichun Yin, Jiaxin Shi, Zenglin Xu, Ming Zhang,
  Lifeng Shang, Xin Jiang, Qun Liu
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2401.09192 ,  1088kb)
------------------------------------------------------------------------------
\\
arXiv:2112.12508
replaced with revised version Thu, 18 Jan 2024 16:53:35 GMT   (257kb,D)

Title: From Procedures, Objects, Actors, Components, Services, to Agents -- A
  Comparative Analysis of the History and Evolution of Programming Abstractions
Authors: Jean-Pierre Briot
Categories: cs.SE cs.AI cs.PL
Comments: This preprint has been published as a chapter of a book about the
  French school of programming, coordinated by Bertrand Meyer and published by
  Springer in 2024
MSC-class: 97P40
ACM-class: D.3
\\ ( https://arxiv.org/abs/2112.12508 ,  257kb)
------------------------------------------------------------------------------
\\
arXiv:2211.11086
replaced with revised version Thu, 18 Jan 2024 14:40:43 GMT   (0kb,I)

Title: An Embarrassingly Simple Baseline for Imbalanced Semi-Supervised
  Learning
Authors: Hao Chen, Yue Fan, Yidong Wang, Jindong Wang, Bernt Schiele, Xing Xie,
  Marios Savvides, Bhiksha Raj
Categories: cs.CV cs.AI cs.LG
Comments: Issues in the paper, will re-open later
\\ ( https://arxiv.org/abs/2211.11086 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2211.13118
replaced with revised version Thu, 18 Jan 2024 10:28:53 GMT   (809kb,D)

Title: Decision Diagram-Based Branch-and-Bound with Caching for Dominance and
  Suboptimality Detection
Authors: Vianney Copp\'e, Xavier Gillard, Pierre Schaus
Categories: cs.DS cs.AI cs.DM math.OC
Comments: Accepted to INFORMS Journal on Computing
MSC-class: 90C39, 90C27, 90C57
ACM-class: I.2.8; G.2.1
DOI: 10.1287/ijoc.2022.0340
\\ ( https://arxiv.org/abs/2211.13118 ,  809kb)
------------------------------------------------------------------------------
\\
arXiv:2303.12307
replaced with revised version Thu, 18 Jan 2024 14:15:19 GMT   (8208kb,D)

Title: Curvature-Balanced Feature Manifold Learning for Long-Tailed
  Classification
Authors: Yanbiao Ma, Licheng Jiao, Fang Liu, Shuyuan Yang, Xu Liu and Lingling
  Li
Categories: cs.CV cs.AI
Comments: 20pages, Accepted by CVPR 2023
\\ ( https://arxiv.org/abs/2303.12307 ,  8208kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03354
replaced with revised version Wed, 17 Jan 2024 23:39:36 GMT   (1474kb,D)

Title: Simulation-Based Counterfactual Causal Discovery on Real World Driver
  Behaviour
Authors: Rhys Howard, Lars Kunze
Categories: cs.RO cs.AI
Comments: 8 Pages, 4 Figures, Published in the Proceedings of the 2023 IEEE
  Intelligent Vehicles Symposium, Final submission version corrected to include
  copyright notice and funding attribution on the first page (rather than the
  last page)
ACM-class: I.2.9; I.2.6; I.6.0
\\ ( https://arxiv.org/abs/2306.03354 ,  1474kb)
------------------------------------------------------------------------------
\\
arXiv:2307.02140
replaced with revised version Thu, 18 Jan 2024 07:57:06 GMT   (600kb,D)

Title: Towards Open Federated Learning Platforms: Survey and Vision from
  Technical and Legal Perspectives
Authors: Moming Duan
Categories: cs.SE cs.AI cs.LG
Comments: This is an ongoing work. See the latest version on
  https://github.com/morningD/Model-Centric-FML
\\ ( https://arxiv.org/abs/2307.02140 ,  600kb)
------------------------------------------------------------------------------
\\
arXiv:2307.12547
replaced with revised version Thu, 18 Jan 2024 05:42:41 GMT   (388kb,D)

Title: Knapsack: Connectedness, Path, and Shortest-Path
Authors: Palash Dey, Sudeshna Kolay, and Sipra Singh
Categories: cs.DS cs.AI
Comments: Under review
\\ ( https://arxiv.org/abs/2307.12547 ,  388kb)
------------------------------------------------------------------------------
\\
arXiv:2308.03200
replaced with revised version Thu, 18 Jan 2024 18:10:38 GMT   (27135kb,D)

Title: Uncovering local aggregated air quality index with smartphone captured
  images leveraging efficient deep convolutional neural network
Authors: Joyanta Jyoti Mondal, Md. Farhadul Islam, Raima Islam, Nowsin Kabir
  Rhidi, Sarfaraz Newaz, Meem Arafat Manab, A. B. M. Alim Al Islam, Jannatun
  Noor
Categories: cs.CV cs.AI
Comments: 18 pages, 7 figures, published to Nature Scientific Reports
Journal-ref: Mondal, J.J., Islam, M.F., Islam, R. et al. Uncovering local
  aggregated air quality index with smartphone captured images leveraging
  efficient deep convolutional neural network. Sci Rep 14, 1627 (2024)
DOI: 10.1038/s41598-023-51015-1
\\ ( https://arxiv.org/abs/2308.03200 ,  27135kb)
------------------------------------------------------------------------------
\\
arXiv:2309.05448
replaced with revised version Thu, 18 Jan 2024 08:33:35 GMT   (2721kb,D)

Title: Panoptic Vision-Language Feature Fields
Authors: Haoran Chen, Kenneth Blomqvist, Francesco Milano and Roland Siegwart
Categories: cs.CV cs.AI cs.CL
Comments: This work has been accepted by IEEE Robotics and Automation Letters
DOI: 10.1109/LRA.2024.3354624
\\ ( https://arxiv.org/abs/2309.05448 ,  2721kb)
------------------------------------------------------------------------------
\\
arXiv:2310.11446
replaced with revised version Thu, 18 Jan 2024 18:50:55 GMT   (315kb,D)

Title: Functional Invariants to Watermark Large Transformers
Authors: Pierre Fernandez, Guillaume Couairon, Teddy Furon, Matthijs Douze
Categories: cs.CR cs.AI cs.CL
Comments: Published at ICASSP 2024. Webpage at
  https://pierrefdz.github.io/publications/invariancewm/
\\ ( https://arxiv.org/abs/2310.11446 ,  315kb)
------------------------------------------------------------------------------
\\
arXiv:2310.17212
replaced with revised version Thu, 18 Jan 2024 07:37:32 GMT   (4955kb,D)

Title: Affective Video Content Analysis: Decade Review and New Perspectives
Authors: Junxiao Xue, Jie Wang, Xuecheng Wu and Qian Zhang
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2310.17212 ,  4955kb)
------------------------------------------------------------------------------
\\
arXiv:2310.19776
replaced with revised version Thu, 18 Jan 2024 17:53:45 GMT   (3858kb,D)

Title: Learn to Categorize or Categorize to Learn? Self-Coding for Generalized
  Category Discovery
Authors: Sarah Rastegar, Hazel Doughty, Cees G. M. Snoek
Categories: cs.CV cs.AI cs.IT cs.LG math.IT
Comments: Accepted by NeurIPS 2023
ACM-class: I.2.1.b; I.2.6.g; I.5.4.b; I.4
\\ ( https://arxiv.org/abs/2310.19776 ,  3858kb)
------------------------------------------------------------------------------
\\
arXiv:2311.04938
replaced with revised version Thu, 18 Jan 2024 00:44:11 GMT   (15437kb)

Title: Improved DDIM Sampling with Moment Matching Gaussian Mixtures
Authors: Prasad Gabbur
Categories: cs.CV cs.AI cs.LG
Comments: 29 pages, 14 figures; Analysis of DDIM-GMM as a multimodal denoiser;
  Additional experiments on LSUN datasets and text-to-image generation with
  Stable Diffusion; Comparison with DPM-Solver; Ablations on GMM parameters;
  Updated equations with bold font for vectors and matrices
MSC-class: I.2, I.4
\\ ( https://arxiv.org/abs/2311.04938 ,  15437kb)
------------------------------------------------------------------------------
\\
arXiv:2311.09262
replaced with revised version Thu, 18 Jan 2024 17:38:59 GMT   (3978kb,D)

Title: Disentangling the Potential Impacts of Papers into Diffusion,
  Conformity, and Contribution Values
Authors: Zhikai Xue, Guoxiu He, Zhuoren Jiang, Sichen Gu, Yangyang Kang, Star
  Zhao, Wei Lu
Categories: cs.SI cs.AI
Comments: Submitted to TOIS
\\ ( https://arxiv.org/abs/2311.09262 ,  3978kb)
------------------------------------------------------------------------------
\\
arXiv:2311.09868
replaced with revised version Thu, 18 Jan 2024 04:36:46 GMT   (5687kb,D)

Title: INTERVENOR: Prompt the Coding Ability of Large Language Models with the
  Interactive Chain of Repairing
Authors: Hanbin Wang, Zhenghao Liu, Shuo Wang, Ganqu Cui, Ning Ding, Zhiyuan
  Liu and Ge Yu
Categories: cs.SE cs.AI
Comments: 26 pages, 19 figures, 8 tables
\\ ( https://arxiv.org/abs/2311.09868 ,  5687kb)
------------------------------------------------------------------------------
\\
arXiv:2401.00132
replaced with revised version Thu, 18 Jan 2024 10:06:29 GMT   (3169kb,D)

Title: Contrastive learning-based agent modeling for deep reinforcement
  learning
Authors: Wenhao Ma, Yu-Cheng Chang, Jie Yang, Yu-Kai Wang, Chin-Teng Lin
Categories: cs.MA cs.AI
Comments: 8 pages, 6 figures
\\ ( https://arxiv.org/abs/2401.00132 ,  3169kb)
------------------------------------------------------------------------------
\\
arXiv:2401.03473
replaced with revised version Thu, 18 Jan 2024 11:18:32 GMT   (15kb)

Title: ICMC-ASR: The ICASSP 2024 In-Car Multi-Channel Automatic Speech
  Recognition Challenge
Authors: He Wang, Pengcheng Guo, Yue Li, Ao Zhang, Jiayao Sun, Lei Xie, Wei
  Chen, Pan Zhou, Hui Bu, Xin Xu, Binbin Zhang, Zhuo Chen, Jian Wu, Longbiao
  Wang, Eng Siong Chng, Sun Li
Categories: cs.SD cs.AI eess.AS
Comments: 2 pages
\\ ( https://arxiv.org/abs/2401.03473 ,  15kb)
------------------------------------------------------------------------------
\\
arXiv:2401.05163
replaced with revised version Thu, 18 Jan 2024 09:34:31 GMT   (1295kb,D)

Title: MISS: A Generative Pretraining and Finetuning Approach for Med-VQA
Authors: Jiawei Chen, Dingkang Yang, Yue Jiang, Yuxuan Lei, Lihua Zhang
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2401.05163 ,  1295kb)
------------------------------------------------------------------------------
\\
arXiv:2401.05566
replaced with revised version Wed, 17 Jan 2024 20:26:01 GMT   (7452kb,D)

Title: Sleeper Agents: Training Deceptive LLMs that Persist Through Safety
  Training
Authors: Evan Hubinger, Carson Denison, Jesse Mu, Mike Lambert, Meg Tong, Monte
  MacDiarmid, Tamera Lanham, Daniel M. Ziegler, Tim Maxwell, Newton Cheng, Adam
  Jermyn, Amanda Askell, Ansh Radhakrishnan, Cem Anil, David Duvenaud, Deep
  Ganguli, Fazl Barez, Jack Clark, Kamal Ndousse, Kshitij Sachan, Michael
  Sellitto, Mrinank Sharma, Nova DasSarma, Roger Grosse, Shauna Kravec, Yuntao
  Bai, Zachary Witten, Marina Favaro, Jan Brauner, Holden Karnofsky, Paul
  Christiano, Samuel R. Bowman, Logan Graham, Jared Kaplan, S\"oren Mindermann,
  Ryan Greenblatt, Buck Shlegeris, Nicholas Schiefer, Ethan Perez
Categories: cs.CR cs.AI cs.CL cs.LG cs.SE
Comments: updated to add missing acknowledgements
\\ ( https://arxiv.org/abs/2401.05566 ,  7452kb)
------------------------------------------------------------------------------
\\
arXiv:2401.07450
replaced with revised version Thu, 18 Jan 2024 13:55:56 GMT   (8587kb,D)

Title: Hierarchical Fashion Design with Multi-stage Diffusion Models
Authors: Zhifeng Xie, Hao li, Huiming Ding, Mengtian Li, Ying Cao
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2401.07450 ,  8587kb)
------------------------------------------------------------------------------
\\
arXiv:2308.10462
replaced with revised version Thu, 18 Jan 2024 15:37:33 GMT   (163kb,D)

Title: Exploring Parameter-Efficient Fine-Tuning Techniques for Code Generation
  with Large Language Models
Authors: Martin Weyssow, Xin Zhou, Kisub Kim, David Lo and Houari Sahraoui
Categories: cs.SE cs.CL cs.LG
\\ ( https://arxiv.org/abs/2308.10462 ,  163kb)
------------------------------------------------------------------------------
\\
arXiv:2310.03128
replaced with revised version Thu, 18 Jan 2024 18:57:10 GMT   (6830kb,D)

Title: MetaTool Benchmark for Large Language Models: Deciding Whether to Use
  Tools and Which to Use
Authors: Yue Huang and Jiawen Shi and Yuan Li and Chenrui Fan and Siyuan Wu and
  Qihui Zhang and Yixin Liu and Pan Zhou and Yao Wan and Neil Zhenqiang Gong
  and Lichao Sun
Categories: cs.SE cs.CL
\\ ( https://arxiv.org/abs/2310.03128 ,  6830kb)
------------------------------------------------------------------------------
\\
arXiv:2312.10321
replaced with revised version Wed, 17 Jan 2024 20:11:38 GMT   (266kb,D)

Title: LLM-SQL-Solver: Can LLMs Determine SQL Equivalence?
Authors: Fuheng Zhao, Lawrence Lim, Ishtiyaque Ahmad, Divyakant Agrawal, Amr El
  Abbadi
Categories: cs.DB cs.CL
\\ ( https://arxiv.org/abs/2312.10321 ,  266kb)
------------------------------------------------------------------------------
\\
arXiv:2011.14238 (*cross-listing*)
replaced with revised version Thu, 18 Jan 2024 00:57:57 GMT   (1830kb,D)

Title: Approximate Cross-validated Mean Estimates for Bayesian Hierarchical
  Regression Models
Authors: Amy X. Zhang, Le Bao, Changcheng Li, Michael J. Daniels
Categories: stat.ML cs.LG stat.CO
Comments: 26 pages, 2 figures
\\ ( https://arxiv.org/abs/2011.14238 ,  1830kb)
------------------------------------------------------------------------------
\\
arXiv:2301.00924
replaced with revised version Thu, 18 Jan 2024 06:13:12 GMT   (3876kb,D)

Title: Increasing biases can be more efficient than increasing weights
Authors: Carlo Metta, Marco Fantozzi, Andrea Papini, Gianluca Amato, Matteo
  Bergamaschi, Silvia Giulia Galfr\`e, Alessandro Marchetti, Michelangelo
  Vegli\`o, Maurizio Parton, Francesco Morandin
Categories: cs.NE cs.LG
Comments: Major rewriting. Supersedes v1 and v2. Focusing on the fact that not
  all parameters are born equal: biases can be more important than weights.
  Accordingly, new title and new abstract, and many more experiments on fully
  connected architectures. This is the extended version of the paper published
  at WACV 2024
ACM-class: I.2.6
\\ ( https://arxiv.org/abs/2301.00924 ,  3876kb)
------------------------------------------------------------------------------
\\
arXiv:2302.02070
replaced with revised version Thu, 18 Jan 2024 14:03:28 GMT   (9992kb,D)

Title: Semantic-Guided Generative Image Augmentation Method with Diffusion
  Models for Image Classification
Authors: Bohan Li, Xiao Xu, Xinghao Wang, Yutai Hou, Yunlong Feng, Feng Wang,
  Xuanliang Zhang, Qingfu Zhu, Wanxiang Che
Categories: cs.CV cs.LG
Comments: AAAI 2024
\\ ( https://arxiv.org/abs/2302.02070 ,  9992kb)
------------------------------------------------------------------------------
\\
arXiv:2302.07580 (*cross-listing*)
replaced with revised version Thu, 18 Jan 2024 18:42:28 GMT   (1540kb,D)

Title: Unboxing Tree Ensembles for interpretability: a hierarchical
  visualization tool and a multivariate optimal re-built tree
Authors: Giulia Di Teodoro, Marta Monaci, Laura Palagi
Categories: math.OC cs.LG
Comments: 44 pages, 9 figures, 20 tables
DOI: 10.1016/j.ejco.2024.100084
\\ ( https://arxiv.org/abs/2302.07580 ,  1540kb)
------------------------------------------------------------------------------
\\
arXiv:2303.15579 (*cross-listing*)
replaced with revised version Wed, 17 Jan 2024 19:42:46 GMT   (247kb,D)

Title: Adjusted Wasserstein Distributionally Robust Estimator in Statistical
  Learning
Authors: Yiling Xie, Xiaoming Huo
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/2303.15579 ,  247kb)
------------------------------------------------------------------------------
\\
arXiv:2303.17045
replaced with revised version Thu, 18 Jan 2024 12:10:03 GMT   (28kb)

Title: Training Neural Networks is NP-Hard in Fixed Dimension
Authors: Vincent Froese, Christoph Hertrich
Categories: cs.CC cs.DS cs.LG cs.NE stat.ML
Comments: Paper accepted at NeurIPS 2023
\\ ( https://arxiv.org/abs/2303.17045 ,  28kb)
------------------------------------------------------------------------------
\\
arXiv:2304.09172
replaced with revised version Thu, 18 Jan 2024 17:13:21 GMT   (4903kb,D)

Title: Hyperbolic Image-Text Representations
Authors: Karan Desai, Maximilian Nickel, Tanmay Rajpurohit, Justin Johnson,
  Ramakrishna Vedantam
Categories: cs.CV cs.LG
Comments: ICML 2023 (v3: Add link to code in abstract)
\\ ( https://arxiv.org/abs/2304.09172 ,  4903kb)
------------------------------------------------------------------------------
\\
arXiv:2305.02650
replaced with revised version Thu, 18 Jan 2024 09:25:44 GMT   (826kb,D)

Title: A Constrained BA Algorithm for Rate-Distortion and Distortion-Rate
  Functions
Authors: Lingyi Chen, Shitong Wu, Wenhao Ye, Huihui Wu, Wenyi Zhang, Hao Wu and
  Bo Bai
Categories: cs.IT cs.LG math.IT stat.ML
Comments: Version_2
\\ ( https://arxiv.org/abs/2305.02650 ,  826kb)
------------------------------------------------------------------------------
\\
arXiv:2305.07376
replaced with revised version Thu, 18 Jan 2024 10:22:03 GMT   (2189kb,D)

Title: DAISM: Digital Approximate In-SRAM Multiplier-based Accelerator for DNN
  Training and Inference
Authors: Lorenzo Sonnino, Shaswot Shresthamali, Yuan He and Masaaki Kondo
Categories: cs.AR cs.LG
Comments: 12 pages, 9 figures
\\ ( https://arxiv.org/abs/2305.07376 ,  2189kb)
------------------------------------------------------------------------------
\\
arXiv:2305.09820
replaced with revised version Wed, 17 Jan 2024 18:17:48 GMT   (8221kb,D)

Title: Machine-Made Media: Monitoring the Mobilization of Machine-Generated
  Articles on Misinformation and Mainstream News Websites
Authors: Hans W. A. Hanley, Zakir Durumeric
Categories: cs.CY cs.LG cs.SI
Comments: Accepted to ICWSM 2024
\\ ( https://arxiv.org/abs/2305.09820 ,  8221kb)
------------------------------------------------------------------------------
\\
arXiv:2308.03686 (*cross-listing*)
replaced with revised version Thu, 18 Jan 2024 14:54:37 GMT   (173kb,D)

Title: Nearly $d$-Linear Convergence Bounds for Diffusion Models via Stochastic
  Localization
Authors: Joe Benton, Valentin De Bortoli, Arnaud Doucet, George Deligiannidis
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/2308.03686 ,  173kb)
------------------------------------------------------------------------------
\\
arXiv:2308.12952
replaced with revised version Wed, 17 Jan 2024 22:41:29 GMT   (6221kb,D)

Title: BridgeData V2: A Dataset for Robot Learning at Scale
Authors: Homer Walke, Kevin Black, Abraham Lee, Moo Jin Kim, Max Du, Chongyi
  Zheng, Tony Zhao, Philippe Hansen-Estruch, Quan Vuong, Andre He, Vivek Myers,
  Kuan Fang, Chelsea Finn, Sergey Levine
Categories: cs.RO cs.LG
Comments: 9 pages
\\ ( https://arxiv.org/abs/2308.12952 ,  6221kb)
------------------------------------------------------------------------------
\\
arXiv:2309.03708
replaced with revised version Thu, 18 Jan 2024 15:35:38 GMT   (190kb)

Title: Chat Failures and Troubles: Reasons and Solutions
Authors: Manal Helal, Patrick Holthaus, Gabriella Lakatos, Farshid
  Amirabdollahian
Categories: cs.RO cs.HC cs.LG
Comments: In WTF Workshop Proceedings (arXiv:2401.04108) held in conjunction
  with the ACM conference on Conversational User Interfaces (CUI), 19 - 21/07
  2023, in Eindhoven, The Netherlands
Report-no: WTFCUI/2023/05
Journal-ref: Working with Trouble and Failures in Conversation between humans
  and Robots (WTF) workshop held alongside the 5th International Conference on
  Conversational User Interfaces (CUI '23), June 19, 2023, Eindhoven,
  Netherlands
\\ ( https://arxiv.org/abs/2309.03708 ,  190kb)
------------------------------------------------------------------------------
\\
arXiv:2309.07778 (*cross-listing*)
replaced with revised version Thu, 18 Jan 2024 03:55:30 GMT   (15181kb,D)

Title: Virchow: A Million-Slide Digital Pathology Foundation Model
Authors: Eugene Vorontsov, Alican Bozkurt, Adam Casson, George Shaikovski,
  Michal Zelechowski, Siqi Liu, Kristen Severson, Eric Zimmermann, James Hall,
  Neil Tenenholtz, Nicolo Fusi, Philippe Mathieu, Alexander van Eck, Donghun
  Lee, Julian Viret, Eric Robert, Yi Kan Wang, Jeremy D. Kunz, Matthew C. H.
  Lee, Jan Bernhard, Ran A. Godrich, Gerard Oakley, Ewan Millar, Matthew Hanna,
  Juan Retamero, William A. Moye, Razik Yousfi, Christopher Kanan, David
  Klimstra, Brandon Rothrock, Thomas J. Fuchs
Categories: eess.IV cs.CV cs.LG q-bio.TO
\\ ( https://arxiv.org/abs/2309.07778 ,  15181kb)
------------------------------------------------------------------------------
\\
arXiv:2309.16316 (*cross-listing*)
replaced with revised version Thu, 18 Jan 2024 10:23:17 GMT   (8506kb,D)

Title: Astroconformer: The Prospects of Analyzing Stellar Light Curves with
  Transformer-Based Deep Learning Models
Authors: Jia-Shu Pan, Yuan-Sen Ting, Jie Yu
Categories: astro-ph.SR astro-ph.EP astro-ph.IM cs.LG
Comments: 15 pages, 10 figures, Accepted by MNRAS
DOI: 10.1093/mnras/stae068
\\ ( https://arxiv.org/abs/2309.16316 ,  8506kb)
------------------------------------------------------------------------------
\\
arXiv:2309.17366 (*cross-listing*)
replaced with revised version Thu, 18 Jan 2024 02:27:11 GMT   (471kb,D)

Title: 3D-Mol: A Novel Contrastive Learning Framework for Molecular Property
  Prediction with 3D Information
Authors: Taojie Kuang, Yiming Ren, Zhixiang Ren
Categories: q-bio.BM cs.LG
\\ ( https://arxiv.org/abs/2309.17366 ,  471kb)
------------------------------------------------------------------------------
\\
arXiv:2310.13897
replaced with revised version Thu, 18 Jan 2024 02:31:31 GMT   (33kb,D)

Title: Masked Hard-Attention Transformers and Boolean RASP Recognize Exactly
  the Star-Free Languages
Authors: Dana Angluin, David Chiang, and Andy Yang
Categories: cs.FL cs.LG cs.LO
\\ ( https://arxiv.org/abs/2310.13897 ,  33kb)
------------------------------------------------------------------------------
\\
arXiv:2311.01356 (*cross-listing*)
replaced with revised version Thu, 18 Jan 2024 14:39:26 GMT   (68kb,D)

Title: Upper and lower bounds for the Lipschitz constant of random neural
  networks
Authors: Paul Geuchen, Thomas Heindl, Dominik St\"oger, Felix Voigtlaender
Categories: stat.ML cs.LG math.PR
MSC-class: 68T07, 26A16, 60B20, 60G15
\\ ( https://arxiv.org/abs/2311.01356 ,  68kb)
------------------------------------------------------------------------------
\\
arXiv:2311.10359
replaced with revised version Thu, 18 Jan 2024 16:47:43 GMT   (4184kb,D)

Title: FIKIT: Priority-Based Real-time GPU Multi-tasking Scheduling with Kernel
  Identification
Authors: Wenqing Wu
Categories: cs.DC cs.LG
Comments: 20 pages, 20 figures. Update the Abstract on the arXiv page
\\ ( https://arxiv.org/abs/2311.10359 ,  4184kb)
------------------------------------------------------------------------------
\\
arXiv:2311.18243
replaced with revised version Thu, 18 Jan 2024 07:47:24 GMT   (47654kb,D)

Title: DKiS: Decay weight invertible image steganography with private key
Authors: Hang Yang, Yitian Xu, Xuhua Liu
Categories: cs.MM cs.CR cs.CV cs.LG
\\ ( https://arxiv.org/abs/2311.18243 ,  47654kb)
------------------------------------------------------------------------------
\\
arXiv:2312.12849
replaced with revised version Thu, 18 Jan 2024 00:39:29 GMT   (325kb,D)

Title: Divergences induced by dual subtractive and divisive normalizations of
  exponential families and their convex deformations
Authors: Frank Nielsen
Categories: cs.IT cs.LG math.IT
Comments: 19 pages, 3 figures
\\ ( https://arxiv.org/abs/2312.12849 ,  325kb)
------------------------------------------------------------------------------
\\
arXiv:2312.17670
replaced with revised version Thu, 18 Jan 2024 12:29:31 GMT   (14426kb,D)

Title: TopCoW: Benchmarking Topology-Aware Anatomical Segmentation of the
  Circle of Willis (CoW) for CTA and MRA
Authors: Kaiyuan Yang, Fabio Musio, Yihui Ma, Norman Juchler, Johannes C.
  Paetzold, Rami Al-Maskari, Luciano H\"oher, Hongwei Bran Li, Ibrahim Ethem
  Hamamci, Anjany Sekuboyina, Suprosanna Shit, Houjing Huang, Diana
  Waldmannstetter, Florian Kofler, Fernando Navarro, Martin Menten, Ivan Ezhov,
  Daniel Rueckert, Iris Vos, Ynte Ruigrok, Birgitta Velthuis, Hugo Kuijf,
  Julien H\"ammerli, Catherine Wurster, Philippe Bijlenga, Laura Westphal,
  Jeroen Bisschop, Elisa Colombo, Hakim Baazaoui, Andrew Makmur, James
  Hallinan, Bene Wiestler, Jan S. Kirschke, Roland Wiest, Emmanuel Montagnon,
  Laurent Letourneau-Guillon, Adrian Galdran, Francesco Galati, Daniele
  Falcetta, Maria A. Zuluaga, Chaolong Lin, Haoran Zhao, Zehan Zhang, Sinyoung
  Ra, Jongyun Hwang, Hyunjin Park, Junqiang Chen, Marek Wodzinski, Henning
  M\"uller, et al. (33 additional authors not shown)
Categories: cs.CV cs.LG q-bio.QM q-bio.TO
Comments: 23 pages, 11 figures, 9 tables. Summary Paper for the MICCAI TopCoW
  2023 Challenge
\\ ( https://arxiv.org/abs/2312.17670 ,  14426kb)
------------------------------------------------------------------------------
\\
arXiv:2401.04855
replaced with revised version Thu, 18 Jan 2024 08:18:58 GMT   (30795kb,D)

Title: LPAC: Learnable Perception-Action-Communication Loops with Applications
  to Coverage Control
Authors: Saurav Agarwal, Ramya Muthukrishnan, Walker Gosrich, Vijay Kumar,
  Alejandro Ribeiro
Categories: cs.RO cs.LG
\\ ( https://arxiv.org/abs/2401.04855 ,  30795kb)
------------------------------------------------------------------------------
\\
arXiv:2401.08224 (*cross-listing*)
replaced with revised version Wed, 17 Jan 2024 04:32:29 GMT   (772kb,D)

Title: Differentially Private Estimation of CATE in Adaptive Experiment
Authors: Jiachun Li, Kaining Shi and David Simchi-Levi
Categories: stat.ME cs.CR cs.LG
Comments: Corrected the order of author names
\\ ( https://arxiv.org/abs/2401.08224 ,  772kb)
------------------------------------------------------------------------------
\\
arXiv:2401.08689
replaced with revised version Thu, 18 Jan 2024 06:45:16 GMT   (1421kb,D)

Title: NODI: Out-Of-Distribution Detection with Noise from Diffusion
Authors: Jingqiu Zhou, Aojun Zhou, Hongsheng Li
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2401.08689 ,  1421kb)
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---
